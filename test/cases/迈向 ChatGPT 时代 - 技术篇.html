<html lang="zh" data-ios="true" class="itcauecng" data-theme="light" data-rh="data-theme"><head><meta charset="utf-8"><title>迈向 ChatGPT 时代 - 技术篇 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0,viewport-fit=cover"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=10,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-rh="true" name="keywords" content="LLM（大型语言模型）,强化学习 (Reinforcement Learning),GPT"><meta data-rh="true" name="description" content="最近关于 AIGC，ChatGPT 等方面的消息和文章非常多，无论是从没了解过机器学习的圈外人士，还是每天跟模型打交道的专业从业者，都无不被 ChatGPT 的能力震惊。几年后来回顾这个事件，应该会成为通向通用人工智能/…"><meta data-rh="true" property="og:title" content="迈向 ChatGPT 时代 - 技术篇"><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/608075096"><meta data-rh="true" property="og:description" content="最近关于 AIGC，ChatGPT 等方面的消息和文章非常多，无论是从没了解过机器学习的圈外人士，还是每天跟模型打交道的专业从业者，都无不被 ChatGPT 的能力震惊。几年后来回顾这个事件，应该会成为通向通用人工智能/…"><meta data-rh="true" property="og:image" content="https://pic1.zhimg.com/v2-2270f46df05a45d27c520dc784ac336d_720w.jpg?source=172ae18b"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="og:site_name" content="知乎专栏"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png" sizes="152x152"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.d5793cac.png" sizes="120x120"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7abf3393.png" sizes="76x76"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.362a8eac.png" sizes="60x60"><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"><link rel="dns-prefetch" href="//static.zhimg.com"><link rel="dns-prefetch" href="//pica.zhimg.com"><link rel="dns-prefetch" href="//picx.zhimg.com"><link rel="dns-prefetch" href="//pic1.zhimg.com"><link rel="dns-prefetch" href="//pic2.zhimg.com"><link rel="dns-prefetch" href="//pic3.zhimg.com"><link rel="dns-prefetch" href="//pic4.zhimg.com"><link rel="dns-prefetch" href="//static.zhihu.com"><script nonce="ef6bb798-a1b7-475b-8c98-d02c0116af70" data-web-reporter-config="{&quot;platform&quot;:&quot;web&quot;,&quot;project&quot;:&quot;heifetz&quot;}">!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports):"function"==typeof define&&define.amd?define(["exports"],t):t((e=e||self).webReporter={})}(this,function(e){"use strict";var t={},n=!1,o=function(){var e,o,r,a,i;return n||(e=document.querySelector("script[data-web-reporter-config]"),o=e&&e.dataset.webReporterConfig||"{}",r=JSON.parse(o),a=r.platform,i=r.project,t={platform:a,project:i},n=!0),t};function r(e){return a(function(){return localStorage.getItem(e)})()}function a(e){return function(){try{return e.apply(void 0,arguments)}catch(e){}}}var i=a(function(e,t){var n={platform:"web",project:o().project,clientTimestamp:+new Date};!function(e,t,n){"1"===r("weber:logenabled")&&console.log("[web-reporter]%o",{type:e,base:t,data:n})}(e,n,t),function(e,t){var n=btoa(JSON.stringify(t));if("undefined"!=typeof Blob&&window.navigator&&window.navigator.sendBeacon){var o=new Blob([n],{type:"text/plain"});navigator.sendBeacon(e,o)}else{var r=new XMLHttpRequest;r.open("POST",e),r.withCredentials=!1,r.setRequestHeader("Content-Type","text/plain;charset=UTF-8"),r.send(n)}}(r("weber:api")||"https://apm.zhihu.com/collector/web_json",{type:e,base:n,data:t})});e.report=i,Object.defineProperty(e,"__esModule",{value:!0})});
</script><link href="https://static.zhihu.com/heifetz/680.216a26f4.bc3dd4670546193a4781.css" crossorigin="" rel="stylesheet"><link href="https://static.zhihu.com/heifetz/column.216a26f4.3326da597f7431c1ea67.css" crossorigin="" rel="stylesheet"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/GoodsRecommendGoodsCardList.216a26f4.d95ce79191cdf8d7ac28.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/3280.216a26f4.8bfc371d6d7cfdc6aeec.css" crossorigin="anonymous"><script nonce="ef6bb798-a1b7-475b-8c98-d02c0116af70">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"824-bcf32e16\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script><script crossorigin="anonymous" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;824-bcf32e16&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrorsPreset&quot;:&quot;ReactApp&quot;,&quot;tags&quot;:{&quot;app_name&quot;:&quot;heifetz&quot;}}" src="https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js"></script><style data-emotion-css="uzm3ri">.css-uzm3ri{position:fixed;top:0;right:0;left:0;z-index:101;display:none;height:2px;pointer-events:none;background:#056DE8;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}</style><style data-emotion-css="15ro776">.css-15ro776{margin-right:4px;}</style><style data-emotion-css="183aq3r">.css-183aq3r{border-radius:24px;padding:0 15px;font-size:13px;line-height:28px;-webkit-flex:none;-ms-flex:none;flex:none;}</style><style data-emotion-css="1ie3c6f">.css-1ie3c6f{fill:#999999;margin:0 10px;}</style><style data-emotion-css="78p1r9">.css-78p1r9{box-sizing:border-box;margin:0;min-width:0;margin-left:auto;margin-right:auto;max-width:690px;margin-top:0;}@media screen and (min-width:40em){.css-78p1r9{margin-top:1em;}}</style><style data-emotion-css="w59ah2">.css-w59ah2{position:relative;padding-bottom:66.5%;height:0;border-radius:inherit;}</style><style data-emotion-css="1b198zr">.css-1b198zr{box-sizing:border-box;margin:0;min-width:0;position:relative;padding-bottom:66.5%;height:0;border-radius:inherit;}</style><style data-emotion-css="1ld0bim">.css-1ld0bim{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;}</style><style data-emotion-css="1ujtx97">.css-1ujtx97{object-fit:cover;background-color:#F6F6F6;}</style><style data-emotion-css="uodor8">.css-uodor8{border-radius:50%;}</style><style data-emotion-css="kl6aur">.css-kl6aur{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:34px;height:34px;border-radius:50%;}</style><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1yuhvjn">.css-1yuhvjn{margin-top:16px;}</style><style data-emotion-css="376mun">.css-376mun{position:relative;display:inline;}</style><style data-emotion-css="1hhle02">.css-1hhle02 .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1hhle02 .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1hhle02 .FileLinkCard-info{margin-left:12px;}.css-1hhle02 .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1hhle02 .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1hhle02 .FileLinkCard-source{white-space:pre;}.css-1hhle02 img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1r0wf39">.css-1r0wf39 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1r0wf39 .LinkCard.new,.css-1r0wf39 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1r0wf39 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1r0wf39 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1r0wf39 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1r0wf39 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1r0wf39 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1r0wf39 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1r0wf39 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1r0wf39 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1r0wf39 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1r0wf39 .LinkCard.old,.css-1r0wf39 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="3np2dk">.css-3np2dk .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-3np2dk .LinkCard.old,.css-3np2dk .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-3np2dk .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-3np2dk .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-3np2dk .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-3np2dk .LinkCard.new,.css-3np2dk .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-3np2dk .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-3np2dk .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-3np2dk .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-3np2dk .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-3np2dk .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-3np2dk .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-3np2dk .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-3np2dk .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-3np2dk .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-3np2dk .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-3np2dk .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-3np2dk .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-3np2dk .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-3np2dk .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-3np2dk .FileLinkCard-info{margin-left:12px;}.css-3np2dk .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-3np2dk .FileLinkCard-source{white-space:pre;}.css-3np2dk img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1t538q animation-1yvu044">.css-1t538q{word-break:break-word;line-height:1.6;}.css-1t538q > [data-first-child]{margin-top:0;}.css-1t538q > :last-child{margin-bottom:0;}.css-1t538q h1,.css-1t538q h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:500;}.css-1t538q h3,.css-1t538q h4,.css-1t538q h5,.css-1t538q h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:500;}.css-1t538q u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #444444;}.css-1t538q b{font-weight:500;}.css-1t538q sup{font-size:0.8em;}.css-1t538q sup[data-draft-type='reference']{color:#175199;}.css-1t538q a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-1t538q a:focus{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(5,109,232,0.3);}.css-1t538q a.ztext-link,.css-1t538q a.internal,.css-1t538q a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #808080;}.css-1t538q a.ztext-link:hover,.css-1t538q a.internal:hover,.css-1t538q a.external:hover{color:#175199;border-bottom:1px solid #175199;}.css-1t538q a.ztext-link > .ellipsis::after,.css-1t538q a.internal > .ellipsis::after,.css-1t538q a.external > .ellipsis::after{content:'...';}.css-1t538q a.ztext-link > .invisible,.css-1t538q a.internal > .invisible,.css-1t538q a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-1t538q a.ztext-link u,.css-1t538q a.internal u,.css-1t538q a.external u{border:none;}.css-1t538q a.member_mention{color:#175199;}.css-1t538q a.member_mention:hover{border-bottom:1px solid #175199;}.css-1t538q a.UserLink-link{color:#175199;}.css-1t538q a.UserLink-link:hover{border-bottom:1px solid #175199;}.css-1t538q p{margin:1.4em 0;}.css-1t538q p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-1t538q p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-1t538q hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #D3D3D3;}.css-1t538q img[eeimg]{max-width:100%;vertical-align:middle;}.css-1t538q img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-1t538q img[eeimg="2"]{margin:1.4em auto;display:block;}.css-1t538q blockquote{margin:1.4em 0;padding-left:1em;color:#646464;border-left:3px solid #D3D3D3;}.css-1t538q ol,.css-1t538q ul{margin:1.4em 0;padding:0;width:100%;}.css-1t538q ol ol,.css-1t538q ul ol,.css-1t538q ol ul,.css-1t538q ul ul{margin:0;}.css-1t538q ol li::before,.css-1t538q ul li::before{width:1em;}.css-1t538q ol > ol,.css-1t538q ul > ol,.css-1t538q ol > ul,.css-1t538q ul > ul{display:table-row;}.css-1t538q ol > ol::before,.css-1t538q ul > ol::before,.css-1t538q ol > ul::before,.css-1t538q ul > ul::before{display:table-cell;content:'';}.css-1t538q ul{display:table;}.css-1t538q ul>li{display:table-row;list-style:none;}.css-1t538q ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-1t538q ol{display:table;counter-reset:ol;}.css-1t538q ol > li{display:table-row;list-style:none;}.css-1t538q ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-1t538q ol ol{counter-reset:ol2;}.css-1t538q ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-1t538q ol ol ol{counter-reset:ol3;}.css-1t538q ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-1t538q ol ol ol ol{counter-reset:ol4;}.css-1t538q ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-1t538q figure{margin:1.4em 0;}.css-1t538q figure .content_image,.css-1t538q figure .origin_image{margin:0 auto;}.css-1t538q figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#999999;}.css-1t538q figure + figure{margin-top:calc(1.4em * 1.6);}.css-1t538q figure[data-size='small'],.css-1t538q figure:not([data-size]) > [data-size='small']{clear:both;}.css-1t538q figure[data-size='left'],.css-1t538q figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-1t538q figure[data-size='right'],.css-1t538q figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-1t538q figure[data-size='collapse']{margin-bottom:0;}.css-1t538q figure[data-size='collapse'] + figure{margin-top:0;}.css-1t538q .content_image,.css-1t538q .origin_image{display:block;max-width:100%;height:auto;margin:1.4em auto;}.css-1t538q .content_image[data-size='small'],.css-1t538q .origin_image[data-size='small']{max-width:40%;}.css-1t538q .content_image.zh-lightbox-thumb,.css-1t538q .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-1t538q code{margin:0 2px;padding:3px 4px;border-radius:3px;font-family:Menlo,Monaco,Consolas,'Andale Mono','lucida console','Courier New',monospace;font-size:0.9em;background-color:#F6F6F6;}.css-1t538q pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#F6F6F6;border-radius:4px;}.css-1t538q pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-1t538q li pre{white-space:pre-wrap;}.css-1t538q table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-1t538q table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-1t538q table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#F6F6F6;}.css-1t538q table[data-draft-type='table'] td,.css-1t538q table[data-draft-type='table'] th{border:1px solid #D3D3D3;line-height:24px;height:24px;padding:3px 12px;}.css-1t538q table[data-draft-type='table'] th{background:#EBEBEB;color:#121212;font-weight:500;}.css-1t538q .video-box,.css-1t538q .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #EBEBEB;border-radius:4px;}.css-1t538q .lazy[data-lazy-status]{background-color:#F6F6F6;}.css-1t538q .lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1yvu044 0.5s ease-in;animation:animation-1yvu044 0.5s ease-in;}.css-1t538q .highlight{margin:1em 0;}.css-1t538q .highlight pre{margin:0;}.css-1t538q .highlight .hll{background-color:#FDFDFD;}.css-1t538q .highlight .c{font-style:italic;color:#999999;}.css-1t538q .highlight .err{color:#F1403C;}.css-1t538q .highlight .k{font-weight:500;}.css-1t538q .highlight .o{font-weight:500;}.css-1t538q .highlight .cm{font-style:italic;color:#999999;}.css-1t538q .highlight .cp{font-weight:500;color:#999999;}.css-1t538q .highlight .c1{font-style:italic;color:#999999;}.css-1t538q .highlight .cs{font-style:italic;font-weight:500;color:#999999;}.css-1t538q .highlight .gd{color:#FF3366;}.css-1t538q .highlight .ge{font-style:italic;}.css-1t538q .highlight .gr{color:#F1403C;}.css-1t538q .highlight .gh{color:#999999;}.css-1t538q .highlight .gi{color:#12b370;}.css-1t538q .highlight .go{color:#808080;}.css-1t538q .highlight .gp{color:#646464;}.css-1t538q .highlight .gs{font-weight:500;}.css-1t538q .highlight .gu{color:#999999;}.css-1t538q .highlight .gt{color:#F1403C;}.css-1t538q .highlight .kc{font-weight:500;}.css-1t538q .highlight .kd{font-weight:500;}.css-1t538q .highlight .kn{font-weight:500;}.css-1t538q .highlight .kp{font-weight:500;}.css-1t538q .highlight .kr{font-weight:500;}.css-1t538q .highlight .kt{font-weight:500;color:#175199;}.css-1t538q .highlight .m{color:#056DE8;}.css-1t538q .highlight .s{color:#F1403C;}.css-1t538q .highlight .na{color:#056DE8;}.css-1t538q .highlight .nb{color:#056DE8;}.css-1t538q .highlight .nc{font-weight:500;color:#175199;}.css-1t538q .highlight .no{color:#056DE8;}.css-1t538q .highlight .ni{color:#5555DD;}.css-1t538q .highlight .ne{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nf{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nn{color:#646464;}.css-1t538q .highlight .nt{color:#175199;}.css-1t538q .highlight .nv{color:#056DE8;}.css-1t538q .highlight .ow{font-weight:500;}.css-1t538q .highlight .w{color:#BFBFBF;}.css-1t538q .highlight .mf{color:#056DE8;}.css-1t538q .highlight .mh{color:#056DE8;}.css-1t538q .highlight .mi{color:#056DE8;}.css-1t538q .highlight .mo{color:#056DE8;}.css-1t538q .highlight .sb{color:#F1403C;}.css-1t538q .highlight .sc{color:#F1403C;}.css-1t538q .highlight .sd{color:#F1403C;}.css-1t538q .highlight .s2{color:#F1403C;}.css-1t538q .highlight .se{color:#F1403C;}.css-1t538q .highlight .sh{color:#F1403C;}.css-1t538q .highlight .si{color:#F1403C;}.css-1t538q .highlight .sx{color:#F1403C;}.css-1t538q .highlight .sr{color:#A5542F;}.css-1t538q .highlight .s1{color:#F1403C;}.css-1t538q .highlight .ss{color:#F1403C;}.css-1t538q .highlight .bp{color:#999999;}.css-1t538q .highlight .vc{color:#056DE8;}.css-1t538q .highlight .vg{color:#056DE8;}.css-1t538q .highlight .vi{color:#056DE8;}.css-1t538q .highlight .il{color:#056DE8;}.css-1t538q .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(18,18,18,0.5);border-radius:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(18,18,18,0.6);}.css-1t538q .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1t538q .LinkCard.old,.css-1t538q .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1t538q .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1t538q .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-1t538q .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1t538q .LinkCard.new,.css-1t538q .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1t538q .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1t538q .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1t538q .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1t538q .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1t538q .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1t538q .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1t538q .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1t538q .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1t538q .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1t538q .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1t538q .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1t538q .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1t538q .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1t538q .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1t538q .FileLinkCard-info{margin-left:12px;}.css-1t538q .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1t538q .FileLinkCard-source{white-space:pre;}.css-1t538q img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}@-webkit-keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}@keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}</style><style data-emotion-css="1k6fd7f">.css-1k6fd7f{margin:0;padding-top:15px;}</style><style data-emotion-css="1any501">.css-1any501{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:40px;height:40px;border-radius:50%;}</style><style data-emotion="css"></style></head><body class="WhiteBg-body PostIndex-body Body--Mobile Body--iOS Body--isAppleDevice" aria-basefontsize="16" data-rh="class"><a id="ariaTipText" role="pagedescription" aria-label="链接，无障碍模式读屏软件服务通道。" aria-atomic="true" href="javascript:void(0)" class="skipAutoFix" onclick="aria.wzaStart();" style="width: 1px; height: 1px;"><img src="" style="width:1px !important;height:1px !important;position:absolute;top:0;"></a><div id="root"><div class="App"><div class="LoadingBar  css-nvw5ip"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content Post-content-mobile" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;字节&quot;,&quot;itemId&quot;:608075096,&quot;title&quot;:&quot;迈向 ChatGPT 时代 - 技术篇&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;608075096&quot;}}}"><div><header class="Sticky MobileAppHeader" style="line-height:50px"><div class="MobileAppHeader-inner"><a class="MobileAppHeader-logo" href="//www.zhihu.com?utm_source=zhihu&amp;utm_campaign=guest_feed&amp;utm_content=guide&amp;utm_medium=zhuanlan&amp;utm_id=0" aria-label="知乎"><svg viewBox="0 0 64 30" fill="#056DE8" width="52" height="24.375"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><div class="MobileAppHeader-actions"><label class="MobileAppHeader-searchBox MobileAppHeader-searchBoxWithUnlogin Input-wrapper"><svg width="16" height="16" viewBox="0 0 24 24" fill="#999" class="ZDI ZDI--Search24 css-15ro776"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M11.5 18.389c3.875 0 7-3.118 7-6.945 0-3.826-3.125-6.944-7-6.944s-7 3.118-7 6.944 3.125 6.945 7 6.945Zm0 1.5c4.694 0 8.5-3.78 8.5-8.445C20 6.781 16.194 3 11.5 3S3 6.78 3 11.444c0 4.664 3.806 8.445 8.5 8.445Z"></path><path d="M16.47 16.97a.75.75 0 0 1 1.06 0l3.5 3.5a.75.75 0 1 1-1.06 1.06l-3.5-3.5a.75.75 0 0 1 0-1.06Z"></path></g></svg><input type="search" value="" class="Input" placeholder="搜索"></label><a class="MobileAppHeader-authLink" href="https://www.zhihu.com/signin?next=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F608075096" data-za-detail-view-name="注册或登录"><svg width="24" height="24" viewBox="0 0 24 24" style="vertical-align:middle;margin-bottom:1px" class="ZDI ZDI--User24" fill="currentColor"><path fill-rule="evenodd" d="M7.25 8A4.75 4.75 0 0 1 12 3.25 4.75 4.75 0 0 1 16.75 8 4.75 4.75 0 0 1 12 12.75 4.75 4.75 0 0 1 7.25 8ZM12 1.75A6.25 6.25 0 0 0 5.75 8a6.248 6.248 0 0 0 3.275 5.498c-2.993 1.03-5.222 3.572-5.521 6.681a.75.75 0 1 0 1.493.144c.31-3.209 3.277-5.819 7.006-5.819.025 0 .05-.001.075-.004 3.692.036 6.622 2.634 6.93 5.823a.75.75 0 1 0 1.492-.144c-.3-3.11-2.527-5.652-5.52-6.684A6.248 6.248 0 0 0 18.25 8 6.25 6.25 0 0 0 12 1.75Z" clip-rule="evenodd"></path></svg></a><button type="button" class="Button css-183aq3r Button--blue">打开App</button><svg width="22" height="22" viewBox="0 0 24 24" class="ZDI ZDI--Dots24 css-1ie3c6f" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></div></div><div></div></header></div><div class="css-78p1r9"><div class="css-1b198zr"><div class="css-1ld0bim"><img src="https://pic1.zhimg.com/v2-2270f46df05a45d27c520dc784ac336d_720w.jpg?source=172ae18b" alt="迈向 ChatGPT 时代 - 技术篇" width="100%" height="100%" class="css-1phd9a0" srcset="https://pic1.zhimg.com/v2-2270f46df05a45d27c520dc784ac336d_200x0.jpg?source=172ae18b 200w,https://pic1.zhimg.com/v2-2270f46df05a45d27c520dc784ac336d_qhd.jpg?source=172ae18b 480w,https://pic1.zhimg.com/v2-2270f46df05a45d27c520dc784ac336d_720w.jpg?source=172ae18b 720w,https://pic1.zhimg.com/v2-2270f46df05a45d27c520dc784ac336d_1440w.jpg?source=172ae18b 1440w" loading="lazy"></div></div></div><article class="Post-Main Post-Main-Mobile" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">迈向 ChatGPT 时代 - 技术篇</h1></header><div class="Post-TimeExtra">3 个月前<!-- --> · 来自专栏 <!-- -->RandomGenerator</div><div class="Post-Author Post-Author-Mobile"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><div class="AuthorInfo"><meta itemprop="name" content="字节"><meta itemprop="image" content="https://pic1.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/zijie0"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar AuthorInfo-avatar css-kl6aur" src="https://pic1.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b" srcset="https://pic1.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b 2x" alt="字节"></a></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">字节</a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText css-0">天地大观，志存高远</div></div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path fill-rule="evenodd" d="M13.25 3.25a1.25 1.25 0 1 0-2.5 0v7.5h-7.5a1.25 1.25 0 1 0 0 2.5h7.5v7.5a1.25 1.25 0 1 0 2.5 0v-7.5h7.5a1.25 1.25 0 0 0 0-2.5h-7.5v-7.5Z" clip-rule="evenodd"></path></svg></span>关注</button></div><div class="Post-RichTextContainer"><div class="css-1yuhvjn"><div class="css-376mun"><div class="RichText ztext Post-RichText css-1t538q" options="[object Object]"><p data-first-child="" data-pid="n9g-OzYs">最近关于 AIGC，ChatGPT 等方面的消息和文章非常多，无论是从没了解过机器学习的圈外人士，还是每天跟模型打交道的专业从业者，都无不被 ChatGPT 的能力震惊。几年后来回顾这个事件，应该会成为通向通用人工智能/技术奇点的一个关键里程碑。这两个月我也不能免俗刷了很多相关文章和视频，过程中发现了不少颠覆我原有认知的信息。这篇文章主要是站在“巨人们的肩膀上”，从各个角度来聊聊我的收获和一些思考。</p><p data-pid="I-nGbiwd">这也是我第一次尝试付费文章的形式，看看接受度如何 :) 本文的内容大致会分成技术，商业化和提升个人生产力三个角度来展开，每个部分主要内容都是个人的 key takeaways 和思考，同时把我目前看到的比较好的参考文章列出来。非常欢迎有不同想法的同学来一起探讨。从受众角度，应该比较适合：</p><ol><li data-pid="bDVOfoYF">AI 领域从业者，想了解 LLM 和 AGI 的最新进展以及对自己工作的影响。但不太适合那种已经看了几十篇 LLM 领域论文的专业大佬，那样的话我这边写的内容应该你都很熟悉了。</li><li data-pid="WM2lCY6u">平时用 Google，知乎等网站比较多的知识型工作者（尤其是软件工程师），对于 <a href="https://zhuanlan.zhihu.com/p/366187306" class="internal">生产力工具</a> 非常感兴趣的同学，这篇文章应该也会比较合你胃口。</li><li data-pid="sv0BFUVR">有创业或者相关领域投资方面想法的同学，但这方面的不确定性很强，个人见解仅供参考。</li><li data-pid="d4IS54Ms">想了解通用人工智能对我们的工作，学习，生活的各种影响的其他同学，如果你不缺这几块钱的话 :)</li></ol><p data-pid="6qiMMUhU">好了，话不多说，先让我们来看下 ChatGPT 背后的神奇技术与 OpenAI 的远大 vision。</p><h2>技术</h2><p data-pid="mbrayNGu">这部分先推荐一篇来自张俊林老师的文章 <a href="https://zhuanlan.zhihu.com/p/597586623" class="internal">通向 AGI 之路：大型语言模型（LLM）技术精要</a>。一般来说，张老师如果在某个领域写了篇文章，在很长一段时间里我都不会考虑单独写这个话题了，贡献非常有限 。这部分会快速列举一些我之前不知道的或者令人意外的信息和思考角度。</p><h3>新范式：生成一切</h3><p data-pid="2fupdprX">如果去读一些经典的机器学习教材，我们会发现大多数的算法建模任务都是以“输入信息，输出判别”的形式来思考的。例如给定一句话，希望模型来判断这句话表达的是正面还是负面的情感，这就是一个经典的分类问题。而在 NLP 中，又有很多“生成”性质的问题。例如提一个问题，希望模型给出答案。这种任务上的多样性，导致以往我们需要针对每一个任务来分别设计数据收集，模型训练流程，很难进行复用。当年 BERT 模型推出时，令我印象最深刻的也是它对于多任务统一的巧妙设计。</p><p data-pid="fNM5Znqr">但到了以 GPT 为代表的大语言模型阶段，一个显著的思维方式变化是我们其实可以通过“生成”来解决一切问题。例如还是上面的情感分类问题，我们可以直接把语句输入给模型，并提问“这句话表达的是正面还是负面的情绪”，然后让模型对于上面的一整串输入，去生成一个输出回答。这样无论是分类，回归，还是生成类任务，都可以统一到一种框架下来实现了，也就可以使用统一的预训练模型来处理，非常优雅。这个生成一切的思维转变，也影响到了后面我们会提到的从 fine tune 思路到 prompt engineering 的思维转变等。</p><p data-pid="3bJhExuv">回过头来看，生成式的范式的确是很自然的想法，但在大多数领域我们目前都还做不到这点。比如我们能否输入一连串历史天气信息，让模型自动去生成未来几天的天气预报；输入用户的历史浏览、购物信息，生成出可能感兴趣的商品；输入一张图片，生成出图片中的物体名称及位置信息等等。如果这些任务都能以生成式的方式去做，或许未来能进一步形成多模态的预训练模型，解决更多领域的实际问题。</p><h3>自监督</h3><p data-pid="2X02y_Vo">GPT 背后的模型原理出奇的简单，就是通过一系列输入文本，去预测后面会出现的文本是什么。大佬 Andrej Karpathy 在这个视频里 <a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1E14y1M75n/" class=" wrap external" target="_blank" rel="nofollow noreferrer">手把手教你如何从头实现 GPT</a>，如果对实现细节感兴趣的同学可以参考。这种自监督的模式使得我们能以较低成本获取海量的训练数据，例如 Wikipedia，出版书籍，新闻，各种公开 blog，Stack Overflow，GitHub 等等。而前面提到的一些其他类型的如图像/视频理解之类的问题，我们就比较难获取类似数量和质量的训练数据了。</p><p data-pid="fh1P-nzp">当然也正是由于 GPT 背后的思想如此的简单，很多人（包括我在内）在一开始都觉得深度学习的本质并没有什么突破，仍然是在一堆数据中去拟合一个概率分布，后续在“生成”时做个采样而已。像各种知识概念，逻辑推理等，都是无法从当前的技术路线中产生的，需要融合像知识图谱，符号推理等手段才行。但在用过 ChatGPT 之后，相信大多数人都开始觉得这种简单的自回归模型或许真的能够带我们在通用人工智能的这条路上走得很远。</p><h3>遵循自然语言指令</h3><p data-pid="czNYS-ck">沿着生成一切的思路，一个自然的想法就是让模型能够“听懂”人类的指令，并做出期望的反馈回答。OpenAI 和 Google 都在这个方向上做了不少研究工作，略过技术细节，这些研究的目标是能够达到：</p><ul><li data-pid="VbQlCNiy">让模型理解用户的意图是什么，而不只是简简单单做文本的“续写”输出。</li><li data-pid="7kjc1Yzg">对于模型没有见过的问题，也能很好地理解与回答（zero-shot）。</li><li data-pid="xeUQ6Ety">符合人类的价值观，例如输出的内容中应该遵循事实，语气友好，减少“有害”内容等。这一点 ChatGPT 做得格外好，很多人都觉得这是一个可以让自己孩子与之交谈学习的聊天机器人。很多其它大厂产品在这块都受到了很大的挑战。</li></ul><p data-pid="biXROq3t">具体可以参考 <a href="https://link.zhihu.com/?target=https%3A//openai.com/blog/instruction-following/%23moon" class=" wrap external" target="_blank" rel="nofollow noreferrer">OpenAI 这篇文章中的一些例子</a>。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_b.jpg" data-size="normal" data-rawwidth="1796" data-rawheight="1118" class="origin_image zh-lightbox-thumb" width="1796" data-original="https://pic4.zhimg.com/v2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1796' height='1118'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1796" data-rawheight="1118" class="origin_image zh-lightbox-thumb lazy" width="1796" data-original="https://pic4.zhimg.com/v2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_b.jpg" data-original-token="v2-7ad04a63e50415484e8976f12b9c0675"></div><figcaption>Instruct Tuning 的效果</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="wiRNsY_b">打一个不太精确的比方，只用自监督训练形成的大语言模型相当于把互联网上所有的高质量文本信息都看了一遍，拥有了大量的知识，并且可以模仿人类的方式来续写文本，但它从来没有跟真实的人交互过，因此也无法理解人类的交互意图。通过人类指令和期望回答方面的学习，模型在“续写”能力上增加了“理解力”，从而成为一个真正可用的多任务通用模型。</p><h3>强化学习</h3><p data-pid="p4fy6SsM">在做上述的人类指令学习方面，InstructGPT/ChatGPT 引入了人工标注与强化学习技术（RLHF）。从技术细节上来看，有几个比较有意思的点可以讨论。</p><p data-pid="yM-2OLRc">如果让你来做人类指令的学习，你会怎么实现呢？一个最直观的思路肯定是给定一些问题，然后由人工来撰写回答，将这部分数据作为监督学习的样本放到模型中去训练。从 ChatGPT 的模型使用方式来看，也并不是像下棋一样跟人对弈，没有像典型的强化学习那样有“根据环境改变策略”的操作。所以很多人应该跟我一样，都觉得这里其实不用强化学习也可以达到类似的效果。</p><p data-pid="4oaM_J-S">但后来仔细看了一下他们做 RLHF 的过程，发现有几个相对于直接做有监督 tuning 的提升的可能出发点：</p><ul><li data-pid="sFq8L8q6">直接写问题的答案，相比来说对于人工标记员的水平要求和时间开销可能更高，学习到的指令理解可能也更偏向于标记人员的取向。而如果让标记员对模型生成的若干个回答做从好到坏的排序相对来说更容易一些，形成的 reward model 有更高的复用性，大大提升效率。</li><li data-pid="phjB0G93">对于排序信息的利用也有一些小 trick，相当于做了一定的数据增强。这部分论文里有很详细的描述，包括怎么招标记团队等，几乎可以直接拿来使用。</li><li data-pid="mdzljlTg">他们在强化学习的 loss 中做了一些特殊设计，使得模型能符合人类预期，同时在 in context learning 和模型任务上不会损失太多性能。不过这一点应该在有监督中也可以做到，不知道具体效果有多大差别。</li><li data-pid="gOzlR7Ud">强化学习的流程更符合产品人机交互的形态，便于后续迭代。例如当前 ChatGPT 输出的回答，我们是可以提供正面或者负面反馈的，这些信息就相当于在给模型输出做排序，后面可以继续用在同样的框架里优化模型。这一点对于产品化来说非常重要，当前一亿的用户量能够提供的反馈数据量绝对是一大产品壁垒。</li><li data-pid="wiHGzLzt">强化学习作为通用范式，未来有更大的想象空间，把在时间维度上做连续决策的能力也用上。例如聊天过程中为了更好地达成用户满意度（可以灵活选择 objective）的目标，可以先主动询问和澄清问题，再去做回答；模型生成的代码也可以在真实环境去运行，生成 reward signal，继续优化 reward 模型和 policy 模型。这与 OpenAI 发展通用人工智能的设想是高度一致的。</li></ul><p data-pid="GaSEPckF">所以总结来看，这里并不只是为了炫技而使用强化学习，而是有其背后深层的设计考量的。从自回归的“模仿学习”再到与真实环境交互的“强化学习”，或许就是 OpenAI 对于 AGI 的整体路线设计。</p><h3>从“微调”到“提示词”优化</h3><p data-pid="jffWeY0P">前面提到的让模型遵循自然语言指令，极大地改变了我们使用模型的方式。以往的常见思路是我们一般会有一个基于公开数据训练的模型，然后针对于特定领域的任务，我们再收集一波“领域专用”数据，然后做一下模型微调（fine tune）。就有点像我们有了一个各方面能力还过得去的普通人，然后训练它一下，让它更擅长做某种具体的任务（医学诊断，气象云图分析，自动驾驶之类）。这个思路看起来很美好，但也会碰到很多挑战：</p><ul><li data-pid="P_g92IRt">领域的新数据持续产生，需要持续的微调与部署，有较大计算成本。</li><li data-pid="yIi_E11u">微调本身改变了模型参数，可能导致“灾难性遗忘”。事实上 InstructGPT 就在提升理解能力的基础上，损失了一些任务的性能，被称为“对齐税”。</li><li data-pid="xwtW7_K_">过程中模型性能会持续下降，等到下一次微调再提升回来，有一定的滞后性。</li><li data-pid="lWqaw7TM">微调数据可能与原有训练数据的分布差别较大，导致模型的泛化性降低。这也不太像人类的工作方式 :)</li></ul><p data-pid="3bwELODv">所以在 OpenAI 的一系列工作中，都非常突出 zero-shot/few-shot 方向的能力优化。简单来说，就是在碰到一个新领域的问题时，我是否可以不微调模型，而是改变一下我问问题的方式，就能让模型做出比较好的回答。Zero-shot，指的是我完全不给任何任务相关的例子，就希望模型来回答，有时候也被称为 prompt/instruct 的设计/调优。Few-shot，则是我在问题中给出几个例子，然后再让模型来回答，有时候也被称为 in context learning。但不管怎么说，这个思路都是令人震撼的，相当于我没有改变任何模型的参数，仅仅通过不同的提问方式，就能让它知道应该怎么回答。</p><h3>“问一个好的问题”</h3><p data-pid="vtXyLP2N">知道答案不重要，能问出好的问题才是核心能力。这句话放在当前的大语言模型上真是再合适不过了。这里有非常多神奇的现象，我们分别来看一下。</p><h3>Chain of Thought</h3><p data-pid="9ff4EIpa">人们在使用 GPT 这类模型中发现，一个原始的问题，模型可能没法正确回答，但是只要在提问中加一句“让我们一步一步来思考”，或者对于给出样例的问题中，同时给出一些推理过程，那么模型就能大幅度提升回答的准确率。第一次看到这个发现，我相信很多人脑海里都会出现一堆“黑人问号”的表情……看起来模型已经拥有了强大的推理能力。</p><h3>Few-shot Prompt</h3><p data-pid="shqYTqxt">在一些模型没有见过的任务上，我们可以给出一些样例，比如我们在做新产品的头脑风暴，可以描述一下大概想要的几种创意，然后让模型来生成更多。这里比较有意思的在于，假设我们举的例子是一系列 f(x) = y 的数据对，这个 y 的值是否准确并不重要，而只要 y 的总体分布符合真实分布就可以。这跟两个真实的人交谈很像，“我举个例子”，这个例子只要形式上正确就行，具体数值是否精确并不妨碍另外一个人对 context 的理解。</p><p data-pid="Pnw3snOB">这一点可以说与传统的 fine tune 的思维发生了巨大的转变，我们现在完全可以向一个固定的模型去提问，在问题中包含一些“训练样本”，模型就能在不改变 weights 的情况下，实时学习到这些内容，并产生我们想要的输出。简单来说就是，amazing！</p><p data-pid="NQccZ1sP">从技术角度分析，这篇 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.10559" class=" wrap external" target="_blank" rel="nofollow noreferrer">Why Can GPT Learn In-Context?</a> 文章给出了一个很有意思的解释，in context learning 可以等价于在做一个少量样本的 fine tune。</p><h3>复杂的组合应用</h3><p data-pid="IpXRFvmR">我们可以进一步把问问题串联起来，完成复杂任务。比如：</p><ul><li data-pid="UAR-syWc">可以给模型一些样例，让它来生成问题指令（soft prompting），然后再以这个问题去问模型。</li><li data-pid="Z1FwuL8b">可以对一个问题提供多种思路，分别来问模型，最后再集成起来让模型自己做个总结之类。</li><li data-pid="Tc2XQKJn">可以把模型的回答再输入给模型，问它“你觉得上面的回答是否不够友好/含有歧视，是否可以改进”等，进而提升模型的安全性。</li><li data-pid="ub8oBeJi">可以把一个问题拆解成多个子问题，一个一个问，然后再把问题和回答作为 context，组合起来问最终的问题，实现分而治之。</li><li data-pid="0GchYO0G">还有像 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.10560" class=" wrap external" target="_blank" rel="nofollow noreferrer">Self-Instruct</a> 这样的应用，让模型自己来生成数据“训练”自己！</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-4b8f9118dfc992439cfb11ad9e102615_b.jpg" data-size="normal" data-rawwidth="2130" data-rawheight="958" class="origin_image zh-lightbox-thumb" width="2130" data-original="https://pic2.zhimg.com/v2-4b8f9118dfc992439cfb11ad9e102615_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2130' height='958'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2130" data-rawheight="958" class="origin_image zh-lightbox-thumb lazy" width="2130" data-original="https://pic2.zhimg.com/v2-4b8f9118dfc992439cfb11ad9e102615_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-4b8f9118dfc992439cfb11ad9e102615_b.jpg" data-original-token="v2-209d6f5701a38c2863d0d4c36367755d"></div><figcaption>Self-Instruct 流程</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>激发模型能力</h3><p data-pid="c18-Of6g">从上面这些例子可以看出，大语言模型拥有非常类似于人的思维能力，只是需要通过正确的指令来进行激发。就如前面所说，模型已经学习了互联网上的所有文本，具有了非常丰富的知识和潜在的推理能力（后续会详细解释）。但这个模型是没有与真实世界的感知连接的。比如真实的两个人在交谈时，现在的时间，地点，环境等等情境信息，我们都是可以通过真实的感知获得的，因此在对话中双方都有这部分的预设信息。而对于模型来说，简单的一个问题可能并没有办法让它理解当前的情境和提问者的意图，是想让我做创意想象，还是做逻辑推理，还是查询事实知识等。这些信息都依赖于指令本身来提供，而好的指令能够激发模型，选择其相应的“记忆”与“能力”，完成具体任务。</p><p data-pid="iSxPNGHl">更通俗来说，即使是同一件事情，我们在做工作汇报时的思维与表达方式，和跟同事吃饭时闲聊的描述的方式，都会有很大的不同。对于模型来说更是如此。因此详细的问题情境描述能够把让模型把特定的“思考方式”调用出来，实现能力的激发。这也是神奇的 in context learning 的一种直观理解方式。</p><h3>ChatGPT 的能力从何而来</h3><p data-pid="fq1HFxKY">对于上述提到的 ChatGPT 的神奇能力，大家应该都很好奇到底是从何而来。好像不需要知识图谱，符号主义的那套方法，模型也能记住各种知识和它们之间的关联，并做一些简单的逻辑推理。这里有一篇非常好的文章，推断了 <a href="https://link.zhihu.com/?target=https%3A//yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1%23c45fd4df87a349028ade2d9dbeb1188f" class=" wrap external" target="_blank" rel="nofollow noreferrer">GPT 系列模型中各种能力的来源</a>。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-2551c51bd2bd3f58ee70da59b9199901_b.jpg" data-size="normal" data-rawwidth="2112" data-rawheight="1886" class="origin_image zh-lightbox-thumb" width="2112" data-original="https://pic2.zhimg.com/v2-2551c51bd2bd3f58ee70da59b9199901_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2112' height='1886'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2112" data-rawheight="1886" class="origin_image zh-lightbox-thumb lazy" width="2112" data-original="https://pic2.zhimg.com/v2-2551c51bd2bd3f58ee70da59b9199901_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-2551c51bd2bd3f58ee70da59b9199901_b.jpg" data-original-token="v2-17813cf760d3b389a26210f004371452"></div><figcaption>GPT 能力一览</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="O5cI0lO_">简单总结来说：</p><ul><li data-pid="aT-eOvVs">大量文本数据（万亿级别 token 数量）做预训练：语言生成能力，基础的世界知识，in context learning 的基础。</li><li data-pid="VlneAAA7">足够大的模型规模（千亿级别参数）：大量知识的记忆与获取能力。</li><li data-pid="rdPGs_6B">在代码数据上训练：复杂推理能力，长距离依赖关系的学习。这也是最令人着迷的一点。</li><li data-pid="CNCYPZZ-">有监督的指令微调：响应人类问题并泛化到没有见过的问题（zero-shot）上。减弱了 in context learning 的能力。目前从论文中看，指令微调和 RLHF 这块用到的打标数据量级并不大（十万条以内），相比自监督部分的数据量可谓是沧海一粟。</li><li data-pid="Kh-bBbAo">RLHF：总体让回答更加丰富具体，也增强了与人类期望的一致性（zero-shot，价值观，内容安全，避免胡说），但会降低模型在任务上的性能。比较有意思的是都用了 RLHF，text-003 模型也跟 ChatGPT 有不同的能力侧重，可惜目前没有论文透露其中的细节。</li></ul><p data-pid="vk1FwkSn">如果在代码数据上训练能够获取到一定的推理能力，这里就能延展出一些其它想法，例如：</p><ul><li data-pid="OdTCzTGj">是否在论文，数学类的教材文章中也能获取逻辑推理能力？</li><li data-pid="dIltrqyN">不同的编程语言对于推理能力的帮助是否会有不同，例如 Haskell，Coq 这类。</li><li data-pid="h7bGYbfC">是否还有其它形式的数据，能够对增强推理能力很有帮助？</li></ul><h3>知识的获取与修改</h3><p data-pid="njFEkFlt">不过目前 ChatGPT 类模型也是有显著局限性的，比较突出的一点是大家在试用时经常发现的，它所学习的信息来源截止于 2021 年，因此后续的信息都无法获取准确的答案。虽然我们的确可以通过 instruct 去实时地“修改”一些知识，但这个信息并不会被“持久化”。在张俊林老师的文章中，提到了很多大语言模型是如何存储和获取知识的原理，也提到了未来如何去高效修改这些知识的一些方向探索。如果我们在模型使用上已经实现了自然语言接口，那么是否能进一步去实现模型训练的自然语言接口（instruct training）呢？这或许也会是迈向通用人工智能的重要一步，当然也需要有很多安全方面的考量。</p><h3>多模态</h3><p data-pid="GvG36bK4">迈向通用人工智能，另外一个比较显而易见的目标是将这类生成式范式应用到多模态上。比如去年另外一个很火的 AIGC 领域就是以 Stable Diffusion、Dall-E 2、Midjourney 等产品为代表的文生图应用。如果我们找到了多模态上的大模型之路，或许就能实现通过自然语言给 AI 一个描述，它就能自动生成出构造零件和组装的 3D 设计图，看到这个设计图，就能自动生成出流水线/机器人的一系列动作把真实的产品构造出来。甚至 AI 可以根据需求先构建机器人，再通过这些机器人去构建各种真实世界的产品，那样的生产成本大幅下降的未来会是何等景象真是难以想象。</p><p data-pid="PgNFFQmN">像自动驾驶也是一个很典型的领域。如果仅仅从视觉来“生成”驾驶动作，难度是非常大的。而我们真实人类在开车过程中，一定是综合结合了视觉，声音，以及很多“内心独白”（语言形式的思考）作出相应的决策动作。整合多模态的输入信息会对实现相应的场景能力有很大的促进作用。</p><p data-pid="_qYOr987">但结合我们前面提到的当前大语言模型的各种范式来说，多模态的数据很多都还没找到类似的实现路径，例如文本数据我们天然可以做用前文预测后一个单词的自监督训练，但用图片/视频生成文本这类数据就显然少了很多。此外不同模态是否能很好地融合在一个模型里也是个问题，直观上来看语言显然是一个很特别的存在，而图片视频这类的数据形态，分布，信息密度上会有很大的不同。所以当前多模态模型上的尝试，比如 ALBEF，VLMo 等都需要在多模态上做很多专门的模型结构设计。当然也有一些很有意思的发现，例如在 VLMo 和 BeiTv3 里都对多模态共享了注意力层，期待未来会有更多有意思的融合统一。</p><p data-pid="bp5khlsw">另外一个值得思考的点在于，各种模态对于形成“智能”的重要性如何，更多的模态是否会有促进作用。一个比较广泛的观点是语言还是人类智能中最为特殊的载体，动物类的智能也有用，但一般我们所说的通用人工智能指向的还是能够通过图灵测试的类人智能。而且即使是那些天生没有视觉、听觉的残障人士，其能够达到的智能水平也与普通人毫无差别，那是否说明其它模态的数据没有那么重要呢？还是说残障人士实际是通过触觉等补足了这方面的能力缺陷？知乎上的这篇 <a href="https://zhuanlan.zhihu.com/p/606364639" class="internal">介绍 BLIP2 的文章</a> 中给出了一些很有趣的思路，把 LLM 作为一个非常核心的“处理器”，实现了非常惊艳的效果。后面在数据角度的讨论中我们也会再回到这个话题上。</p><h3>连接真实世界</h3><p data-pid="poJCVK01">我们在使用 ChatGPT 时很容易碰到的一个局限是它有时候会生成出错误的回答，但却言之凿凿的样子，毕竟 ChatGPT 是一个被禁锢在服务器上的模型，目前唯一与真实世界的触点都来自与用户的对话交互和反馈，可谓是“不闻窗外事”。一个很自然的改进思路就是把模型与一些已有的外部系统连接起来，例如一些知识性的问题可以借助搜索引擎来佐证（后面会提到类似技术和产品），一些理工科相关的计算推理问题可以借助 Wolfram Alpha，生成的代码可以直接在真实环境编译执行并检验效果等。</p><p data-pid="IiGqGkLp">这里有个通用的思考范式，以往我们需要去连接多个系统时，需要互相约定好比较特定的 API 格式。如果我们把语言模型当做一个输入是文本输出也是文本的“转换器”，那么这个转换器就可以与其它转换器很方便的去串联（回想一下前面提到的问题串联的玩法）。例如搜索引擎就是输入查询文本，返回网页文本的转换器，大语言模型也是输入文本（prompt），生成新的文本（回答），这两者就可以进行串联。例如用搜索引擎去搜索问题相关的文本信息，把文本信息作为背景，结合问题再给到语言模型去输出答案。甚至这个循环可以多做几步，问题 -&gt; 网页文本 -&gt; 更好的问题 -&gt; 更多的网页文本 -&gt; 多个问题同时输入到语言模型 -&gt; 再做 summary 等。未来可能就会在此基础上演化出很多领域特定的模型 pipeline 来更好的解决复杂问题，例如最近 Meta 的 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2302.04761" class=" wrap external" target="_blank" rel="nofollow noreferrer">Toolformer</a> 采用的就是类似思路。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-5772e843cff49e330fad918b9576f02b_b.jpg" data-size="normal" data-rawwidth="2558" data-rawheight="1070" class="origin_image zh-lightbox-thumb" width="2558" data-original="https://pic4.zhimg.com/v2-5772e843cff49e330fad918b9576f02b_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2558' height='1070'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2558" data-rawheight="1070" class="origin_image zh-lightbox-thumb lazy" width="2558" data-original="https://pic4.zhimg.com/v2-5772e843cff49e330fad918b9576f02b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-5772e843cff49e330fad918b9576f02b_b.jpg" data-original-token="v2-4d727ebe523cc51aa756f2666dfa9c91"></div><figcaption>斯坦福的一个工作 DSP 演示了这种思路</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="BsxgQBwV">如果从更长远来看，如果模型的输出能够直接形成外部系统的动作，后续又能将相关结果返回到模型，从而去迭代演化其知识与行为策略，那就非常接近强人工智能的终极形态了。当然我们是否要往那个方向发展是个问题，因为涉及真实世界的决策就会有更多安全方面的诉求考量。当前模型在这块的保障还很少，例如经常可以看到例子，通过一些指令引导，可以让模型给出危险的回答来。如果往那个方向发展，AI 的 reward 函数应该如何设计，是否与意识的产生相关，也都是需要深入思考的。</p><p data-pid="rxxgOvsj">结合多模态与真实世界决策问题，已经有类似的研究项目再往这个方向前进了，例如 <a href="https://link.zhihu.com/?target=https%3A//minedojo.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">MineDojo</a> 项目，搜集了各种 Minecraft 游戏相关的 YouTube 视频，Wiki 文章，Reddit 讨论，期望能训练一个模型能通过这些数据来学会如何在一个开放游戏环境中完成各种探索与任务。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-2f916cc61613b68e50b43898be17e881_b.jpg" data-size="normal" data-rawwidth="2026" data-rawheight="1000" class="origin_image zh-lightbox-thumb" width="2026" data-original="https://pic2.zhimg.com/v2-2f916cc61613b68e50b43898be17e881_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2026' height='1000'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2026" data-rawheight="1000" class="origin_image zh-lightbox-thumb lazy" width="2026" data-original="https://pic2.zhimg.com/v2-2f916cc61613b68e50b43898be17e881_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-2f916cc61613b68e50b43898be17e881_b.jpg" data-original-token="v2-5cd7790a05fe038c2aba76b1e2880e01"></div><figcaption>使用多模态数据来训练 AI 学会构建</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>思考“大力出奇迹”</h3><p data-pid="oz7Arexw">回到 GPT 这类大语言模型的诞生，我跟很多人一样，早期只是觉得这是一个大力出奇迹的产物，堆了很多数据，算力，训练出了巨大的模型，但好像没有什么特别的创新之处。但现在来看，这个结论显然是不够深入的，从前面一系列关于 AGI 路线的设想也能略窥一斑。之前在群里讨论时也有朋友提出，如果说数据和算力是最重要的因素，那么为何不是拥有最多数据和算力的大公司们，或者拥有产出最多算力基础设施的显卡厂商们搞出了 ChatGPT，而是这样一家小小的创业公司呢？</p><p data-pid="lzFp6Bsd">再深入去看这些研究人员在设计训练策略时的做法，也有很多有趣的发现。例如数据量，模型参数量和训练轮次是决定计算资源需求的几个要素，那么如何进行配比能让模型在最少资源需求的情况下达到最好的效果呢？是更多的数据更重要，还是更大的模型更重要，还是训练更多个 epoch 更重要？目前看可能最重要的还是高质量更大量的数据，并且与模型参数等形成一个比例关系来一起缩放，也就是所谓的 scaling law。</p><p data-pid="_yuqRnUw">这类大模型还有一个比较有意思的现象，就是复杂系统中经常提到的“涌现”。在模型规模较小时，发现其在很多任务上的表现基本跟瞎猜差不多，但等到模型规模突破一个阈值之后，其相关能力会大幅度地上升，突然就可以完成这类任务了。这里面一个可能的关键因素就是之前提到的 chain of thought 能力，在复杂任务的各个环节的理解能力都逐渐达到了一个水平后，整个链路才得以打通，就突然可以做复杂的推理问题（in context learning）之类了。另外人类知识体系的复杂性也导致了必须掌握大部分的知识，才能去理解一个非常细小的行为。</p><p data-pid="qaNOemg8">过去几年我的很多思路都更倾向于 data-centric AI 里那种用少量高质量的数据去构建和完善特定领域模型，大语言模型在这一点上的特质的确让我打开了视野。如果人类可以识别和处理脏数据，那么足够复杂的大模型是否也能自动处理呢？</p><p data-pid="teZx5GCN">最后，很多人会觉得巨大的模型训练，推理成本会让很多实际应用因为成本问题无法落地。这一点我倒是非常乐观，从工业革命开始技术和计算能力方面的摩尔定律基本就没有失效过。因为担心算力成本而放弃产品化探索，或者过多地把技术壁垒建立在硬件资源的节约上可能反而比较有风险。当然如果本身就是做底层基础设施的厂商，能够契合这种“指数增长”趋势的技术肯定就是巨大的优势了。这方面像稀疏化的大模型，结合 retrieval 技术等都是很有意思的研究发展方向。</p><h3>数据用尽？</h3><p data-pid="xdMFGF63">前面已经提到，当前阶段影响大模型能力的最重要的因素就是高质量的数据。目前很多语言模型已经用了整个因特网上能够获取到的 10%量级的数据了，在可见的将来很可能会出现“数据用尽”的问题。对于这一点，个人有几个方面的思考。</p><p data-pid="sz3ZTULO">首先数据的重要性很可能在一段时间内都会成为相关产品竞争之间的一个重要差异化因素（模型本身反而比较类似），因此在设计相关产品时，相应的“数据飞轮”设计需要重点考虑。这个方面也许会涌现出一些相关技术和厂商的机会来，例如专职于做人工/自动化数据生成，人类反馈数据收集的相关技术栈等。</p><p data-pid="RjYTHE1q">对于目前 ChatGPT 生成的回复信息，很多也是全新的，从未出现过的文字组合。对于这种输出，是否是一种有效的“训练数据”呢？如果不是的话，那么有人类参与的“有效训练数据”与其本质区别是什么？这也类似于问模型目前给出的回答，是不是一种“创新”？</p><p data-pid="cisviqIM">上述问题或许有些哲学意味，换一种说法，我们可以把新的信息的生成分为两类，一类是含义/事实/经验型的数据，相当于世界上发生的各种新事件。这类数据只需要以类似搜索引擎更新数据库的方式去更新模型应该就可以（现在的 prompt 也能解决一部分）。另一类则是逻辑/系统类的数据，体现的是信息之间关系的演变，例如出现了新的系统或组织，实体间的关联关系等。但后者这类信息的更新速度仅由人类来推动的话，或许是非常缓慢的。这也是为何有“太阳底下无新事”的说法存在。这种类型的信息更新，或许才是我们本质上需要去提供相关数据，增量训练模型的出发点。我们可以看到像 WebGPT、Sparrow 这类工作，以及 perplexity.ai、新版的 Bing 等产品都开始体现了 LLM 能够利用实时检索信息的能力，而不是任何的新知识都需要训练模型更新参数。</p><p data-pid="P2QTuOT-">另一个更加实际的思考也是往多模态方向演进，思考未被“文本化”的知识主要在哪。例如人类日常中有非常多的语言文字交流是以口头形式完成的，那么各种面试，会议，播客访谈，日常聊天，甚至自言自语等是否都可以记录下来，形成更多更丰富的文本资料？例如像 <a href="https://link.zhihu.com/?target=https%3A//www.rewind.ai/" class=" wrap external" target="_blank" rel="nofollow noreferrer">rewind</a> 这样的产品就已经在做一些类似形式的尝试了，说不定会成为一种趋势。</p><p data-pid="uZ8FZszl">如果大模型有了与真实世界更多的交互能力，那么新数据的生成或许也真的不再受限于人类产生数据的速度了。但这个方向也是有很大风险的。即使仅考虑文字输出，例如有些人可以通过控制一系列的 <a href="https://link.zhihu.com/?target=https%3A//github.com/yaroslav-n/tweetGPT" class=" wrap external" target="_blank" rel="nofollow noreferrer">twitter bot</a>，生成特定的社交媒体信息，达到操控舆论导向的目的。前阵子 Stack Overflow 禁止使用 ChatGPT 插件来回答问题，也是担心其产生的错误回答影响社区整体的信息质量。如果模型能做更多类型的决策，其安全风险必然更大。</p><p data-pid="Q4XY6VF8">数据安全，隐私等方面也是一个绕不过去的话题。尤其是当前的大语言模型极度依赖于数据，谁控制了训练（包括 instruct tuning 等）数据，谁就控制了模型的“价值取向”。这在模型开始得到更广泛规模的使用时就显得极为重要。虽然前面也设想了一下是否能够实现通过指令来做实时增量训练，但显然模型安全方面是个需要先考虑解决的前提条件。目前也有一些工作在往这个方向发展，例如 <a href="https://link.zhihu.com/?target=https%3A//github.com/mit-han-lab/offsite-tuning" class=" wrap external" target="_blank" rel="nofollow noreferrer">Offsite-Tuning</a> 等。</p><h3>可解释机器学习</h3><p data-pid="5n1784W5">在大语言模型的框架下，许多之前的研究都可以重新来审视和思考，这里仅以可解释机器学习来举个例子。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-2bfa8690e6d6ad1c37148b9c6198c37e_b.jpg" data-size="normal" data-rawwidth="2500" data-rawheight="1324" class="origin_image zh-lightbox-thumb" width="2500" data-original="https://pic3.zhimg.com/v2-2bfa8690e6d6ad1c37148b9c6198c37e_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2500' height='1324'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2500" data-rawheight="1324" class="origin_image zh-lightbox-thumb lazy" width="2500" data-original="https://pic3.zhimg.com/v2-2bfa8690e6d6ad1c37148b9c6198c37e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2bfa8690e6d6ad1c37148b9c6198c37e_b.jpg" data-original-token="v2-2ab631354f54eef34678bfabe312be1a"></div><figcaption>xai 的思考框架</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="kSJBltCv">上图是当前主流的 xai 的思考框架，从人和模型两方的知识范围，工作原理等角度出发，通过不同的路径去扩大两者的交集，促进沟通理解。从某种程度上来说，instruct tuning 或许也是一种新的形成可解释机器学习的方式。通过自然语言指令和多轮对话，我们可以反复确认模型给出预测背后参考的信息，推演逻辑等，这就与我们理解真实人类的想法非常接近了。在这个话题上是否还需要去了解人工神经网络的底层原理和特性可能就不那么重要了。</p><h3>AGI 随想</h3><p data-pid="hpMMbVYp">前面已经提到了很多跟通用人工智能相关的思考与遐想，例如从监督学习，到模仿学习再到强化学习的路线；通过自然语言接口，连接真实环境来达到“知行合一”的独立智能体；通过多模态的数据去增强语言模型的信息交互和“涌现”能力，实现逻辑推理，完成复杂任务等等。不过在强人工智能方向，一个绕不过去的话题是机器能否有意识，或者说我们是否要去创造意识？人类在思考与决策上的很多“缺陷”（如《思考，快与慢》中提到的那些），是不是也有不少是由意识和情感这些因素产生的。如果我们想构建一种与我们互补的“工作伙伴”，或许意识并不是必需的。但如果我们想要让这类智能体在宇宙中去延续人类文明，那么意识可能就比较关键了（还要防止自我毁灭）。</p><p data-pid="MDAmkcyI">另外前面提到的一个设想，如果通用智能后续能够自行完成物品的生产建造，甚至连机器人也都是自动化建造出来的，那么整个社会的商品成本都会极大下降。如果我们把想象更进一步，ChatGPT 是否学习过自己的代码？它能否通过当前模型在世界上的反馈表现去自动更新这部分的代码并不断迭代，甚至为自己创造出更利于自我生存的“意识”来？这是否会跟人类修改基因一样，也涉及到“机器人伦理”问题？:)</p><hr><p data-pid="RrOSEevV">本系列的后续文章：</p><div class="RichText-LinkCardContainer"><a target="_blank" href="https://zhuanlan.zhihu.com/p/607127757" data-draft-node="block" data-draft-type="link-card" data-text="字节：迈向 ChatGPT 时代 - 商业篇" class="LinkCard new css-1r0wf39" data-image="https://pic1.zhimg.com/v2-788bf5fa9e7577286afe6102ced5eaec_180x120.jpg" data-image-width="3072" data-image-height="2048"><span class="LinkCard-contents"><span class="LinkCard-title loading" data-text="true"></span><span class="LinkCard-desc loading"></span></span><span class="LinkCard-image LinkCard-image--default"></span></a></div><p></p></div></div></div></div><div class="Post-ReadMark"></div><div role="button" tabindex="0" class="ContentItem-time">编辑于 2023-02-21 10:00<!-- -->・IP 属地浙江</div></article><div class="Post-Sub Post-Sub-Mobile"><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><img class="Avatar css-1any501" src="https://pica.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b" srcset="https://pica.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b 2x" alt="RandomGenerator"></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span>RandomGenerator</span></h2></div></div></div></ul></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 390px; bottom: 0px; left: 16px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;608075096&quot;}}}"><span><button aria-label="赞同 71 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></span>赞同 71</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down VoteButton--mobileDown"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleDown" fill="currentColor"><path fill-rule="evenodd" d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023Z" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Comment Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span>5 条评论</button><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 0 0 .165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 0 0-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 0 0-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 0 0-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 0 0 .164-.12l2.378-4.122Z"></path></svg></span></button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover1-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover1-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Dots Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></span></button></div></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px; height: 54px;"></div></div></div></div></main></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fapi\u002F","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","allowSignUp":true,"refreshValidityPeriod":"30","release":"824-bcf32e16","currentEntry":"column","isMobileEntry":false,"apollo":{"env":"prod","globalSilence":"","ncgModeSign":"3f8e56febda4fb3bbea72e379d76de1e","topstory_rec_adp":"1","test_canary":"member|0-100,1-0","use_new_player":"member|0-0,1-100","player_vendor":"member|0-0,1-100,2-0","use_hevc":"member|0-0,1-100","upload_use_signature":"member|0-0,1-100","use_backdrop_blur":"member|0-0,1-100","article_title_imagex":"member|0-50,1-50","play_station":"member|0-0,1-100"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"entities":{"users":{"zijie0":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"608075096":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGJ-QhvjYHlDBQ==&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"entityWords":[{"name":"reward model","mention":"reward model","matchorder":1,"begin":4411,"end":4423,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJZCgxyZXdhcmQgbW9kZWwSCU90aGVyVGVybRi7IiDHIigBNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"zero-shot","mention":"zero-shot","matchorder":1,"begin":2828,"end":2837,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJWCgl6ZXJvLXNob3QSCU90aGVyVGVybRiMFiCVFigBNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"大语言模型","mention":"大语言模型","matchorder":1,"begin":1458,"end":1463,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJcCg\u002FlpKfor63oqIDmqKHlnosSCU90aGVyVGVybRiyCyC3CygBNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"prompt engineering","mention":"prompt engineering","matchorder":1,"begin":1674,"end":1692,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJfChJwcm9tcHQgZW5naW5lZXJpbmcSCU90aGVyVGVybRiKDSCcDSgBNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"张俊林","mention":"张俊林","matchorder":1,"begin":960,"end":963,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Person","score":0,"attachedInfoBytes":"sgJTCgnlvKDkv4rmnpcSBlBlcnNvbhjAByDDBygBNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"图灵测试","mention":"图灵测试","matchorder":1,"begin":11761,"end":11765,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzlm77ngbXmtYvor5USB1Vua25vd24Y8Vsg9VsoATUAAAAAOgdhcnRpY2xlQABIAFIkNzQ5ZDI4ZDEtMjRjZi00NmRkLWFmMjgtNWM5MjI4MDYyNjlk","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"fine tune","mention":"fine tune","matchorder":3,"begin":1660,"end":1669,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJWCglmaW5lIHR1bmUSCU90aGVyVGVybRj8DCCFDSgDNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"reward signal","mention":"reward signal","matchorder":1,"begin":4997,"end":5010,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJaCg1yZXdhcmQgc2lnbmFsEglPdGhlclRlcm0YhScgkicoATUAAAAAOgdhcnRpY2xlQABIAFIkNzQ5ZDI4ZDEtMjRjZi00NmRkLWFmMjgtNWM5MjI4MDYyNjlk","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"预训练模型","mention":"预训练模型","matchorder":2,"begin":1619,"end":1624,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJcCg\u002FpooTorq3nu4PmqKHlnosSCU90aGVyVGVybRjTDCDYDCgCNQAAAAA6B2FydGljbGVAAEgAUiQ3NDlkMjhkMS0yNGNmLTQ2ZGQtYWYyOC01YzkyMjgwNjI2OWQ=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"few-shot","mention":"few-shot","matchorder":1,"begin":5811,"end":5819,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJVCghmZXctc2hvdBIJT3RoZXJUZXJtGLMtILstKAE1AAAAADoHYXJ0aWNsZUAASABSJDc0OWQyOGQxLTI0Y2YtNDZkZC1hZjI4LTVjOTIyODA2MjY5ZA==","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"自回归模型","mention":"自回归模型","matchorder":1,"begin":2539,"end":2544,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Math","score":0,"attachedInfoBytes":"sgJXCg\u002Foh6rlm57lvZLmqKHlnosSBE1hdGgY6xMg8BMoATUAAAAAOgdhcnRpY2xlQABIAFIkNzQ5ZDI4ZDEtMjRjZi00NmRkLWFmMjgtNWM5MjI4MDYyNjlk","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""}],"id":608075096,"title":"迈向 ChatGPT 时代 - 技术篇","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F608075096","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2270f46df05a45d27c520dc784ac336d_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-2270f46df05a45d27c520dc784ac336d_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7ad04a63e50415484e8976f12b9c0675_200x112.png\" data-caption=\"Instruct Tuning 的效果\" data-size=\"normal\" data-rawwidth=\"1796\" data-rawheight=\"1118\" data-watermark=\"watermark\" data-original-src=\"v2-7ad04a63e50415484e8976f12b9c0675\" data-watermark-src=\"v2-d3b1b81f60c3fdbf4267c2d6e0d95ca7\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7ad04a63e50415484e8976f12b9c0675_r.png\"\u002F\u003E最近关于 AIGC，ChatGPT 等方面的消息和文章非常多，无论是从没了解过机器学习的圈外人士，还是每天跟模型打交道的专业从业者，都无不被 ChatGPT 的能力震惊。几年后来回顾这个事件，应该会成为通向通用人工智能\u002F技术奇点的一个关键里程碑。这两个月我也不…","created":1676942860,"updated":1676944819,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","ipInfo":"IP 属地浙江","imageWidth":3072,"imageHeight":2048,"content":"\u003Cp data-pid=\"n9g-OzYs\"\u003E最近关于 AIGC，ChatGPT 等方面的消息和文章非常多，无论是从没了解过机器学习的圈外人士，还是每天跟模型打交道的专业从业者，都无不被 ChatGPT 的能力震惊。几年后来回顾这个事件，应该会成为通向通用人工智能\u002F技术奇点的一个关键里程碑。这两个月我也不能免俗刷了很多相关文章和视频，过程中发现了不少颠覆我原有认知的信息。这篇文章主要是站在“巨人们的肩膀上”，从各个角度来聊聊我的收获和一些思考。\u003C\u002Fp\u003E\u003Cp data-pid=\"I-nGbiwd\"\u003E这也是我第一次尝试付费文章的形式，看看接受度如何 :) 本文的内容大致会分成技术，商业化和提升个人生产力三个角度来展开，每个部分主要内容都是个人的 key takeaways 和思考，同时把我目前看到的比较好的参考文章列出来。非常欢迎有不同想法的同学来一起探讨。从受众角度，应该比较适合：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli data-pid=\"bDVOfoYF\"\u003EAI 领域从业者，想了解 LLM 和 AGI 的最新进展以及对自己工作的影响。但不太适合那种已经看了几十篇 LLM 领域论文的专业大佬，那样的话我这边写的内容应该你都很熟悉了。\u003C\u002Fli\u003E\u003Cli data-pid=\"WM2lCY6u\"\u003E平时用 Google，知乎等网站比较多的知识型工作者（尤其是软件工程师），对于 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F366187306\" class=\"internal\"\u003E生产力工具\u003C\u002Fa\u003E 非常感兴趣的同学，这篇文章应该也会比较合你胃口。\u003C\u002Fli\u003E\u003Cli data-pid=\"sv0BFUVR\"\u003E有创业或者相关领域投资方面想法的同学，但这方面的不确定性很强，个人见解仅供参考。\u003C\u002Fli\u003E\u003Cli data-pid=\"d4IS54Ms\"\u003E想了解通用人工智能对我们的工作，学习，生活的各种影响的其他同学，如果你不缺这几块钱的话 :)\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp data-pid=\"6qiMMUhU\"\u003E好了，话不多说，先让我们来看下 ChatGPT 背后的神奇技术与 OpenAI 的远大 vision。\u003C\u002Fp\u003E\u003Ch2\u003E技术\u003C\u002Fh2\u003E\u003Cp data-pid=\"mbrayNGu\"\u003E这部分先推荐一篇来自张俊林老师的文章 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F597586623\" class=\"internal\"\u003E通向 AGI 之路：大型语言模型（LLM）技术精要\u003C\u002Fa\u003E。一般来说，张老师如果在某个领域写了篇文章，在很长一段时间里我都不会考虑单独写这个话题了，贡献非常有限 。这部分会快速列举一些我之前不知道的或者令人意外的信息和思考角度。\u003C\u002Fp\u003E\u003Ch3\u003E新范式：生成一切\u003C\u002Fh3\u003E\u003Cp data-pid=\"2fupdprX\"\u003E如果去读一些经典的机器学习教材，我们会发现大多数的算法建模任务都是以“输入信息，输出判别”的形式来思考的。例如给定一句话，希望模型来判断这句话表达的是正面还是负面的情感，这就是一个经典的分类问题。而在 NLP 中，又有很多“生成”性质的问题。例如提一个问题，希望模型给出答案。这种任务上的多样性，导致以往我们需要针对每一个任务来分别设计数据收集，模型训练流程，很难进行复用。当年 BERT 模型推出时，令我印象最深刻的也是它对于多任务统一的巧妙设计。\u003C\u002Fp\u003E\u003Cp data-pid=\"fNM5Znqr\"\u003E但到了以 GPT 为代表的大语言模型阶段，一个显著的思维方式变化是我们其实可以通过“生成”来解决一切问题。例如还是上面的情感分类问题，我们可以直接把语句输入给模型，并提问“这句话表达的是正面还是负面的情绪”，然后让模型对于上面的一整串输入，去生成一个输出回答。这样无论是分类，回归，还是生成类任务，都可以统一到一种框架下来实现了，也就可以使用统一的预训练模型来处理，非常优雅。这个生成一切的思维转变，也影响到了后面我们会提到的从 fine tune 思路到 prompt engineering 的思维转变等。\u003C\u002Fp\u003E\u003Cp data-pid=\"3bJhExuv\"\u003E回过头来看，生成式的范式的确是很自然的想法，但在大多数领域我们目前都还做不到这点。比如我们能否输入一连串历史天气信息，让模型自动去生成未来几天的天气预报；输入用户的历史浏览、购物信息，生成出可能感兴趣的商品；输入一张图片，生成出图片中的物体名称及位置信息等等。如果这些任务都能以生成式的方式去做，或许未来能进一步形成多模态的预训练模型，解决更多领域的实际问题。\u003C\u002Fp\u003E\u003Ch3\u003E自监督\u003C\u002Fh3\u003E\u003Cp data-pid=\"2X02y_Vo\"\u003EGPT 背后的模型原理出奇的简单，就是通过一系列输入文本，去预测后面会出现的文本是什么。大佬 Andrej Karpathy 在这个视频里 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.bilibili.com\u002Fvideo\u002FBV1E14y1M75n\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E手把手教你如何从头实现 GPT\u003C\u002Fa\u003E，如果对实现细节感兴趣的同学可以参考。这种自监督的模式使得我们能以较低成本获取海量的训练数据，例如 Wikipedia，出版书籍，新闻，各种公开 blog，Stack Overflow，GitHub 等等。而前面提到的一些其他类型的如图像\u002F视频理解之类的问题，我们就比较难获取类似数量和质量的训练数据了。\u003C\u002Fp\u003E\u003Cp data-pid=\"fh1P-nzp\"\u003E当然也正是由于 GPT 背后的思想如此的简单，很多人（包括我在内）在一开始都觉得深度学习的本质并没有什么突破，仍然是在一堆数据中去拟合一个概率分布，后续在“生成”时做个采样而已。像各种知识概念，逻辑推理等，都是无法从当前的技术路线中产生的，需要融合像知识图谱，符号推理等手段才行。但在用过 ChatGPT 之后，相信大多数人都开始觉得这种简单的自回归模型或许真的能够带我们在通用人工智能的这条路上走得很远。\u003C\u002Fp\u003E\u003Ch3\u003E遵循自然语言指令\u003C\u002Fh3\u003E\u003Cp data-pid=\"czNYS-ck\"\u003E沿着生成一切的思路，一个自然的想法就是让模型能够“听懂”人类的指令，并做出期望的反馈回答。OpenAI 和 Google 都在这个方向上做了不少研究工作，略过技术细节，这些研究的目标是能够达到：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"VbQlCNiy\"\u003E让模型理解用户的意图是什么，而不只是简简单单做文本的“续写”输出。\u003C\u002Fli\u003E\u003Cli data-pid=\"7kjc1Yzg\"\u003E对于模型没有见过的问题，也能很好地理解与回答（zero-shot）。\u003C\u002Fli\u003E\u003Cli data-pid=\"xeUQ6Ety\"\u003E符合人类的价值观，例如输出的内容中应该遵循事实，语气友好，减少“有害”内容等。这一点 ChatGPT 做得格外好，很多人都觉得这是一个可以让自己孩子与之交谈学习的聊天机器人。很多其它大厂产品在这块都受到了很大的挑战。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"biXROq3t\"\u003E具体可以参考 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fopenai.com\u002Fblog\u002Finstruction-following\u002F%23moon\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EOpenAI 这篇文章中的一些例子\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_b.jpg\" data-size=\"normal\" data-rawwidth=\"1796\" data-rawheight=\"1118\" class=\"origin_image zh-lightbox-thumb\" width=\"1796\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1796&#39; height=&#39;1118&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1796\" data-rawheight=\"1118\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1796\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d3b1b81f60c3fdbf4267c2d6e0d95ca7_b.jpg\" data-original-token=\"v2-7ad04a63e50415484e8976f12b9c0675\"\u002F\u003E\u003Cfigcaption\u003EInstruct Tuning 的效果\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"wiRNsY_b\"\u003E打一个不太精确的比方，只用自监督训练形成的大语言模型相当于把互联网上所有的高质量文本信息都看了一遍，拥有了大量的知识，并且可以模仿人类的方式来续写文本，但它从来没有跟真实的人交互过，因此也无法理解人类的交互意图。通过人类指令和期望回答方面的学习，模型在“续写”能力上增加了“理解力”，从而成为一个真正可用的多任务通用模型。\u003C\u002Fp\u003E\u003Ch3\u003E强化学习\u003C\u002Fh3\u003E\u003Cp data-pid=\"p4fy6SsM\"\u003E在做上述的人类指令学习方面，InstructGPT\u002FChatGPT 引入了人工标注与强化学习技术（RLHF）。从技术细节上来看，有几个比较有意思的点可以讨论。\u003C\u002Fp\u003E\u003Cp data-pid=\"yM-2OLRc\"\u003E如果让你来做人类指令的学习，你会怎么实现呢？一个最直观的思路肯定是给定一些问题，然后由人工来撰写回答，将这部分数据作为监督学习的样本放到模型中去训练。从 ChatGPT 的模型使用方式来看，也并不是像下棋一样跟人对弈，没有像典型的强化学习那样有“根据环境改变策略”的操作。所以很多人应该跟我一样，都觉得这里其实不用强化学习也可以达到类似的效果。\u003C\u002Fp\u003E\u003Cp data-pid=\"4oaM_J-S\"\u003E但后来仔细看了一下他们做 RLHF 的过程，发现有几个相对于直接做有监督 tuning 的提升的可能出发点：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"sFq8L8q6\"\u003E直接写问题的答案，相比来说对于人工标记员的水平要求和时间开销可能更高，学习到的指令理解可能也更偏向于标记人员的取向。而如果让标记员对模型生成的若干个回答做从好到坏的排序相对来说更容易一些，形成的 reward model 有更高的复用性，大大提升效率。\u003C\u002Fli\u003E\u003Cli data-pid=\"phjB0G93\"\u003E对于排序信息的利用也有一些小 trick，相当于做了一定的数据增强。这部分论文里有很详细的描述，包括怎么招标记团队等，几乎可以直接拿来使用。\u003C\u002Fli\u003E\u003Cli data-pid=\"mdzljlTg\"\u003E他们在强化学习的 loss 中做了一些特殊设计，使得模型能符合人类预期，同时在 in context learning 和模型任务上不会损失太多性能。不过这一点应该在有监督中也可以做到，不知道具体效果有多大差别。\u003C\u002Fli\u003E\u003Cli data-pid=\"gOzlR7Ud\"\u003E强化学习的流程更符合产品人机交互的形态，便于后续迭代。例如当前 ChatGPT 输出的回答，我们是可以提供正面或者负面反馈的，这些信息就相当于在给模型输出做排序，后面可以继续用在同样的框架里优化模型。这一点对于产品化来说非常重要，当前一亿的用户量能够提供的反馈数据量绝对是一大产品壁垒。\u003C\u002Fli\u003E\u003Cli data-pid=\"wiHGzLzt\"\u003E强化学习作为通用范式，未来有更大的想象空间，把在时间维度上做连续决策的能力也用上。例如聊天过程中为了更好地达成用户满意度（可以灵活选择 objective）的目标，可以先主动询问和澄清问题，再去做回答；模型生成的代码也可以在真实环境去运行，生成 reward signal，继续优化 reward 模型和 policy 模型。这与 OpenAI 发展通用人工智能的设想是高度一致的。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"GaSEPckF\"\u003E所以总结来看，这里并不只是为了炫技而使用强化学习，而是有其背后深层的设计考量的。从自回归的“模仿学习”再到与真实环境交互的“强化学习”，或许就是 OpenAI 对于 AGI 的整体路线设计。\u003C\u002Fp\u003E\u003Ch3\u003E从“微调”到“提示词”优化\u003C\u002Fh3\u003E\u003Cp data-pid=\"jffWeY0P\"\u003E前面提到的让模型遵循自然语言指令，极大地改变了我们使用模型的方式。以往的常见思路是我们一般会有一个基于公开数据训练的模型，然后针对于特定领域的任务，我们再收集一波“领域专用”数据，然后做一下模型微调（fine tune）。就有点像我们有了一个各方面能力还过得去的普通人，然后训练它一下，让它更擅长做某种具体的任务（医学诊断，气象云图分析，自动驾驶之类）。这个思路看起来很美好，但也会碰到很多挑战：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"P_g92IRt\"\u003E领域的新数据持续产生，需要持续的微调与部署，有较大计算成本。\u003C\u002Fli\u003E\u003Cli data-pid=\"yIi_E11u\"\u003E微调本身改变了模型参数，可能导致“灾难性遗忘”。事实上 InstructGPT 就在提升理解能力的基础上，损失了一些任务的性能，被称为“对齐税”。\u003C\u002Fli\u003E\u003Cli data-pid=\"xwtW7_K_\"\u003E过程中模型性能会持续下降，等到下一次微调再提升回来，有一定的滞后性。\u003C\u002Fli\u003E\u003Cli data-pid=\"lWqaw7TM\"\u003E微调数据可能与原有训练数据的分布差别较大，导致模型的泛化性降低。这也不太像人类的工作方式 :)\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"3bwELODv\"\u003E所以在 OpenAI 的一系列工作中，都非常突出 zero-shot\u002Ffew-shot 方向的能力优化。简单来说，就是在碰到一个新领域的问题时，我是否可以不微调模型，而是改变一下我问问题的方式，就能让模型做出比较好的回答。Zero-shot，指的是我完全不给任何任务相关的例子，就希望模型来回答，有时候也被称为 prompt\u002Finstruct 的设计\u002F调优。Few-shot，则是我在问题中给出几个例子，然后再让模型来回答，有时候也被称为 in context learning。但不管怎么说，这个思路都是令人震撼的，相当于我没有改变任何模型的参数，仅仅通过不同的提问方式，就能让它知道应该怎么回答。\u003C\u002Fp\u003E\u003Ch3\u003E“问一个好的问题”\u003C\u002Fh3\u003E\u003Cp data-pid=\"vtXyLP2N\"\u003E知道答案不重要，能问出好的问题才是核心能力。这句话放在当前的大语言模型上真是再合适不过了。这里有非常多神奇的现象，我们分别来看一下。\u003C\u002Fp\u003E\u003Ch3\u003EChain of Thought\u003C\u002Fh3\u003E\u003Cp data-pid=\"9ff4EIpa\"\u003E人们在使用 GPT 这类模型中发现，一个原始的问题，模型可能没法正确回答，但是只要在提问中加一句“让我们一步一步来思考”，或者对于给出样例的问题中，同时给出一些推理过程，那么模型就能大幅度提升回答的准确率。第一次看到这个发现，我相信很多人脑海里都会出现一堆“黑人问号”的表情……看起来模型已经拥有了强大的推理能力。\u003C\u002Fp\u003E\u003Ch3\u003EFew-shot Prompt\u003C\u002Fh3\u003E\u003Cp data-pid=\"shqYTqxt\"\u003E在一些模型没有见过的任务上，我们可以给出一些样例，比如我们在做新产品的头脑风暴，可以描述一下大概想要的几种创意，然后让模型来生成更多。这里比较有意思的在于，假设我们举的例子是一系列 f(x) = y 的数据对，这个 y 的值是否准确并不重要，而只要 y 的总体分布符合真实分布就可以。这跟两个真实的人交谈很像，“我举个例子”，这个例子只要形式上正确就行，具体数值是否精确并不妨碍另外一个人对 context 的理解。\u003C\u002Fp\u003E\u003Cp data-pid=\"Pnw3snOB\"\u003E这一点可以说与传统的 fine tune 的思维发生了巨大的转变，我们现在完全可以向一个固定的模型去提问，在问题中包含一些“训练样本”，模型就能在不改变 weights 的情况下，实时学习到这些内容，并产生我们想要的输出。简单来说就是，amazing！\u003C\u002Fp\u003E\u003Cp data-pid=\"NQccZ1sP\"\u003E从技术角度分析，这篇 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2212.10559\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EWhy Can GPT Learn In-Context?\u003C\u002Fa\u003E 文章给出了一个很有意思的解释，in context learning 可以等价于在做一个少量样本的 fine tune。\u003C\u002Fp\u003E\u003Ch3\u003E复杂的组合应用\u003C\u002Fh3\u003E\u003Cp data-pid=\"IpXRFvmR\"\u003E我们可以进一步把问问题串联起来，完成复杂任务。比如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"UAR-syWc\"\u003E可以给模型一些样例，让它来生成问题指令（soft prompting），然后再以这个问题去问模型。\u003C\u002Fli\u003E\u003Cli data-pid=\"Z1FwuL8b\"\u003E可以对一个问题提供多种思路，分别来问模型，最后再集成起来让模型自己做个总结之类。\u003C\u002Fli\u003E\u003Cli data-pid=\"Tc2XQKJn\"\u003E可以把模型的回答再输入给模型，问它“你觉得上面的回答是否不够友好\u002F含有歧视，是否可以改进”等，进而提升模型的安全性。\u003C\u002Fli\u003E\u003Cli data-pid=\"ub8oBeJi\"\u003E可以把一个问题拆解成多个子问题，一个一个问，然后再把问题和回答作为 context，组合起来问最终的问题，实现分而治之。\u003C\u002Fli\u003E\u003Cli data-pid=\"0GchYO0G\"\u003E还有像 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2212.10560\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ESelf-Instruct\u003C\u002Fa\u003E 这样的应用，让模型自己来生成数据“训练”自己！\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-4b8f9118dfc992439cfb11ad9e102615_b.jpg\" data-size=\"normal\" data-rawwidth=\"2130\" data-rawheight=\"958\" class=\"origin_image zh-lightbox-thumb\" width=\"2130\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-4b8f9118dfc992439cfb11ad9e102615_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2130&#39; height=&#39;958&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2130\" data-rawheight=\"958\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2130\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-4b8f9118dfc992439cfb11ad9e102615_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-4b8f9118dfc992439cfb11ad9e102615_b.jpg\" data-original-token=\"v2-209d6f5701a38c2863d0d4c36367755d\"\u002F\u003E\u003Cfigcaption\u003ESelf-Instruct 流程\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E激发模型能力\u003C\u002Fh3\u003E\u003Cp data-pid=\"c18-Of6g\"\u003E从上面这些例子可以看出，大语言模型拥有非常类似于人的思维能力，只是需要通过正确的指令来进行激发。就如前面所说，模型已经学习了互联网上的所有文本，具有了非常丰富的知识和潜在的推理能力（后续会详细解释）。但这个模型是没有与真实世界的感知连接的。比如真实的两个人在交谈时，现在的时间，地点，环境等等情境信息，我们都是可以通过真实的感知获得的，因此在对话中双方都有这部分的预设信息。而对于模型来说，简单的一个问题可能并没有办法让它理解当前的情境和提问者的意图，是想让我做创意想象，还是做逻辑推理，还是查询事实知识等。这些信息都依赖于指令本身来提供，而好的指令能够激发模型，选择其相应的“记忆”与“能力”，完成具体任务。\u003C\u002Fp\u003E\u003Cp data-pid=\"iSxPNGHl\"\u003E更通俗来说，即使是同一件事情，我们在做工作汇报时的思维与表达方式，和跟同事吃饭时闲聊的描述的方式，都会有很大的不同。对于模型来说更是如此。因此详细的问题情境描述能够把让模型把特定的“思考方式”调用出来，实现能力的激发。这也是神奇的 in context learning 的一种直观理解方式。\u003C\u002Fp\u003E\u003Ch3\u003EChatGPT 的能力从何而来\u003C\u002Fh3\u003E\u003Cp data-pid=\"fq1HFxKY\"\u003E对于上述提到的 ChatGPT 的神奇能力，大家应该都很好奇到底是从何而来。好像不需要知识图谱，符号主义的那套方法，模型也能记住各种知识和它们之间的关联，并做一些简单的逻辑推理。这里有一篇非常好的文章，推断了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fyaofu.notion.site\u002FHow-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1%23c45fd4df87a349028ade2d9dbeb1188f\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EGPT 系列模型中各种能力的来源\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2551c51bd2bd3f58ee70da59b9199901_b.jpg\" data-size=\"normal\" data-rawwidth=\"2112\" data-rawheight=\"1886\" class=\"origin_image zh-lightbox-thumb\" width=\"2112\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2551c51bd2bd3f58ee70da59b9199901_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2112&#39; height=&#39;1886&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2112\" data-rawheight=\"1886\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2112\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2551c51bd2bd3f58ee70da59b9199901_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2551c51bd2bd3f58ee70da59b9199901_b.jpg\" data-original-token=\"v2-17813cf760d3b389a26210f004371452\"\u002F\u003E\u003Cfigcaption\u003EGPT 能力一览\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"O5cI0lO_\"\u003E简单总结来说：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"aT-eOvVs\"\u003E大量文本数据（万亿级别 token 数量）做预训练：语言生成能力，基础的世界知识，in context learning 的基础。\u003C\u002Fli\u003E\u003Cli data-pid=\"VlneAAA7\"\u003E足够大的模型规模（千亿级别参数）：大量知识的记忆与获取能力。\u003C\u002Fli\u003E\u003Cli data-pid=\"rdPGs_6B\"\u003E在代码数据上训练：复杂推理能力，长距离依赖关系的学习。这也是最令人着迷的一点。\u003C\u002Fli\u003E\u003Cli data-pid=\"CNCYPZZ-\"\u003E有监督的指令微调：响应人类问题并泛化到没有见过的问题（zero-shot）上。减弱了 in context learning 的能力。目前从论文中看，指令微调和 RLHF 这块用到的打标数据量级并不大（十万条以内），相比自监督部分的数据量可谓是沧海一粟。\u003C\u002Fli\u003E\u003Cli data-pid=\"Kh-bBbAo\"\u003ERLHF：总体让回答更加丰富具体，也增强了与人类期望的一致性（zero-shot，价值观，内容安全，避免胡说），但会降低模型在任务上的性能。比较有意思的是都用了 RLHF，text-003 模型也跟 ChatGPT 有不同的能力侧重，可惜目前没有论文透露其中的细节。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"vk1FwkSn\"\u003E如果在代码数据上训练能够获取到一定的推理能力，这里就能延展出一些其它想法，例如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"OdTCzTGj\"\u003E是否在论文，数学类的教材文章中也能获取逻辑推理能力？\u003C\u002Fli\u003E\u003Cli data-pid=\"dIltrqyN\"\u003E不同的编程语言对于推理能力的帮助是否会有不同，例如 Haskell，Coq 这类。\u003C\u002Fli\u003E\u003Cli data-pid=\"h7bGYbfC\"\u003E是否还有其它形式的数据，能够对增强推理能力很有帮助？\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch3\u003E知识的获取与修改\u003C\u002Fh3\u003E\u003Cp data-pid=\"njFEkFlt\"\u003E不过目前 ChatGPT 类模型也是有显著局限性的，比较突出的一点是大家在试用时经常发现的，它所学习的信息来源截止于 2021 年，因此后续的信息都无法获取准确的答案。虽然我们的确可以通过 instruct 去实时地“修改”一些知识，但这个信息并不会被“持久化”。在张俊林老师的文章中，提到了很多大语言模型是如何存储和获取知识的原理，也提到了未来如何去高效修改这些知识的一些方向探索。如果我们在模型使用上已经实现了自然语言接口，那么是否能进一步去实现模型训练的自然语言接口（instruct training）呢？这或许也会是迈向通用人工智能的重要一步，当然也需要有很多安全方面的考量。\u003C\u002Fp\u003E\u003Ch3\u003E多模态\u003C\u002Fh3\u003E\u003Cp data-pid=\"GvG36bK4\"\u003E迈向通用人工智能，另外一个比较显而易见的目标是将这类生成式范式应用到多模态上。比如去年另外一个很火的 AIGC 领域就是以 Stable Diffusion、Dall-E 2、Midjourney 等产品为代表的文生图应用。如果我们找到了多模态上的大模型之路，或许就能实现通过自然语言给 AI 一个描述，它就能自动生成出构造零件和组装的 3D 设计图，看到这个设计图，就能自动生成出流水线\u002F机器人的一系列动作把真实的产品构造出来。甚至 AI 可以根据需求先构建机器人，再通过这些机器人去构建各种真实世界的产品，那样的生产成本大幅下降的未来会是何等景象真是难以想象。\u003C\u002Fp\u003E\u003Cp data-pid=\"PgNFFQmN\"\u003E像自动驾驶也是一个很典型的领域。如果仅仅从视觉来“生成”驾驶动作，难度是非常大的。而我们真实人类在开车过程中，一定是综合结合了视觉，声音，以及很多“内心独白”（语言形式的思考）作出相应的决策动作。整合多模态的输入信息会对实现相应的场景能力有很大的促进作用。\u003C\u002Fp\u003E\u003Cp data-pid=\"_qYOr987\"\u003E但结合我们前面提到的当前大语言模型的各种范式来说，多模态的数据很多都还没找到类似的实现路径，例如文本数据我们天然可以做用前文预测后一个单词的自监督训练，但用图片\u002F视频生成文本这类数据就显然少了很多。此外不同模态是否能很好地融合在一个模型里也是个问题，直观上来看语言显然是一个很特别的存在，而图片视频这类的数据形态，分布，信息密度上会有很大的不同。所以当前多模态模型上的尝试，比如 ALBEF，VLMo 等都需要在多模态上做很多专门的模型结构设计。当然也有一些很有意思的发现，例如在 VLMo 和 BeiTv3 里都对多模态共享了注意力层，期待未来会有更多有意思的融合统一。\u003C\u002Fp\u003E\u003Cp data-pid=\"bp5khlsw\"\u003E另外一个值得思考的点在于，各种模态对于形成“智能”的重要性如何，更多的模态是否会有促进作用。一个比较广泛的观点是语言还是人类智能中最为特殊的载体，动物类的智能也有用，但一般我们所说的通用人工智能指向的还是能够通过图灵测试的类人智能。而且即使是那些天生没有视觉、听觉的残障人士，其能够达到的智能水平也与普通人毫无差别，那是否说明其它模态的数据没有那么重要呢？还是说残障人士实际是通过触觉等补足了这方面的能力缺陷？知乎上的这篇 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F606364639\" class=\"internal\"\u003E介绍 BLIP2 的文章\u003C\u002Fa\u003E 中给出了一些很有趣的思路，把 LLM 作为一个非常核心的“处理器”，实现了非常惊艳的效果。后面在数据角度的讨论中我们也会再回到这个话题上。\u003C\u002Fp\u003E\u003Ch3\u003E连接真实世界\u003C\u002Fh3\u003E\u003Cp data-pid=\"poJCVK01\"\u003E我们在使用 ChatGPT 时很容易碰到的一个局限是它有时候会生成出错误的回答，但却言之凿凿的样子，毕竟 ChatGPT 是一个被禁锢在服务器上的模型，目前唯一与真实世界的触点都来自与用户的对话交互和反馈，可谓是“不闻窗外事”。一个很自然的改进思路就是把模型与一些已有的外部系统连接起来，例如一些知识性的问题可以借助搜索引擎来佐证（后面会提到类似技术和产品），一些理工科相关的计算推理问题可以借助 Wolfram Alpha，生成的代码可以直接在真实环境编译执行并检验效果等。\u003C\u002Fp\u003E\u003Cp data-pid=\"IiGqGkLp\"\u003E这里有个通用的思考范式，以往我们需要去连接多个系统时，需要互相约定好比较特定的 API 格式。如果我们把语言模型当做一个输入是文本输出也是文本的“转换器”，那么这个转换器就可以与其它转换器很方便的去串联（回想一下前面提到的问题串联的玩法）。例如搜索引擎就是输入查询文本，返回网页文本的转换器，大语言模型也是输入文本（prompt），生成新的文本（回答），这两者就可以进行串联。例如用搜索引擎去搜索问题相关的文本信息，把文本信息作为背景，结合问题再给到语言模型去输出答案。甚至这个循环可以多做几步，问题 -&gt; 网页文本 -&gt; 更好的问题 -&gt; 更多的网页文本 -&gt; 多个问题同时输入到语言模型 -&gt; 再做 summary 等。未来可能就会在此基础上演化出很多领域特定的模型 pipeline 来更好的解决复杂问题，例如最近 Meta 的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2302.04761\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EToolformer\u003C\u002Fa\u003E 采用的就是类似思路。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5772e843cff49e330fad918b9576f02b_b.jpg\" data-size=\"normal\" data-rawwidth=\"2558\" data-rawheight=\"1070\" class=\"origin_image zh-lightbox-thumb\" width=\"2558\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5772e843cff49e330fad918b9576f02b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2558&#39; height=&#39;1070&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2558\" data-rawheight=\"1070\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2558\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5772e843cff49e330fad918b9576f02b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5772e843cff49e330fad918b9576f02b_b.jpg\" data-original-token=\"v2-4d727ebe523cc51aa756f2666dfa9c91\"\u002F\u003E\u003Cfigcaption\u003E斯坦福的一个工作 DSP 演示了这种思路\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"BsxgQBwV\"\u003E如果从更长远来看，如果模型的输出能够直接形成外部系统的动作，后续又能将相关结果返回到模型，从而去迭代演化其知识与行为策略，那就非常接近强人工智能的终极形态了。当然我们是否要往那个方向发展是个问题，因为涉及真实世界的决策就会有更多安全方面的诉求考量。当前模型在这块的保障还很少，例如经常可以看到例子，通过一些指令引导，可以让模型给出危险的回答来。如果往那个方向发展，AI 的 reward 函数应该如何设计，是否与意识的产生相关，也都是需要深入思考的。\u003C\u002Fp\u003E\u003Cp data-pid=\"rxxgOvsj\"\u003E结合多模态与真实世界决策问题，已经有类似的研究项目再往这个方向前进了，例如 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fminedojo.org\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMineDojo\u003C\u002Fa\u003E 项目，搜集了各种 Minecraft 游戏相关的 YouTube 视频，Wiki 文章，Reddit 讨论，期望能训练一个模型能通过这些数据来学会如何在一个开放游戏环境中完成各种探索与任务。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f916cc61613b68e50b43898be17e881_b.jpg\" data-size=\"normal\" data-rawwidth=\"2026\" data-rawheight=\"1000\" class=\"origin_image zh-lightbox-thumb\" width=\"2026\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f916cc61613b68e50b43898be17e881_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2026&#39; height=&#39;1000&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2026\" data-rawheight=\"1000\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2026\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f916cc61613b68e50b43898be17e881_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f916cc61613b68e50b43898be17e881_b.jpg\" data-original-token=\"v2-5cd7790a05fe038c2aba76b1e2880e01\"\u002F\u003E\u003Cfigcaption\u003E使用多模态数据来训练 AI 学会构建\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E思考“大力出奇迹”\u003C\u002Fh3\u003E\u003Cp data-pid=\"oz7Arexw\"\u003E回到 GPT 这类大语言模型的诞生，我跟很多人一样，早期只是觉得这是一个大力出奇迹的产物，堆了很多数据，算力，训练出了巨大的模型，但好像没有什么特别的创新之处。但现在来看，这个结论显然是不够深入的，从前面一系列关于 AGI 路线的设想也能略窥一斑。之前在群里讨论时也有朋友提出，如果说数据和算力是最重要的因素，那么为何不是拥有最多数据和算力的大公司们，或者拥有产出最多算力基础设施的显卡厂商们搞出了 ChatGPT，而是这样一家小小的创业公司呢？\u003C\u002Fp\u003E\u003Cp data-pid=\"lzFp6Bsd\"\u003E再深入去看这些研究人员在设计训练策略时的做法，也有很多有趣的发现。例如数据量，模型参数量和训练轮次是决定计算资源需求的几个要素，那么如何进行配比能让模型在最少资源需求的情况下达到最好的效果呢？是更多的数据更重要，还是更大的模型更重要，还是训练更多个 epoch 更重要？目前看可能最重要的还是高质量更大量的数据，并且与模型参数等形成一个比例关系来一起缩放，也就是所谓的 scaling law。\u003C\u002Fp\u003E\u003Cp data-pid=\"_yuqRnUw\"\u003E这类大模型还有一个比较有意思的现象，就是复杂系统中经常提到的“涌现”。在模型规模较小时，发现其在很多任务上的表现基本跟瞎猜差不多，但等到模型规模突破一个阈值之后，其相关能力会大幅度地上升，突然就可以完成这类任务了。这里面一个可能的关键因素就是之前提到的 chain of thought 能力，在复杂任务的各个环节的理解能力都逐渐达到了一个水平后，整个链路才得以打通，就突然可以做复杂的推理问题（in context learning）之类了。另外人类知识体系的复杂性也导致了必须掌握大部分的知识，才能去理解一个非常细小的行为。\u003C\u002Fp\u003E\u003Cp data-pid=\"qaNOemg8\"\u003E过去几年我的很多思路都更倾向于 data-centric AI 里那种用少量高质量的数据去构建和完善特定领域模型，大语言模型在这一点上的特质的确让我打开了视野。如果人类可以识别和处理脏数据，那么足够复杂的大模型是否也能自动处理呢？\u003C\u002Fp\u003E\u003Cp data-pid=\"teZx5GCN\"\u003E最后，很多人会觉得巨大的模型训练，推理成本会让很多实际应用因为成本问题无法落地。这一点我倒是非常乐观，从工业革命开始技术和计算能力方面的摩尔定律基本就没有失效过。因为担心算力成本而放弃产品化探索，或者过多地把技术壁垒建立在硬件资源的节约上可能反而比较有风险。当然如果本身就是做底层基础设施的厂商，能够契合这种“指数增长”趋势的技术肯定就是巨大的优势了。这方面像稀疏化的大模型，结合 retrieval 技术等都是很有意思的研究发展方向。\u003C\u002Fp\u003E\u003Ch3\u003E数据用尽？\u003C\u002Fh3\u003E\u003Cp data-pid=\"xdMFGF63\"\u003E前面已经提到，当前阶段影响大模型能力的最重要的因素就是高质量的数据。目前很多语言模型已经用了整个因特网上能够获取到的 10%量级的数据了，在可见的将来很可能会出现“数据用尽”的问题。对于这一点，个人有几个方面的思考。\u003C\u002Fp\u003E\u003Cp data-pid=\"sz3ZTULO\"\u003E首先数据的重要性很可能在一段时间内都会成为相关产品竞争之间的一个重要差异化因素（模型本身反而比较类似），因此在设计相关产品时，相应的“数据飞轮”设计需要重点考虑。这个方面也许会涌现出一些相关技术和厂商的机会来，例如专职于做人工\u002F自动化数据生成，人类反馈数据收集的相关技术栈等。\u003C\u002Fp\u003E\u003Cp data-pid=\"RjYTHE1q\"\u003E对于目前 ChatGPT 生成的回复信息，很多也是全新的，从未出现过的文字组合。对于这种输出，是否是一种有效的“训练数据”呢？如果不是的话，那么有人类参与的“有效训练数据”与其本质区别是什么？这也类似于问模型目前给出的回答，是不是一种“创新”？\u003C\u002Fp\u003E\u003Cp data-pid=\"cisviqIM\"\u003E上述问题或许有些哲学意味，换一种说法，我们可以把新的信息的生成分为两类，一类是含义\u002F事实\u002F经验型的数据，相当于世界上发生的各种新事件。这类数据只需要以类似搜索引擎更新数据库的方式去更新模型应该就可以（现在的 prompt 也能解决一部分）。另一类则是逻辑\u002F系统类的数据，体现的是信息之间关系的演变，例如出现了新的系统或组织，实体间的关联关系等。但后者这类信息的更新速度仅由人类来推动的话，或许是非常缓慢的。这也是为何有“太阳底下无新事”的说法存在。这种类型的信息更新，或许才是我们本质上需要去提供相关数据，增量训练模型的出发点。我们可以看到像 WebGPT、Sparrow 这类工作，以及 perplexity.ai、新版的 Bing 等产品都开始体现了 LLM 能够利用实时检索信息的能力，而不是任何的新知识都需要训练模型更新参数。\u003C\u002Fp\u003E\u003Cp data-pid=\"P2QTuOT-\"\u003E另一个更加实际的思考也是往多模态方向演进，思考未被“文本化”的知识主要在哪。例如人类日常中有非常多的语言文字交流是以口头形式完成的，那么各种面试，会议，播客访谈，日常聊天，甚至自言自语等是否都可以记录下来，形成更多更丰富的文本资料？例如像 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.rewind.ai\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Erewind\u003C\u002Fa\u003E 这样的产品就已经在做一些类似形式的尝试了，说不定会成为一种趋势。\u003C\u002Fp\u003E\u003Cp data-pid=\"uZ8FZszl\"\u003E如果大模型有了与真实世界更多的交互能力，那么新数据的生成或许也真的不再受限于人类产生数据的速度了。但这个方向也是有很大风险的。即使仅考虑文字输出，例如有些人可以通过控制一系列的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fyaroslav-n\u002FtweetGPT\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Etwitter bot\u003C\u002Fa\u003E，生成特定的社交媒体信息，达到操控舆论导向的目的。前阵子 Stack Overflow 禁止使用 ChatGPT 插件来回答问题，也是担心其产生的错误回答影响社区整体的信息质量。如果模型能做更多类型的决策，其安全风险必然更大。\u003C\u002Fp\u003E\u003Cp data-pid=\"Q4XY6VF8\"\u003E数据安全，隐私等方面也是一个绕不过去的话题。尤其是当前的大语言模型极度依赖于数据，谁控制了训练（包括 instruct tuning 等）数据，谁就控制了模型的“价值取向”。这在模型开始得到更广泛规模的使用时就显得极为重要。虽然前面也设想了一下是否能够实现通过指令来做实时增量训练，但显然模型安全方面是个需要先考虑解决的前提条件。目前也有一些工作在往这个方向发展，例如 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fmit-han-lab\u002Foffsite-tuning\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EOffsite-Tuning\u003C\u002Fa\u003E 等。\u003C\u002Fp\u003E\u003Ch3\u003E可解释机器学习\u003C\u002Fh3\u003E\u003Cp data-pid=\"5n1784W5\"\u003E在大语言模型的框架下，许多之前的研究都可以重新来审视和思考，这里仅以可解释机器学习来举个例子。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2bfa8690e6d6ad1c37148b9c6198c37e_b.jpg\" data-size=\"normal\" data-rawwidth=\"2500\" data-rawheight=\"1324\" class=\"origin_image zh-lightbox-thumb\" width=\"2500\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2bfa8690e6d6ad1c37148b9c6198c37e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2500&#39; height=&#39;1324&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2500\" data-rawheight=\"1324\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2500\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2bfa8690e6d6ad1c37148b9c6198c37e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2bfa8690e6d6ad1c37148b9c6198c37e_b.jpg\" data-original-token=\"v2-2ab631354f54eef34678bfabe312be1a\"\u002F\u003E\u003Cfigcaption\u003Exai 的思考框架\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"kSJBltCv\"\u003E上图是当前主流的 xai 的思考框架，从人和模型两方的知识范围，工作原理等角度出发，通过不同的路径去扩大两者的交集，促进沟通理解。从某种程度上来说，instruct tuning 或许也是一种新的形成可解释机器学习的方式。通过自然语言指令和多轮对话，我们可以反复确认模型给出预测背后参考的信息，推演逻辑等，这就与我们理解真实人类的想法非常接近了。在这个话题上是否还需要去了解人工神经网络的底层原理和特性可能就不那么重要了。\u003C\u002Fp\u003E\u003Ch3\u003EAGI 随想\u003C\u002Fh3\u003E\u003Cp data-pid=\"hpMMbVYp\"\u003E前面已经提到了很多跟通用人工智能相关的思考与遐想，例如从监督学习，到模仿学习再到强化学习的路线；通过自然语言接口，连接真实环境来达到“知行合一”的独立智能体；通过多模态的数据去增强语言模型的信息交互和“涌现”能力，实现逻辑推理，完成复杂任务等等。不过在强人工智能方向，一个绕不过去的话题是机器能否有意识，或者说我们是否要去创造意识？人类在思考与决策上的很多“缺陷”（如《思考，快与慢》中提到的那些），是不是也有不少是由意识和情感这些因素产生的。如果我们想构建一种与我们互补的“工作伙伴”，或许意识并不是必需的。但如果我们想要让这类智能体在宇宙中去延续人类文明，那么意识可能就比较关键了（还要防止自我毁灭）。\u003C\u002Fp\u003E\u003Cp data-pid=\"MDAmkcyI\"\u003E另外前面提到的一个设想，如果通用智能后续能够自行完成物品的生产建造，甚至连机器人也都是自动化建造出来的，那么整个社会的商品成本都会极大下降。如果我们把想象更进一步，ChatGPT 是否学习过自己的代码？它能否通过当前模型在世界上的反馈表现去自动更新这部分的代码并不断迭代，甚至为自己创造出更利于自我生存的“意识”来？这是否会跟人类修改基因一样，也涉及到“机器人伦理”问题？:)\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Cp data-pid=\"RrOSEevV\"\u003E本系列的后续文章：\u003C\u002Fp\u003E\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F607127757\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-788bf5fa9e7577286afe6102ced5eaec_qhd.jpg\" data-image-width=\"3072\" data-image-height=\"2048\" class=\"internal\"\u003E字节：迈向 ChatGPT 时代 - 商业篇\u003C\u002Fa\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F26797383","type":"topic","id":"26797383","name":"LLM（大型语言模型）"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19912106","type":"topic","id":"19912106","name":"GPT"}],"voteupCount":71,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"},"commentCount":5,"contributions":[{"id":44286951,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":374,"isNormal":true,"status":0,"activityToppingInfo":{"state":"untopped"},"shareText":"迈向 ChatGPT 时代 - 技术篇 - 来自知乎专栏「RandomGenerator」，作者: 字节 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F608075096 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":36,"hasColumn":true,"republishers":[],"isNewLinkCard":true,"emojiReaction":{"cryFaceCount":0,"cryFaceHasSet":false,"hugCount":0,"hugHasSet":false,"likeCount":36,"likeHasSet":false,"onlookerCount":0,"onlookerHasSet":false},"abParam":{"qaHiddenVoteup":"1","rsInterest1":"1"},"attachedInfo":"kgIkCgkyMjMyNTk3MDMSCTYwODA3NTA5NhgHIgpJTUFHRV9URVhU","shareGuide":{"hasPositiveBubble":false,"hasTimeBubble":false,"hitShareGuideCluster":false},"settings":{"tableOfContents":{"enabled":true}},"canReference":false,"reactionInstruction":{}}},"columns":{"zijie0":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"zvideos":{},"zvideoContributions":{},"briefs":{},"eduCourses":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"ab":{"config":{"params":[{"id":"ques_follow_con","type":"Int","value":"0","chainId":"_gene_","layerId":"ques_follow_con","key":3320}],"experiments":[],"chains":[],"encodedParams":"Cgo7ArcDiwUnB\u002FgMEgUAAAAAAA=="},"triggers":{}},"abV2":{"config":{"paramMap":{"pm_new_task":{"value":"0"},"in_editor_title":{"value":"0"},"ws_platform_new":{"value":"0"}},"abMap":{}},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":true,"Android":false,"iOS":true,"isAppleDevice":true,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (iPhone; CPU iPhone OS 16_4 like Mac OS X) AppleWebKit\u002F605.1.15 (KHTML, like Gecko) Mobile\u002F15E148"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F608075096","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F608075096","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"oppoSearch":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false,"huaweiSearch":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"","xUDId":"AFBXnGGr8BaPTq1NbGXn_ppp0RPq8BY0Jxo=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"武汉","countryName":"中国","regionName":"湖北","countryCode":"CN"},"logged":false,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0}},"recommend":{"recommendTimes":{}}},"explore":{},"levelUpperLimit":10,"mcn":{},"mcnManage":{},"tasks":{},"announcement":{},"creatorsRecommendInfo":{}},"creators":{"common":{"applyStatus":{},"rightsStatus":{}},"bayesDomains":{"status":{},"options":{"topDomains":null,"allDomains":null,"editable":0},"contents":null},"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"faq":{"tabs":[],"article":{}},"knowledgeIncome":{},"safeguardRights":{},"analytics":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"account":{"growthLevel":{}},"KMResource":{},"training":{},"ToolsQuestion":{"goodatTopics":[]},"ToolsHotspot":{"domains":[]},"ToolsRecommend":{},"ToolsCustomPromotion":{"itemLists":{},"baseInfo":{}},"ToolsSearchQuestion":{},"editorSetting":{},"MCNManage":{},"knowledgeTasks":{},"incomeAnalysis":{"income":{"aggregation":{}}},"creationManage":{"editModal":{"status":false}},"activity":{},"announcement":{},"home":{"currentCreatorUrlToken":null,"rights":[],"newRights":[],"scoreInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"bannerList":[],"recentlyCreated":[]},"videoSupport":{"textBenefit":{}},"videoDistribution":{}},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"concernedUpvoters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"zijie0"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false},"linkCardLimit":0},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]},"adPromotion":{"answer":{},"article":{}}},"fetchHost":"www.zhihu.com","subAppName":"column","spanName":"Post","canaryConfig":{"test_canary":"0","use_new_player":"1","player_vendor":"1","use_hevc":"1","upload_use_signature":"1","use_backdrop_blur":"1","article_title_imagex":"0","play_station":"1"}}</script><script crossorigin="" src="https://static.zhihu.com/heifetz/vendor.5f3e51e68d56265eb628.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react@17.0.2/umd/react.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom-server.browser.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/runtime.app.560046624f28621b8b9f.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-29107295.app.a7b6d98ed785438234bf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-79b5cf47.app.f16b5bf4c3cff85007a0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-330004dc.app.1a4905d34b3df3f09dff.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-0e5ce61e.app.121a4e979ab55ff600b2.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-83b0f42f.app.6f9779781d0af52a0ddf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-2ec050f6.app.c4cf2528b321f02e9fa0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/680.app.f3c9d9e614b550bbff65.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.app.b9bcd5e5f805cd0c6068.js"></script><script defer="" src="https://static.zhihu.com/event/wza/4613/aria.js?appid=c5ddb58ead4528987249d96fb27246ab" id="ariascripts" wapforceoldfixed="false" loaddata="false" callbackexit="RQ_HALW_QDPH" callback="RQ_VWDUW_QDPH"></script><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script crossorigin="" src="https://unpkg.zhimg.com/za-js-sdk@4.13.0/dist/zap.js"></script><div><div style="display: none;"><i>想来知乎工作？请发送邮件到 jobs@zhihu.com</i></div></div><script src="https://zz.bdstatic.com/linksubmit/push.js"></script><script crossorigin="" src="https://unpkg.zhimg.com/@cfe/emoticon@1.2.4/lib/emoticon.js"></script></body></html>