<!doctype html>
<html data-n-head-ssr>
  <head >
    <title>SeqGPT: 开箱即用的开放域自然语言理解大模型 - 智源社区</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" data-hid="viewport" name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no"><meta data-n-head="ssr" data-hid="google-site-verification" name="google-site-verification" content="u-JiwxGIuE3RbhXnquXdzK_ik29oSJ6GTAcZ5axu0vo"><meta data-n-head="ssr" data-hid="baidu-site-verification" name="baidu-site-verification" content="code-zPrPvzUuOe"><meta data-n-head="ssr" data-hid="bytedance-verification-code" name="bytedance-verification-code" content="BD/+PKoa0lO7XlbxphuC"><meta data-n-head="ssr" data-hid="sogou_site_verification" name="sogou_site_verification" content="N0ymPtfCiv"><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" data-hid="keywords" name="keywords" content="自然语言处理,大模型,开放科学"><meta data-n-head="ssr" data-hid="description" name="description" content="SeqGPT是一款开源的大型语言模型，可以用于开放领域序列理解任务。该模型的代码已经上传到GitHub，同时也提供了在线体验地址。论文详细介绍了SeqGPT的设计和性能评估。"><meta data-n-head="ssr" property="og:type" content="article"><meta data-n-head="ssr" property="og:url" content="https://hub.baai.ac.cn/view/30166"><meta data-n-head="ssr" property="og:image" content="https://simg.baai.ac.cn/hub-detail/a0263e91a7131c9c0bebb42a41c78ac31693806602626.webp"><meta data-n-head="ssr" property="og:release_date" content="2023-09-04T13:50:08"><meta data-n-head="ssr" property="og:title" content="SeqGPT: 开箱即用的开放域自然语言理解大模型 - 智源社区"><meta data-n-head="ssr" data-hid="og:description" property="og:description" content="SeqGPT是一款开源的大型语言模型，可以用于开放领域序列理解任务。该模型的代码已经上传到GitHub，同时也提供了在线体验地址。论文详细介绍了SeqGPT的设计和性能评估。"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="https://hub.baai.ac.cn/_nuxt/favicon.ico"><link data-n-head="ssr" rel="canonical" href="https://hub.baai.ac.cn/view/30166"><script data-n-head="ssr" src="https://hub.baai.ac.cn/shim-js/hub-modal.js"></script><script data-n-head="ssr" src="https://hm.baidu.com/hm.js?22af78906280d40a7c5ad981171db6d3"></script><script data-n-head="ssr" src="https://ticket-assets.baai.ac.cn/uploads/775529c69d2d5632895cc05e924780bb.js?ver=1.0.0"></script><link rel="preload" href="/_nuxt/47317e0.js" as="script"><link rel="preload" href="/_nuxt/02421f5.js" as="script"><link rel="preload" href="/_nuxt/css/753213b.css" as="style"><link rel="preload" href="/_nuxt/ba2b37f.js" as="script"><link rel="preload" href="/_nuxt/css/c045f4f.css" as="style"><link rel="preload" href="/_nuxt/9174bba.js" as="script"><link rel="preload" href="/_nuxt/css/f21fa99.css" as="style"><link rel="preload" href="/_nuxt/337bdbf.js" as="script"><link rel="stylesheet" href="/_nuxt/css/753213b.css"><link rel="stylesheet" href="/_nuxt/css/c045f4f.css"><link rel="stylesheet" href="/_nuxt/css/f21fa99.css">
  </head>
  <body >
    <div data-server-rendered="true" id="__nuxt"><div id="__layout"><div id="app" class="app" style="opacity:0;"><header class="header"><section class="container"><div class="logo"><a href="/"><img src="/_nuxt/img/logo.3ab8d1f.png"></a></div> <nav class="nav"><span><a href="/" class="nav-item"><i class="icon icon-home iconfont"></i>首页</a></span><span><a href="/events" class="nav-item"><i class="icon icon-activity iconfont"></i>活动</a></span><span><a href="/comments" class="nav-item"><i class="icon icon-comment iconfont"></i>评论</a></span> <span><a href="https://2023.baai.ac.cn/" target="_blank" class="nav-item__2023" style="margin-left: 20px;"><img src="/_nuxt/img/2023icon-01.15b8f95.svg" alt="2023智源大会" style="height: 34px;max-width: 120px;"></a></span></nav> <div id="header-search" class="header-search"><div class="header-search-main"><!----> <form action="javascript:return true" class="header-search-form" style="display:;"><label class="header-search-input"><input type="search" maxlength="100" placeholder="AI日报" value=""> <i class="icon icon-search iconfont"></i></label></form> <span class="header-search-cancel" style="display:none;">取消</span></div> <div class="van-overlay header-search-overlay" style="animation-duration:0s;display:none;"></div></div> <div class="header-right"><div class="header-btns"><button class="van-button van-button--default van-button--small"><div class="van-button__content"><span class="van-button__text">注册</span></div></button> <button class="van-button van-button--primary van-button--small"><div class="van-button__content"><span class="van-button__text">登录</span></div></button></div></div></section> <!----></header> <main class="main"><div class="view-page" data-v-70cdbe81><div class="main-container" style="display:;" data-v-70cdbe81><div class="text-center" data-v-70cdbe81><h1 id="post-title" data-v-70cdbe81>SeqGPT: 开箱即用的开放域自然语言理解大模型</h1> <div class="meta-box" data-v-70cdbe81><div class="tag-container" data-v-70cdbe81><span class="tag-item" data-v-70cdbe81><a href="/?tag_id=20" class="tag storiesTag" data-v-70cdbe81><span data-v-70cdbe81>自然语言处理</span></a></span><span class="tag-item" data-v-70cdbe81><a href="/?tag_id=90" class="tag storiesTag" data-v-70cdbe81><span data-v-70cdbe81>大模型</span></a></span><span class="tag-item" data-v-70cdbe81><a href="/?tag_id=1009" class="tag storiesTag" data-v-70cdbe81><span data-v-70cdbe81>开放科学</span></a></span></div> <div class="author-container fl" data-v-70cdbe81><div class="author-name author-item clearfix" data-v-70cdbe81><div id="post-author" class="show-pop moucehand fl author-label show-pop" data-v-70cdbe81><span class="avatar fl avatar-circle avatar-default" data-v-70cdbe81><img src="https://hub-avatar.baai.ac.cn/user/19478.png"></span> <span class="author-label-text" data-v-70cdbe81>NewBeeNLP
                2023-09-04 13:50 分享</span></div> <div class="person-popover" style="display:none;" data-v-6a4a665c data-v-70cdbe81><div class="personage-wrap moucehand" data-v-6a4a665c><div class="personage-head" data-v-6a4a665c><div class="personage-head-left" data-v-6a4a665c><div class="personage-avatar" data-v-6a4a665c><span class="ant-avatar ant-avatar-circle ant-avatar-image" data-v-6a4a665c><img src="https://hub-avatar.baai.ac.cn/user/19478.png" data-v-6a4a665c></span> <div class="avatar-badge" data-v-6a4a665c><div class="cap" data-v-6a4a665c><i class="cap-icon" data-v-6a4a665c></i> <span class="cap-name" data-v-6a4a665c></span></div></div></div></div> <div class="personage-head-right" data-v-6a4a665c><div class="have-cont" data-v-6a4a665c><div class="have-cont-head text-center" data-v-6a4a665c><span class="span-h3" data-v-6a4a665c>NewBeeNLP</span></div> <div class="user-count text-center" data-v-6a4a665c><span data-v-6a4a665c>帖子数：15</span> <span data-v-6a4a665c>评论数：0</span></div> <div class="user-more text-center" data-v-6a4a665c><span class="btn" data-v-6a4a665c>个人主页</span></div></div></div></div></div></div></div></div> <div class="clearfix" data-v-70cdbe81></div> <a href="javascript:;" data-v-70cdbe81><div class="article-source" data-v-70cdbe81>
            以下文章来源于mp.weixin.qq.com
          </div></a></div></div> <div id="post-content" class="post-content" data-v-70cdbe81><html><head></head><body><div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;margin-bottom: 24px;" data-mpa-powered-by="yiban.io"><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzIxMzkwNjM2NQ==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/DHibuUfpZvQdLGIOziaPIFvO2Wlm2YSKuDzn1NcibKTwzT3eCVMmTgHKuNJMiaaLjHJbJWL0pdkQovwE5YPQr9ibZ7A/0?wx_fmt=png" data-nickname="NewBeeNLP" data-alias="NewBeeNLP" data-signature="永远有料，永远有趣" data-from="0" data-is_biz_ban="0"></mp-common-profile></section><blockquote data-tool="mdnice编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;border-left-color: rgba(0, 0, 0, 0.4);background: rgba(0, 0, 0, 0.05);color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;"><p style="font-size: 16px;padding-top: 8px;padding-bottom: 8px;color: black;line-height: 26px;">论文链接：<span style="color: rgb(0, 82, 255);">SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding（https://arxiv.org/abs/2308.10529）</span></p><p style="font-size: 16px;padding-top: 8px;padding-bottom: 8px;color: black;line-height: 26px;"><span style="letter-spacing: 0px;">GitHub链接：</span><span style="letter-spacing: 0px;color: rgb(0, 82, 255);">https://github.com/Alibaba-NLP/SeqGPT</span><span style="color: rgb(0, 82, 255);letter-spacing: 0px;"></span></p><p style="font-size: 16px;padding-top: 8px;padding-bottom: 8px;color: black;line-height: 26px;">体验地址：<span style="color: rgb(0, 82, 255);">https://www.modelscope.cn/studios/TTCoding/open_ner/summary</span></p></blockquote><figure data-tool="mdnice编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="211" data-ratio="0.4759259259259259" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/a0263e91a7131c9c0bebb42a41c78ac31693806602626.webp" data-type="png" data-w="1080" style="width: 558px;height: 265px;" src="https://simg.baai.ac.cn/hub-detail/a0263e91a7131c9c0bebb42a41c78ac31693806602626.webp" referrerpolicy="no-referrer"></p></figure><h2 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;">概念介绍</h2><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">自然语言理解（Natural Language Understanding, 简称NLU）任务是帮助机器理解自然语言的任务的总称，与自然语言生成（Natural Language Generation，简称NLG）&nbsp;合称为自然语言处理（Natural Language Processing，简称NLP）。NLU任务覆盖文本分类、信息抽取、情感分类、关系抽取、事件抽取等子任务，是各类信息处理系统，如信息管理系统、推荐系统、搜索引擎的重要基础组件。</p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">正是由于其重要性和应用的广泛性，NLU一直是NLP从业人员重点研发的方向。在过去几十年中，尤其自BERT诞生后，NLU技术取得长足进步。在各类细分场景中，基于大规模高质量的标注数据，采用监督学习的NLU模型达到了极高的精度。但是，监督模型高昂的定制成本（数据标注成本、研发时间成本等）限制了它的应用范围。除了需求相对固定，有大规模使用可以摊薄成本的场景外，对于成本敏感、数据标注难度大、需求变化快的场景，很难实际落地。因此，研究者一直致力于探索一种没有领域（可以等价为场景）限制的通用模型，即开放域（open domain）模型，期望在任何场景都可以开箱即用。</p><h2 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;">动机</h2><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">然而，受限于小模型的泛化性不足，真正的开放域模型如凤毛麟角。随着大规模语言模型，特别是GPT3的出现，研究者看到了理想实现的可能性。ChatGPT的出现则直接将开放域模型变成了现实。用户只需仔细描述自己的需求，无需标注大量数据，即可以获得相对可靠的结果。但是深度使用过类似ChatGPT的做NLU任务用户应该不难发现，还存在一些问题。</p><ol data-tool="mdnice编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">成本问题，NLU任务作为基础性任务，其调用量巨大，长期的调用成本甚至超过了专门研发监督模型的成本。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">数据安全问题，对于一些数据安全管理严格的场景，是不可能将输出传输到外部互联网服务器的。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">推理速度问题，ChatGPT接口的并发数和RT很难支持NLU这一类基础任务每天大规模的实时请求。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">提示工程繁琐，ChatGPT的效果受提示影响很大，对于不同任务需要精心设计提示语。严格来说，不能算开箱即用的开放域模型，因为对不同任务还是有提示设计的成本。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">范围格式可解析性与稳定性差，ChatGPT等模型的输出为自然语言形式，没有严格的模式（即使通过提示语进行限制，依然会有很高比例的例外），给下游任务利用模型结果造成困难。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">闭源模型，无法结合沉淀的业务数据深度定制。通用版本的效果难以满足高准确率需求的场景。</p></section></li></ol><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">因此，研发一款规模较小（使用成本低、推理速度快）、输入输出简洁（类似于API）、可私有定制的模型，有其必要性。</p><h2 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;">方法简述</h2><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">统一任务范式</h3><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">大规模语言模型输入是序列，包含任务相关知识，然后输出答案。为了用一个模型和一致的输入输出格式解决不同的NLU任务，我们将NLU统一转换成两个原子任务：</p><ul data-tool="mdnice编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">抽取：该任务识别输入句子中每个查询的所有相关片段。查询可以是单个单词、短语（如实体类型）或自然语言描述（如机器阅读理解问题）。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">分类：该任务旨在将整个输入与给定标签集合中合适的子集相关联，支持多标签分类。</p></section></li></ul><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">对于每个原子任务，我们设计了一个简单的提示模板（如下图所示），它包含（1）一些控制词，区分输入的不同要素，（2）要分析的具体文本，以及（3）所需要的的标签列表。输出答案则根据原子任务类型格式化为固定且易于解析的形式。特别地，对于抽取任务，答案逐行列出。每行包含用户输入的类型，后面跟着相应答案的短语列表。对于分类任务，答案格式化为单行列表，其中包含提供的标签集合中的答案标签。</p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="340" data-ratio="0.37777777777777777" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/645362fa02a7974068a894dc53cd321e1693806602627.webp" data-type="png" data-w="1080" style="width: 578px;height: 219px;" src="https://simg.baai.ac.cn/hub-detail/645362fa02a7974068a894dc53cd321e1693806602627.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">通常，大多数任务只涉及其中一个原子任务。NLI和NER是仅依靠分类或提取的任务的示例。然而，有些任务需要将其分解为多个原子任务。例如，关系抽取（RE）首先识别实体，然后进行分类以区分每对实体之间的关系。此外，我们还进行了必要的提示设计工作，以处理特定任务的输入。例如，NLI涉及两个句子（即前提和假设）。我们使用分隔符将它们连接起来。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">训练流程</h3><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">我们基于BLOOMZ训练SeqGPT，并采用两阶段的训练策略，包括预训练（Pre-training, 简称PT）和微调(Fine-tuning, 简称FT)，并在每个阶段使用不同的训练数据。在我们的初步实验中，这种策略优于使用PT和FT数据的简单混合训练。训练方式采用标准的因果语言模型（Causal language model，&nbsp;简称CLM）训练方法，训练参数细节请参考论文。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">预训练数据</h3><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">相关研究证明，丰富数据多样性有利于提升模型的泛化能力。因此，我们构建了一个大规模的预训练（PT）数据集，包含来自多个领域（包括维基百科、新闻和社交媒体等）极其多样化的标签集的数据。我们主要选择了三个任务：分类（CLS）、实体分类（ET）和实体识别（NER）。我们通过调用ChatGPT为每个样本获得伪标签。最终，PT数据集包含1,146,271个实例和817,075个不同的标签。下表列出了详细的统计信息。</p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="373" data-ratio="0.6089743589743589" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/eaac97d1fb5d85f1c07405fdfe14cbdc1693806602628.webp" data-type="png" data-w="936" style="width: 578px;height: 352px;" src="https://simg.baai.ac.cn/hub-detail/eaac97d1fb5d85f1c07405fdfe14cbdc1693806602628.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">负例采样：由于ChatGPT生成的PT数据缺乏负例标签，即没有答案的标签（抽取任务）或不正确的类别（分类任务），因此不能直接用于训练。我们使用随机抽样的标签来增加PT数据中的负样本。由于标签集规模较大，这些抽样的细粒度标签很可能与输入句子无关（没有相关类型实体或不是对应的目标类别），因此可以安全地假设是负例标签。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">微调数据</h3><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">为了进一步校准模型以执行各类NLU任务并消除PT数据中的错误造成的影响，我们收集了来自不同领域的大规模高质量NLU数据集进行微调。如下图所示，我们的微调（FT）数据集包含110个NLU数据集，涵盖英语和中文两种语言以及10大类任务。除了任务多样性外，领域（包括医学、新闻和与AI助手的对话）的多样性以及标签多样性也保证了数据多样性。每个任务被转化为原子任务，共产生了139个分类原子任务和94个抽取原子任务。我们手动选择了其中一小部分NLU数据集作为零样本评估的评估集。</p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="255" data-ratio="0.6679316888045541" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/a1dd3f014fdefd1dbfa7252bc85e20051693806602628.webp" data-type="png" data-w="1054" style="width: 558px;height: 373px;" src="https://simg.baai.ac.cn/hub-detail/a1dd3f014fdefd1dbfa7252bc85e20051693806602628.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">FT数据集包含大量的数据集，以确保多样性，但与此同时，也引入了数据不平衡的问题。以两个分类数据集为例，IFLYTEK和AG News的平均每个标签的实例数分别为124和31,900。因此，我们为每个数据集-标签对设置了一个配额来平衡数据。对于那些实例数少于配额的数据集-标签对，我们使用整个实例集而不进行上采样。然后我们将所有数据混合在一起，并在训练中均匀地从中采样。</p><h2 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;">结果分析</h2><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">评价方式</h3><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">考虑到语言模型有时会生成合理但不完全匹配的答案，传统的Micro-F1指标对于评估来说不够平滑。为了缓解这个问题并使评估更容忍一些次要缺陷，我们提出将Micro-F1和更平滑的ROUGE分数结合作为整体指标。具体而言，我们将ROUGE-1、ROUGE-2和ROUGE-L的平均值作为ROUGE分数，将Micro-F1和ROUGE分数的平均值作为最终得分。</p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">本文重点评估模型泛化能力，我们将数据集分为held-in和held-out两部分，两部分从数据集层面没有交集。下文如无特殊说明，均为在held-out数据集上效果。为了提高效率，我们从每个测试集拆分中随机抽取48个记录（我们前期的实验证明这个结果与使用完整测试集是无偏的）。此外，在涉及被拆分的任务时，我们报告原子任务的平均分数。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">效果对比</h3><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="433" data-ratio="0.45740740740740743" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/cb5d9d4ca48ac2f1968078c905f2e2b21693806602628.webp" data-type="png" data-w="1080" style="width: 578px;height: 264px;" src="https://simg.baai.ac.cn/hub-detail/cb5d9d4ca48ac2f1968078c905f2e2b21693806602628.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">上表中比较了SeqGPT家族和基线模型的测试集性能。我们有以下发现：</p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">（1）最小的SeqGPT-560m在性能上大幅超过ChatGPT，超出了19.1个百分点，证明了我们的框架的有效性，说明小型模型可以学习到强大的自然语言理解能力。需要说明是，ChatGPT的总体得分较低有两方面原因，一是我们没有针对每个任务进行仔细的提示工程，而是采用了和我们构建数据集类似的提示进行发问。二是因为ChatGPT生成的输出格式无法总是严格遵守我们的评估数据格式，自动评估脚本无法处理。因此，我们补充了进行了人工评价，结果参考最后人工评价部分。</p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">（2）通过使用更大的7b1主干模型，平均得分进一步提高到65.5，我们认为这一提升可以归功于更好的复杂推理能力和更多样化的世界知识，这些都是更大的预训练语言模型所带来的。（3）弱监督的超细粒度预训练数据对于较小的模型尤为有帮助。如果不使用预训练数据，SeqGPT-560m的性能从57.2下降到53.9。具体而言，对于需要对实体进行多样化理解的实体分类任务，各个大小的SeqGPT的得分都显著下降。（4）然而，利用预训练数据所实现的性能提升随着模型的增大而减小。我们认为这是因为在我们的预训练数据中的超细粒度知识也可以在LLM的预训练阶段直接学习，并且这些知识会随着预训练LLM模型的增大而更好地学习和保留。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">规模缩放实验</h3><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="458" data-ratio="0.7768518518518519" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/3dce344eb64bc676441dedaabf7275281693806602628.webp" data-type="png" data-w="1080" style="width: 578px;height: 449px;" src="https://simg.baai.ac.cn/hub-detail/3dce344eb64bc676441dedaabf7275281693806602628.webp" referrerpolicy="no-referrer"></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="446" data-ratio="0.8206627680311891" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/ec158402be2310fa38d5e5d0f4579e041693806602628.webp" data-type="png" data-w="1026" style="width: 558px;height: 458px;" src="https://simg.baai.ac.cn/hub-detail/ec158402be2310fa38d5e5d0f4579e041693806602628.webp" referrerpolicy="no-referrer"></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="192" data-ratio="0.7988614800759013" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/1d221d711afea3bce973cfb53ebf17911693806602628.webp" data-type="png" data-w="1054" style="width: 558px;height: 446px;" src="https://simg.baai.ac.cn/hub-detail/1d221d711afea3bce973cfb53ebf17911693806602628.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">我们也做了多组缩放实验，分别是：（1）模型参数量缩放；（2）任务数缩放；（3）每个任务的数据量缩放。相应结果如上图展示。可以有以下结论：</p><ol data-tool="mdnice编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">在一定范围内，是符合scalig law的，模型规模越大，数据越多模型效果越好。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">在held-in数据上，模型规模持续增长的边际效益递减，held-out数据集上这个问题没有那么明显。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">任务数的增加对提升held-out效果至关重要，即数据多样性非常重要。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">与3相对的是，每个任务的数据量不是越多越好，边际效应递减甚至为负，因此如果要提升模型效果，多样性优先于数据量。这个多样性体现在任务的多样性、数据领域多样性、相同任务的标签集多样性等。</p></section></li></ol><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">跨语言实验</h3><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="475" data-ratio="0.34444444444444444" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/3b59ef74c9d1d04e6d7aaf23e64c1b1a1693806602628.webp" data-type="png" data-w="1080" style="width: 578px;height: 199px;" src="https://simg.baai.ac.cn/hub-detail/3b59ef74c9d1d04e6d7aaf23e64c1b1a1693806602628.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">我们使用了大量来自英语和中文的训练数据。为了探索每种语言数据的影响以及SeqGPT的跨语言泛化能力，我们进行了跨语言泛化实验（1B7），主要结果如上表所示。我们可以看到，使用单一语言（英语/中文）训练的模型可以推广到另一种语言的任务，并取得较好的性能。比较仅使用英语和使用两种语言的数据训练的结果，我们发现不仅中文任务上效果得到提升，在英语任务也可以得到提升，表明语言之间存在一些共通的能力，可以通过多语言训练阶段学习到。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">跨任务实验</h3><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="491" data-ratio="0.851063829787234" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/2b9ffc86a2b072c340c77e1955f764831693806602629.webp" data-type="png" data-w="1034" style="width: 577px;height: 491px;" src="https://simg.baai.ac.cn/hub-detail/2b9ffc86a2b072c340c77e1955f764831693806602629.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">尽管在我们对所有任务使用相同的提示模版，但解决不同任务所需的能力是多样的。为了分析SeqGPT在训练期间未见过的任务上的工作方式以及训练任务如何影响不同测试任务的性能，我们使用单一任务数据训练了一系列模型，上图中展示了结果。在大多数评估任务中，当训练和测试任务相同时取得了最高或接近最高的性能。对于NLI任务，结论相反，使用NLI数据训练的模型效果最差。我们认为这是因为虽然我们把NLI任务转化为了分类任务，但其本质是逻辑推理，不同数据集的分类逻辑差别较大，因此模型很难泛化。在EE、MRC和RE上训练的模型可以很好地推广到所有测试任务，这表明解决这些任务所需的多样化知识对其他任务也至关重要。这些任务的数据可以作为针对通用领域自然语言理解的模型的重要训练资源。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">人工评价</h3><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="558" data-cropsely1="0" data-cropsely2="265" data-ratio="0.8798185941043084" data-s="300,640" data-src="https://simg.baai.ac.cn/hub-detail/1709b1859e098beef469e4c542936f7c1693806602629.webp" data-type="jpeg" data-w="882" style="width: 558px;height: 491px;" src="https://simg.baai.ac.cn/hub-detail/1709b1859e098beef469e4c542936f7c1693806602629.webp" referrerpolicy="no-referrer"></p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">为了进一步了解我们模型指标上优于ChatGPT的原因，排除格式问题引入的误差，我们对保留的数据集进行了人工评估。评估聘请了十名专业的标注员，并向他们展示了ChatGPT和SeqGPT-7B的答案（隐藏了模型名称）。标注员需要从核心内容上（忽略格式和额外解释性语言）决定哪个模型给出了更好的答案，或者两个模型效果相近。结果如上图所示。从结果可以看出，SeqGPT-7B的确在大多数任务上准确率更好，这证明了使用多样化NLU任务数据的训练模型的收益。此外，我们发现SeqGPT-7B的输出比ChatGPT的输出更简洁，更容易被解析。</p><h3 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;">总结</h3><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">本文介绍了SeqGPT，用一个统一的模型，通过将不同的NLU任务转化为两个通用的原子任务来处理。SeqGPT提供了一致的输入输出格式，使其能够通过任意变化的标签集来解决未见过的任务，而不需要繁琐的提示工程而且结果易于解析。我们使用极细粒度的合成数据和各种领域的大量NLU数据集对模型进行训练。训练过程进一步增强了数据平衡和随机采样负标签。无论是自动基准测试还是对未见任务的人工评估，SeqGPT都相对于ChatGPT的有一定优势。此外，我们通过实验揭示了训练任务数量和模型性能之间的对数相关性。我们还评估了SeqGPT在各种任务和语言上的泛化能力。然而，还有一些值得继续深入的问题。比如为什么PT数据无法增强SeqGPT-7B1，而FT数据的增加可以呢？如何生成更多高质量的NLU数据来满足SeqGPT的数据需求？我们希望未来的研究能够解答这些问题，进一步改进开放域NLU模型。</p><h2 data-tool="mdnice编辑器" style="margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;">讨论</h2><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">最后，还想讨论一个从ChatGPT出现就一直被提起的问题：大模型时代，还有必要做原子化的NLU模型的？我们认为这还是有必要的，虽然说一些以NLU为辅助的任务可以使用LLM进行端到端重构，但是还是有大量的场景需要专用的、小的NLU模型。这里举一些例子，抛转引玉。</p><ol data-tool="mdnice编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">受资源、成本、时间要求等限制，无法使用大模型的场景，如端上场景等。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">以NLU为最终目的的场景，从性价比考虑，无需使用通用大模型。如数据挖掘等。</p></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);"><p style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;">以NLU为重要组件，整体方案成熟，无需使用LLM重构的场景，如信息检索等。</p></section></li></ol><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;">因此，大模型的出现只是缩小了NLU的使用范围，但对高效高质专用模型的需求依然存在。超算替代不了PC, intel 酷睿也替代不了Arm单片机，其中原因相似。以上仅一家之言，还请各位指教。</p><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 26px;"><br mpa-from-tpl="t"></p><section data-mpa-template="t" mpa-from-tpl="t"><section data-mpa-template="t" mpa-from-tpl="t"><span style="padding-left: 10px;font-size: 18px;display: inline-block;border-left: 5px solid rgb(222, 198, 251);color: rgb(89, 89, 89);">一起交流</span><span style="padding-left: 10px;font-size: 18px;display: inline-block;border-left: 5px solid rgb(222, 198, 251);color: rgb(89, 89, 89);"><p data-tool="mdnice编辑器" style="margin-top: 10px;margin-bottom: 10px;padding-top: 8px;padding-bottom: 8px;color: rgb(89, 89, 89);font-family: Optima-Regular, Optima, PingFangTC-Light, PingFangSC-light, PingFangTC-light;letter-spacing: 2px;text-align: left;white-space: normal;font-size: 14px;line-height: 26px;word-spacing: 2px;user-select: auto;"><span style="font-size: 15px;">想和你一起学习进步！『<strong mpa-from-tpl="t">NewBeeNLP』</strong>目前已经建立了多个不同方向交流群（<span style="color: rgb(255, 120, 0);"><strong mpa-from-tpl="t">机器学习 / 深度学习 / 自然语言处理 / 搜索推荐 / 图网络 / 面试交流 /&nbsp;</strong></span>等），名额有限，赶紧添加下方微信加入一起讨论交流吧！（注意一定o要<strong mpa-from-tpl="t">备注信息</strong>才能通过）</span></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-croporisrc="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQfLTORzvcliawJtWWVz6PlXn37UodqVGPXWjuC2EKWmFboaINsADH1HNHtuA9R7XvocIlcHR8mgVTg/0?wx_fmt=jpeg" data-cropx1="100.88235294117646" data-cropx2="556.6332179930796" data-cropy1="275.34948096885813" data-cropy2="741.7820069204153" data-galleryid="" data-ratio="1.0241228070175439" data-s="300,640" data-type="jpeg" data-w="456" style="width: 210px !important;height: auto !important;visibility: visible !important;" data-src="https://simg.baai.ac.cn/hub-detail/7f096db6524ea49f83546900533982911693806602629.webp" src="https://simg.baai.ac.cn/hub-detail/7f096db6524ea49f83546900533982911693806602629.webp" referrerpolicy="no-referrer"></p></span></section><p><br mpa-from-tpl="t"></p></section><p><br mpa-from-tpl="t"></p><pre data-tool="mdnice编辑器" style="margin-top: 0em;outline: 0px;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;word-spacing: 1px;color: rgb(105, 105, 105);widows: 1;caret-color: rgb(0, 0, 0);visibility: visible;"><pre data-tool="mdnice编辑器" style="margin-top: 0em;outline: 0px;letter-spacing: 0.544px;visibility: visible;"><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;outline: 0px;letter-spacing: 0.544px;white-space: normal;font-family: arial;font-size: 15px;caret-color: rgb(51, 51, 51);line-height: 30px;color: rgb(80, 80, 80);text-align: right;"><span style="outline: 0px;font-size: 14px;"><strong style="outline: 0px;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;letter-spacing: 0.544px;color: rgb(0, 82, 255);"><br mpa-from-tpl="t"></strong></span></p><section data-mpa-template="t" mpa-from-tpl="t"><section data-mpa-template="t" mpa-from-tpl="t"><section data-mpa-template="t" mpa-from-tpl="t"><section data-tools="新媒体排版" data-id="3667731" data-style-type="undefined" mpa-from-tpl="t"><section data-id="3464974" data-style-type="undefined" style="user-select: auto;max-width: 100%;" mpa-from-tpl="t"><section label="小黄人科技" donone="shifuMouseDownCard('shifu_c_018')" style="margin-top: 5px;padding: 10px 1em;white-space: normal;font-family: 微软雅黑;box-sizing: border-box;text-align: center;text-shadow: rgb(255, 255, 255) 0px 1px 0px;border-width: 1px;border-style: solid;border-color: rgb(102, 102, 102);border-radius: 10px;user-select: auto;max-width: 100%;overflow-wrap: break-word !important;" mpa-from-tpl="t"><p style="text-align: center;"><img class="rich_pages __bg_gif wxw-img" data-ratio="0.7415730337078652" data-s="300,640" data-type="gif" data-w="1068" height="792" width="1068" style="font-family: 微软雅黑;text-align: center;white-space: normal;width: 677px !important;height: auto !important;visibility: visible !important;" data-src="https://simg.baai.ac.cn/hub-detail/7949d66925d484d631cba8a71bf4603f1693806602629.webp" src="https://simg.baai.ac.cn/hub-detail/7949d66925d484d631cba8a71bf4603f1693806602629.webp" referrerpolicy="no-referrer"></p></section></section></section></section></section></section><p data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;outline: 0px;letter-spacing: 0.544px;white-space: normal;font-family: arial;font-size: 15px;caret-color: rgb(51, 51, 51);line-height: 30px;color: rgb(80, 80, 80);text-align: right;"><span style="outline: 0px;font-size: 14px;"><strong style="outline: 0px;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;letter-spacing: 0.544px;color: rgb(0, 82, 255);"></strong></span></p></pre></pre></section><p style="display: none;margin-bottom: 24px;"><strong style="outline: 0px;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;letter-spacing: 0.544px;color: rgb(0, 82, 255);"><mp-style-type data-value="3"></mp-style-type></strong></p></div></body></html></div> <div class="button-list" data-v-70cdbe81><div class="story-actions-container" data-v-70cdbe81><div class="story-item-action"><span class="story-item-action-item"><i class="icon icon-like iconfont"></i>
      111
    </span> <span class="story-item-action-item"><i class="icon icon-collect iconfont"></i>
      0
    </span> <span class="story-item-action-item"><i class="icon icon-comment iconfont"></i>
      0
    </span> <span class="story-item-action-item"><span class="van-popover__wrapper"><!----><i class="icon icon-share iconfont"></i></span></span> <!----> <span class="story-item-action-item"><i class="icon iconimage" style="background-image:url(/_nuxt/img/report.a50a987.svg);"></i>举报
    </span></div> <span class="story-item-more"><div class="more-popover-container"><span class="van-popover__wrapper"><!----><i class="icon icon-more iconfont"></i></span> <!----> <div class="hub-dialog__wrapper report-dialog" style="display:none;"><div class="hub-dialog" style="width:512px;height:;"><div class="hub-dialog__header"><span class="hub-dialog__title">举报反馈</span> <i class="icon icon-close iconfont"></i></div> <div class="hub-dialog__body"><div class="report-dialog-content"><div class="report-dialog-type"><p class="report-dialog-title">举报类型（必选）</p> <ul class="clearfix"><li class="report-type-item">样式问题</li><li class="report-type-item">涉嫌广告</li><li class="report-type-item">内容抄袭</li><li class="report-type-item">内容侵权</li><li class="report-type-item">政治相关</li><li class="report-type-item">内容涉黄</li><li class="report-type-item">其他</li></ul></div> <!----> <div class="report-dialog-remark"><p class="report-dialog-title">举报详情（选填）</p> <div class="report-dialog-remark-input"><textarea placeholder="请详细描述举报原因，我们将第一时间核实处理" maxlength="200"></textarea> <p>0/200</p></div></div></div> <div class="report-dialog-footer"><button class="van-button van-button--info van-button--small van-button--plain van-button--round"><div class="van-button__content"><span class="van-button__text">取消</span></div></button> <button class="van-button van-button--info van-button--small van-button--round"><div class="van-button__content"><span class="van-button__text">提交</span></div></button></div></div></div></div></div></span> <!----> <!----><!----><!----></div></div> <!----> <!----> <div class="discuss-list" data-v-70cdbe81><iframe id="discuss-iframe" src="https://hub.baai.ac.cn/views/comment.html?id=30166&amp;title=SeqGPT:%2520%25E5%25BC%2580%25E7%25AE%25B1%25E5%258D%25B3%25E7%2594%25A8%25E7%259A%2584%25E5%25BC%2580%25E6%2594%25BE%25E5%259F%259F%25E8%2587%25AA%25E7%2584%25B6%25E8%25AF%25AD%25E8%25A8%2580%25E7%2590%2586%25E8%25A7%25A3%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B" width="100%" height="100%" frameborder="0" data-v-70cdbe81></iframe></div></div></div></main> <div class="app-safe-area"></div> <!----></div></div></div><script>window.__NUXT__=(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF){return {layout:"default",data:[{showPage:l,post_data:{id:ap,title:ar,user_id:19478,created_at:"2023-09-04 13:50 分享",created_at_edit:as,formart_created_at:"09\u002F04",url:"http:\u002F\u002Fmp.weixin.qq.com\u002Fs?__biz=MzIxMzkwNjM2NQ==&mid=2247524889&idx=2&sn=46f2f82ed5ef41395c0dac9bd7f7c06b&chksm=97ad84cba0da0ddd5f50c02e9b91b9e4f4ea4802e84fdc9012de28cbb87b47e5d363b93067aa&scene=0&xtrack=1#rd",host:i,content:"\u003Chtml\u003E\u003Chead\u003E\u003C\u002Fhead\u003E\u003Cbody\u003E\u003Cdiv class=\"rich_media_content js_underline_content autoTypeSetting24psection\" id=\"js_content\" style=\"visibility: visible;\"\u003E\u003Csection data-tool=\"mdnice编辑器\" data-website=\"https:\u002F\u002Fwww.mdnice.com\" style=\"font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;margin-bottom: 24px;\" data-mpa-powered-by=\"yiban.io\"\u003E\u003Csection class=\"mp_profile_iframe_wrp\"\u003E\u003Cmp-common-profile class=\"js_uneditable custom_select_card mp_profile_iframe\" data-pluginname=\"mpprofile\" data-id=\"MzIxMzkwNjM2NQ==\" data-headimg=\"http:\u002F\u002Fmmbiz.qpic.cn\u002Fmmbiz_png\u002FDHibuUfpZvQdLGIOziaPIFvO2Wlm2YSKuDzn1NcibKTwzT3eCVMmTgHKuNJMiaaLjHJbJWL0pdkQovwE5YPQr9ibZ7A\u002F0?wx_fmt=png\" data-nickname=\"NewBeeNLP\" data-alias=\"NewBeeNLP\" data-signature=\"永远有料，永远有趣\" data-from=\"0\" data-is_biz_ban=\"0\"\u003E\u003C\u002Fmp-common-profile\u003E\u003C\u002Fsection\u003E\u003Cblockquote data-tool=\"mdnice编辑器\" style=\"border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;border-left-color: rgba(0, 0, 0, 0.4);background: rgba(0, 0, 0, 0.05);color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;\"\u003E\u003Cp style=\"font-size: 16px;padding-top: 8px;padding-bottom: 8px;color: black;line-height: 26px;\"\u003E论文链接：\u003Cspan style=\"color: rgb(0, 82, 255);\"\u003ESeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding（https:\u002F\u002Farxiv.org\u002Fabs\u002F2308.10529）\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\u003Cp style=\"font-size: 16px;padding-top: 8px;padding-bottom: 8px;color: black;line-height: 26px;\"\u003E\u003Cspan style=\"letter-spacing: 0px;\"\u003EGitHub链接：\u003C\u002Fspan\u003E\u003Cspan style=\"letter-spacing: 0px;color: rgb(0, 82, 255);\"\u003Ehttps:\u002F\u002Fgithub.com\u002FAlibaba-NLP\u002FSeqGPT\u003C\u002Fspan\u003E\u003Cspan style=\"color: rgb(0, 82, 255);letter-spacing: 0px;\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\u003Cp style=\"font-size: 16px;padding-top: 8px;padding-bottom: 8px;color: black;line-height: 26px;\"\u003E体验地址：\u003Cspan style=\"color: rgb(0, 82, 255);\"\u003Ehttps:\u002F\u002Fwww.modelscope.cn\u002Fstudios\u002FTTCoding\u002Fopen_ner\u002Fsummary\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cfigure data-tool=\"mdnice编辑器\" style=\"margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;\"\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"211\" data-ratio=\"0.4759259259259259\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fa0263e91a7131c9c0bebb42a41c78ac31693806602626.webp\" data-type=\"png\" data-w=\"1080\" style=\"width: 558px;height: 265px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fa0263e91a7131c9c0bebb42a41c78ac31693806602626.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003C\u002Ffigure\u003E\u003Ch2 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;\"\u003E概念介绍\u003C\u002Fh2\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E自然语言理解（Natural Language Understanding, 简称NLU）任务是帮助机器理解自然语言的任务的总称，与自然语言生成（Natural Language Generation，简称NLG）&nbsp;合称为自然语言处理（Natural Language Processing，简称NLP）。NLU任务覆盖文本分类、信息抽取、情感分类、关系抽取、事件抽取等子任务，是各类信息处理系统，如信息管理系统、推荐系统、搜索引擎的重要基础组件。\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E正是由于其重要性和应用的广泛性，NLU一直是NLP从业人员重点研发的方向。在过去几十年中，尤其自BERT诞生后，NLU技术取得长足进步。在各类细分场景中，基于大规模高质量的标注数据，采用监督学习的NLU模型达到了极高的精度。但是，监督模型高昂的定制成本（数据标注成本、研发时间成本等）限制了它的应用范围。除了需求相对固定，有大规模使用可以摊薄成本的场景外，对于成本敏感、数据标注难度大、需求变化快的场景，很难实际落地。因此，研究者一直致力于探索一种没有领域（可以等价为场景）限制的通用模型，即开放域（open domain）模型，期望在任何场景都可以开箱即用。\u003C\u002Fp\u003E\u003Ch2 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;\"\u003E动机\u003C\u002Fh2\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E然而，受限于小模型的泛化性不足，真正的开放域模型如凤毛麟角。随着大规模语言模型，特别是GPT3的出现，研究者看到了理想实现的可能性。ChatGPT的出现则直接将开放域模型变成了现实。用户只需仔细描述自己的需求，无需标注大量数据，即可以获得相对可靠的结果。但是深度使用过类似ChatGPT的做NLU任务用户应该不难发现，还存在一些问题。\u003C\u002Fp\u003E\u003Col data-tool=\"mdnice编辑器\" style=\"margin-top: 8px;margin-bottom: 8px;padding-left: 25px;\" class=\"list-paddingleft-1\"\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E成本问题，NLU任务作为基础性任务，其调用量巨大，长期的调用成本甚至超过了专门研发监督模型的成本。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E数据安全问题，对于一些数据安全管理严格的场景，是不可能将输出传输到外部互联网服务器的。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E推理速度问题，ChatGPT接口的并发数和RT很难支持NLU这一类基础任务每天大规模的实时请求。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E提示工程繁琐，ChatGPT的效果受提示影响很大，对于不同任务需要精心设计提示语。严格来说，不能算开箱即用的开放域模型，因为对不同任务还是有提示设计的成本。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E范围格式可解析性与稳定性差，ChatGPT等模型的输出为自然语言形式，没有严格的模式（即使通过提示语进行限制，依然会有很高比例的例外），给下游任务利用模型结果造成困难。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E闭源模型，无法结合沉淀的业务数据深度定制。通用版本的效果难以满足高准确率需求的场景。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E因此，研发一款规模较小（使用成本低、推理速度快）、输入输出简洁（类似于API）、可私有定制的模型，有其必要性。\u003C\u002Fp\u003E\u003Ch2 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;\"\u003E方法简述\u003C\u002Fh2\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E统一任务范式\u003C\u002Fh3\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E大规模语言模型输入是序列，包含任务相关知识，然后输出答案。为了用一个模型和一致的输入输出格式解决不同的NLU任务，我们将NLU统一转换成两个原子任务：\u003C\u002Fp\u003E\u003Cul data-tool=\"mdnice编辑器\" style=\"margin-top: 8px;margin-bottom: 8px;padding-left: 25px;\" class=\"list-paddingleft-1\"\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E抽取：该任务识别输入句子中每个查询的所有相关片段。查询可以是单个单词、短语（如实体类型）或自然语言描述（如机器阅读理解问题）。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E分类：该任务旨在将整个输入与给定标签集合中合适的子集相关联，支持多标签分类。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E对于每个原子任务，我们设计了一个简单的提示模板（如下图所示），它包含（1）一些控制词，区分输入的不同要素，（2）要分析的具体文本，以及（3）所需要的的标签列表。输出答案则根据原子任务类型格式化为固定且易于解析的形式。特别地，对于抽取任务，答案逐行列出。每行包含用户输入的类型，后面跟着相应答案的短语列表。对于分类任务，答案格式化为单行列表，其中包含提供的标签集合中的答案标签。\u003C\u002Fp\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"340\" data-ratio=\"0.37777777777777777\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F645362fa02a7974068a894dc53cd321e1693806602627.webp\" data-type=\"png\" data-w=\"1080\" style=\"width: 578px;height: 219px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F645362fa02a7974068a894dc53cd321e1693806602627.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E通常，大多数任务只涉及其中一个原子任务。NLI和NER是仅依靠分类或提取的任务的示例。然而，有些任务需要将其分解为多个原子任务。例如，关系抽取（RE）首先识别实体，然后进行分类以区分每对实体之间的关系。此外，我们还进行了必要的提示设计工作，以处理特定任务的输入。例如，NLI涉及两个句子（即前提和假设）。我们使用分隔符将它们连接起来。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E训练流程\u003C\u002Fh3\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E我们基于BLOOMZ训练SeqGPT，并采用两阶段的训练策略，包括预训练（Pre-training, 简称PT）和微调(Fine-tuning, 简称FT)，并在每个阶段使用不同的训练数据。在我们的初步实验中，这种策略优于使用PT和FT数据的简单混合训练。训练方式采用标准的因果语言模型（Causal language model，&nbsp;简称CLM）训练方法，训练参数细节请参考论文。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E预训练数据\u003C\u002Fh3\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E相关研究证明，丰富数据多样性有利于提升模型的泛化能力。因此，我们构建了一个大规模的预训练（PT）数据集，包含来自多个领域（包括维基百科、新闻和社交媒体等）极其多样化的标签集的数据。我们主要选择了三个任务：分类（CLS）、实体分类（ET）和实体识别（NER）。我们通过调用ChatGPT为每个样本获得伪标签。最终，PT数据集包含1,146,271个实例和817,075个不同的标签。下表列出了详细的统计信息。\u003C\u002Fp\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"373\" data-ratio=\"0.6089743589743589\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Feaac97d1fb5d85f1c07405fdfe14cbdc1693806602628.webp\" data-type=\"png\" data-w=\"936\" style=\"width: 578px;height: 352px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Feaac97d1fb5d85f1c07405fdfe14cbdc1693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E负例采样：由于ChatGPT生成的PT数据缺乏负例标签，即没有答案的标签（抽取任务）或不正确的类别（分类任务），因此不能直接用于训练。我们使用随机抽样的标签来增加PT数据中的负样本。由于标签集规模较大，这些抽样的细粒度标签很可能与输入句子无关（没有相关类型实体或不是对应的目标类别），因此可以安全地假设是负例标签。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E微调数据\u003C\u002Fh3\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E为了进一步校准模型以执行各类NLU任务并消除PT数据中的错误造成的影响，我们收集了来自不同领域的大规模高质量NLU数据集进行微调。如下图所示，我们的微调（FT）数据集包含110个NLU数据集，涵盖英语和中文两种语言以及10大类任务。除了任务多样性外，领域（包括医学、新闻和与AI助手的对话）的多样性以及标签多样性也保证了数据多样性。每个任务被转化为原子任务，共产生了139个分类原子任务和94个抽取原子任务。我们手动选择了其中一小部分NLU数据集作为零样本评估的评估集。\u003C\u002Fp\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"255\" data-ratio=\"0.6679316888045541\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fa1dd3f014fdefd1dbfa7252bc85e20051693806602628.webp\" data-type=\"png\" data-w=\"1054\" style=\"width: 558px;height: 373px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fa1dd3f014fdefd1dbfa7252bc85e20051693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003EFT数据集包含大量的数据集，以确保多样性，但与此同时，也引入了数据不平衡的问题。以两个分类数据集为例，IFLYTEK和AG News的平均每个标签的实例数分别为124和31,900。因此，我们为每个数据集-标签对设置了一个配额来平衡数据。对于那些实例数少于配额的数据集-标签对，我们使用整个实例集而不进行上采样。然后我们将所有数据混合在一起，并在训练中均匀地从中采样。\u003C\u002Fp\u003E\u003Ch2 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;\"\u003E结果分析\u003C\u002Fh2\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E评价方式\u003C\u002Fh3\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E考虑到语言模型有时会生成合理但不完全匹配的答案，传统的Micro-F1指标对于评估来说不够平滑。为了缓解这个问题并使评估更容忍一些次要缺陷，我们提出将Micro-F1和更平滑的ROUGE分数结合作为整体指标。具体而言，我们将ROUGE-1、ROUGE-2和ROUGE-L的平均值作为ROUGE分数，将Micro-F1和ROUGE分数的平均值作为最终得分。\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E本文重点评估模型泛化能力，我们将数据集分为held-in和held-out两部分，两部分从数据集层面没有交集。下文如无特殊说明，均为在held-out数据集上效果。为了提高效率，我们从每个测试集拆分中随机抽取48个记录（我们前期的实验证明这个结果与使用完整测试集是无偏的）。此外，在涉及被拆分的任务时，我们报告原子任务的平均分数。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E效果对比\u003C\u002Fh3\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"433\" data-ratio=\"0.45740740740740743\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fcb5d9d4ca48ac2f1968078c905f2e2b21693806602628.webp\" data-type=\"png\" data-w=\"1080\" style=\"width: 578px;height: 264px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fcb5d9d4ca48ac2f1968078c905f2e2b21693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E上表中比较了SeqGPT家族和基线模型的测试集性能。我们有以下发现：\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E（1）最小的SeqGPT-560m在性能上大幅超过ChatGPT，超出了19.1个百分点，证明了我们的框架的有效性，说明小型模型可以学习到强大的自然语言理解能力。需要说明是，ChatGPT的总体得分较低有两方面原因，一是我们没有针对每个任务进行仔细的提示工程，而是采用了和我们构建数据集类似的提示进行发问。二是因为ChatGPT生成的输出格式无法总是严格遵守我们的评估数据格式，自动评估脚本无法处理。因此，我们补充了进行了人工评价，结果参考最后人工评价部分。\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E（2）通过使用更大的7b1主干模型，平均得分进一步提高到65.5，我们认为这一提升可以归功于更好的复杂推理能力和更多样化的世界知识，这些都是更大的预训练语言模型所带来的。（3）弱监督的超细粒度预训练数据对于较小的模型尤为有帮助。如果不使用预训练数据，SeqGPT-560m的性能从57.2下降到53.9。具体而言，对于需要对实体进行多样化理解的实体分类任务，各个大小的SeqGPT的得分都显著下降。（4）然而，利用预训练数据所实现的性能提升随着模型的增大而减小。我们认为这是因为在我们的预训练数据中的超细粒度知识也可以在LLM的预训练阶段直接学习，并且这些知识会随着预训练LLM模型的增大而更好地学习和保留。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E规模缩放实验\u003C\u002Fh3\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"458\" data-ratio=\"0.7768518518518519\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F3dce344eb64bc676441dedaabf7275281693806602628.webp\" data-type=\"png\" data-w=\"1080\" style=\"width: 578px;height: 449px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F3dce344eb64bc676441dedaabf7275281693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"446\" data-ratio=\"0.8206627680311891\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fec158402be2310fa38d5e5d0f4579e041693806602628.webp\" data-type=\"png\" data-w=\"1026\" style=\"width: 558px;height: 458px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fec158402be2310fa38d5e5d0f4579e041693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"192\" data-ratio=\"0.7988614800759013\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F1d221d711afea3bce973cfb53ebf17911693806602628.webp\" data-type=\"png\" data-w=\"1054\" style=\"width: 558px;height: 446px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F1d221d711afea3bce973cfb53ebf17911693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E我们也做了多组缩放实验，分别是：（1）模型参数量缩放；（2）任务数缩放；（3）每个任务的数据量缩放。相应结果如上图展示。可以有以下结论：\u003C\u002Fp\u003E\u003Col data-tool=\"mdnice编辑器\" style=\"margin-top: 8px;margin-bottom: 8px;padding-left: 25px;\" class=\"list-paddingleft-1\"\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E在一定范围内，是符合scalig law的，模型规模越大，数据越多模型效果越好。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E在held-in数据上，模型规模持续增长的边际效益递减，held-out数据集上这个问题没有那么明显。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E任务数的增加对提升held-out效果至关重要，即数据多样性非常重要。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E与3相对的是，每个任务的数据量不是越多越好，边际效应递减甚至为负，因此如果要提升模型效果，多样性优先于数据量。这个多样性体现在任务的多样性、数据领域多样性、相同任务的标签集多样性等。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E跨语言实验\u003C\u002Fh3\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"475\" data-ratio=\"0.34444444444444444\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F3b59ef74c9d1d04e6d7aaf23e64c1b1a1693806602628.webp\" data-type=\"png\" data-w=\"1080\" style=\"width: 578px;height: 199px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F3b59ef74c9d1d04e6d7aaf23e64c1b1a1693806602628.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E我们使用了大量来自英语和中文的训练数据。为了探索每种语言数据的影响以及SeqGPT的跨语言泛化能力，我们进行了跨语言泛化实验（1B7），主要结果如上表所示。我们可以看到，使用单一语言（英语\u002F中文）训练的模型可以推广到另一种语言的任务，并取得较好的性能。比较仅使用英语和使用两种语言的数据训练的结果，我们发现不仅中文任务上效果得到提升，在英语任务也可以得到提升，表明语言之间存在一些共通的能力，可以通过多语言训练阶段学习到。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E跨任务实验\u003C\u002Fh3\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"491\" data-ratio=\"0.851063829787234\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F2b9ffc86a2b072c340c77e1955f764831693806602629.webp\" data-type=\"png\" data-w=\"1034\" style=\"width: 577px;height: 491px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F2b9ffc86a2b072c340c77e1955f764831693806602629.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E尽管在我们对所有任务使用相同的提示模版，但解决不同任务所需的能力是多样的。为了分析SeqGPT在训练期间未见过的任务上的工作方式以及训练任务如何影响不同测试任务的性能，我们使用单一任务数据训练了一系列模型，上图中展示了结果。在大多数评估任务中，当训练和测试任务相同时取得了最高或接近最高的性能。对于NLI任务，结论相反，使用NLI数据训练的模型效果最差。我们认为这是因为虽然我们把NLI任务转化为了分类任务，但其本质是逻辑推理，不同数据集的分类逻辑差别较大，因此模型很难泛化。在EE、MRC和RE上训练的模型可以很好地推广到所有测试任务，这表明解决这些任务所需的多样化知识对其他任务也至关重要。这些任务的数据可以作为针对通用领域自然语言理解的模型的重要训练资源。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E人工评价\u003C\u002Fh3\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"558\" data-cropsely1=\"0\" data-cropsely2=\"265\" data-ratio=\"0.8798185941043084\" data-s=\"300,640\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F1709b1859e098beef469e4c542936f7c1693806602629.webp\" data-type=\"jpeg\" data-w=\"882\" style=\"width: 558px;height: 491px;\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F1709b1859e098beef469e4c542936f7c1693806602629.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E为了进一步了解我们模型指标上优于ChatGPT的原因，排除格式问题引入的误差，我们对保留的数据集进行了人工评估。评估聘请了十名专业的标注员，并向他们展示了ChatGPT和SeqGPT-7B的答案（隐藏了模型名称）。标注员需要从核心内容上（忽略格式和额外解释性语言）决定哪个模型给出了更好的答案，或者两个模型效果相近。结果如上图所示。从结果可以看出，SeqGPT-7B的确在大多数任务上准确率更好，这证明了使用多样化NLU任务数据的训练模型的收益。此外，我们发现SeqGPT-7B的输出比ChatGPT的输出更简洁，更容易被解析。\u003C\u002Fp\u003E\u003Ch3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 20px;\"\u003E总结\u003C\u002Fh3\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E本文介绍了SeqGPT，用一个统一的模型，通过将不同的NLU任务转化为两个通用的原子任务来处理。SeqGPT提供了一致的输入输出格式，使其能够通过任意变化的标签集来解决未见过的任务，而不需要繁琐的提示工程而且结果易于解析。我们使用极细粒度的合成数据和各种领域的大量NLU数据集对模型进行训练。训练过程进一步增强了数据平衡和随机采样负标签。无论是自动基准测试还是对未见任务的人工评估，SeqGPT都相对于ChatGPT的有一定优势。此外，我们通过实验揭示了训练任务数量和模型性能之间的对数相关性。我们还评估了SeqGPT在各种任务和语言上的泛化能力。然而，还有一些值得继续深入的问题。比如为什么PT数据无法增强SeqGPT-7B1，而FT数据的增加可以呢？如何生成更多高质量的NLU数据来满足SeqGPT的数据需求？我们希望未来的研究能够解答这些问题，进一步改进开放域NLU模型。\u003C\u002Fp\u003E\u003Ch2 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px;margin-bottom: 15px;font-weight: bold;font-size: 22px;\"\u003E讨论\u003C\u002Fh2\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E最后，还想讨论一个从ChatGPT出现就一直被提起的问题：大模型时代，还有必要做原子化的NLU模型的？我们认为这还是有必要的，虽然说一些以NLU为辅助的任务可以使用LLM进行端到端重构，但是还是有大量的场景需要专用的、小的NLU模型。这里举一些例子，抛转引玉。\u003C\u002Fp\u003E\u003Col data-tool=\"mdnice编辑器\" style=\"margin-top: 8px;margin-bottom: 8px;padding-left: 25px;\" class=\"list-paddingleft-1\"\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E受资源、成本、时间要求等限制，无法使用大模型的场景，如端上场景等。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E以NLU为最终目的的场景，从性价比考虑，无需使用通用大模型。如数据挖掘等。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Csection style=\"margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(1, 1, 1);\"\u003E\u003Cp style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;color: black;\"\u003E以NLU为重要组件，整体方案成熟，无需使用LLM重构的场景，如信息检索等。\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E因此，大模型的出现只是缩小了NLU的使用范围，但对高效高质专用模型的需求依然存在。超算替代不了PC, intel 酷睿也替代不了Arm单片机，其中原因相似。以上仅一家之言，还请各位指教。\u003C\u002Fp\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;line-height: 26px;\"\u003E\u003Cbr mpa-from-tpl=\"t\"\u003E\u003C\u002Fp\u003E\u003Csection data-mpa-template=\"t\" mpa-from-tpl=\"t\"\u003E\u003Csection data-mpa-template=\"t\" mpa-from-tpl=\"t\"\u003E\u003Cspan style=\"padding-left: 10px;font-size: 18px;display: inline-block;border-left: 5px solid rgb(222, 198, 251);color: rgb(89, 89, 89);\"\u003E一起交流\u003C\u002Fspan\u003E\u003Cspan style=\"padding-left: 10px;font-size: 18px;display: inline-block;border-left: 5px solid rgb(222, 198, 251);color: rgb(89, 89, 89);\"\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"margin-top: 10px;margin-bottom: 10px;padding-top: 8px;padding-bottom: 8px;color: rgb(89, 89, 89);font-family: Optima-Regular, Optima, PingFangTC-Light, PingFangSC-light, PingFangTC-light;letter-spacing: 2px;text-align: left;white-space: normal;font-size: 14px;line-height: 26px;word-spacing: 2px;user-select: auto;\"\u003E\u003Cspan style=\"font-size: 15px;\"\u003E想和你一起学习进步！『\u003Cstrong mpa-from-tpl=\"t\"\u003ENewBeeNLP』\u003C\u002Fstrong\u003E目前已经建立了多个不同方向交流群（\u003Cspan style=\"color: rgb(255, 120, 0);\"\u003E\u003Cstrong mpa-from-tpl=\"t\"\u003E机器学习 \u002F 深度学习 \u002F 自然语言处理 \u002F 搜索推荐 \u002F 图网络 \u002F 面试交流 \u002F&nbsp;\u003C\u002Fstrong\u003E\u003C\u002Fspan\u003E等），名额有限，赶紧添加下方微信加入一起讨论交流吧！（注意一定o要\u003Cstrong mpa-from-tpl=\"t\"\u003E备注信息\u003C\u002Fstrong\u003E才能通过）\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages wxw-img\" data-croporisrc=\"https:\u002F\u002Fmmbiz.qpic.cn\u002Fmmbiz_jpg\u002FDHibuUfpZvQfLTORzvcliawJtWWVz6PlXn37UodqVGPXWjuC2EKWmFboaINsADH1HNHtuA9R7XvocIlcHR8mgVTg\u002F0?wx_fmt=jpeg\" data-cropx1=\"100.88235294117646\" data-cropx2=\"556.6332179930796\" data-cropy1=\"275.34948096885813\" data-cropy2=\"741.7820069204153\" data-galleryid=\"\" data-ratio=\"1.0241228070175439\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"456\" style=\"width: 210px !important;height: auto !important;visibility: visible !important;\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F7f096db6524ea49f83546900533982911693806602629.webp\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F7f096db6524ea49f83546900533982911693806602629.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003C\u002Fspan\u003E\u003C\u002Fsection\u003E\u003Cp\u003E\u003Cbr mpa-from-tpl=\"t\"\u003E\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003Cp\u003E\u003Cbr mpa-from-tpl=\"t\"\u003E\u003C\u002Fp\u003E\u003Cpre data-tool=\"mdnice编辑器\" style=\"margin-top: 0em;outline: 0px;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;word-spacing: 1px;color: rgb(105, 105, 105);widows: 1;caret-color: rgb(0, 0, 0);visibility: visible;\"\u003E\u003Cpre data-tool=\"mdnice编辑器\" style=\"margin-top: 0em;outline: 0px;letter-spacing: 0.544px;visibility: visible;\"\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;outline: 0px;letter-spacing: 0.544px;white-space: normal;font-family: arial;font-size: 15px;caret-color: rgb(51, 51, 51);line-height: 30px;color: rgb(80, 80, 80);text-align: right;\"\u003E\u003Cspan style=\"outline: 0px;font-size: 14px;\"\u003E\u003Cstrong style=\"outline: 0px;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;letter-spacing: 0.544px;color: rgb(0, 82, 255);\"\u003E\u003Cbr mpa-from-tpl=\"t\"\u003E\u003C\u002Fstrong\u003E\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\u003Csection data-mpa-template=\"t\" mpa-from-tpl=\"t\"\u003E\u003Csection data-mpa-template=\"t\" mpa-from-tpl=\"t\"\u003E\u003Csection data-mpa-template=\"t\" mpa-from-tpl=\"t\"\u003E\u003Csection data-tools=\"新媒体排版\" data-id=\"3667731\" data-style-type=\"undefined\" mpa-from-tpl=\"t\"\u003E\u003Csection data-id=\"3464974\" data-style-type=\"undefined\" style=\"user-select: auto;max-width: 100%;\" mpa-from-tpl=\"t\"\u003E\u003Csection label=\"小黄人科技\" donone=\"shifuMouseDownCard('shifu_c_018')\" style=\"margin-top: 5px;padding: 10px 1em;white-space: normal;font-family: 微软雅黑;box-sizing: border-box;text-align: center;text-shadow: rgb(255, 255, 255) 0px 1px 0px;border-width: 1px;border-style: solid;border-color: rgb(102, 102, 102);border-radius: 10px;user-select: auto;max-width: 100%;overflow-wrap: break-word !important;\" mpa-from-tpl=\"t\"\u003E\u003Cp style=\"text-align: center;\"\u003E\u003Cimg class=\"rich_pages __bg_gif wxw-img\" data-ratio=\"0.7415730337078652\" data-s=\"300,640\" data-type=\"gif\" data-w=\"1068\" height=\"792\" width=\"1068\" style=\"font-family: 微软雅黑;text-align: center;white-space: normal;width: 677px !important;height: auto !important;visibility: visible !important;\" data-src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F7949d66925d484d631cba8a71bf4603f1693806602629.webp\" src=\"https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002F7949d66925d484d631cba8a71bf4603f1693806602629.webp\" referrerpolicy=\"no-referrer\"\u003E\u003C\u002Fp\u003E\u003C\u002Fsection\u003E\u003C\u002Fsection\u003E\u003C\u002Fsection\u003E\u003C\u002Fsection\u003E\u003C\u002Fsection\u003E\u003C\u002Fsection\u003E\u003Cp data-tool=\"mdnice编辑器\" style=\"padding-top: 8px;padding-bottom: 8px;outline: 0px;letter-spacing: 0.544px;white-space: normal;font-family: arial;font-size: 15px;caret-color: rgb(51, 51, 51);line-height: 30px;color: rgb(80, 80, 80);text-align: right;\"\u003E\u003Cspan style=\"outline: 0px;font-size: 14px;\"\u003E\u003Cstrong style=\"outline: 0px;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;letter-spacing: 0.544px;color: rgb(0, 82, 255);\"\u003E\u003C\u002Fstrong\u003E\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\u003C\u002Fpre\u003E\u003C\u002Fpre\u003E\u003C\u002Fsection\u003E\u003Cp style=\"display: none;margin-bottom: 24px;\"\u003E\u003Cstrong style=\"outline: 0px;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;letter-spacing: 0.544px;color: rgb(0, 82, 255);\"\u003E\u003Cmp-style-type data-value=\"3\"\u003E\u003C\u002Fmp-style-type\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E\u003C\u002Fbody\u003E\u003C\u002Fhtml\u003E",cover_url:at,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,summary:aq,story_show_user_name:au,user_name:au,user_avatar:"https:\u002F\u002Fhub-avatar.baai.ac.cn\u002Fuser\u002F19478.png",story_ext:{id:30117,story_id:ap,hot_score:av,coefficient:c,final_score:av,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:aw,updated_at:aw,remark_count:b,status:c},tag_names:[{title:"自然语言处理",id:20},{title:"大模型",id:ax},{title:"开放科学",id:1009}],user_ids:[],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:"111",remark_count:d,user_story_cnt:"15",user_comment_cnt:d,description:aq},headConfig:{title:ar,keywords:"自然语言处理,大模型,开放科学",content:"论文链接：SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding（https:\u002F\u002Farxiv.org\u002Fabs\u002F2308.10529）GitHub链接：http",id:ap,cover_url:at,created_at_edit:as,description:aq},merge_data:[]}],fetch:{},error:f,state:{fragment:{events:[],banners:[],leaderboards:[],hotTags:[],tagInfo:{},eventTicket:f,hotWords:[]},resource:{"/":{data:[{story_info:{id:ay,title:"Reddit对LaMDA模型的探讨：并非无状态，采用双重过程，相比它编辑维基百科的方式，有没有感情并不重要",user_id:14718,created_at:"2022-06-22 14:32 分享",url:"https:\u002F\u002Fwww.reddit.com\u002Fr\u002FMachineLearning\u002Fcomments\u002Fvgtydo\u002Fd_two_flaws_in_discussions_surrounding_the_recent\u002F",host:"www.reddit.com",content:"I'm sure everyone here has heard about the LaMDA sentience controversy by now, so in addition to linking to its arxiv full text (\"LaMDA: Language Models for Dialog Applications\" by Thoppilan, et al., 2022), I'd also like to correct a few points that I see most people getting wrong.\nFirst, unlike pla...",cover_url:m,story_show_user_name:az,user_name:az,user_avatar:"https:\u002F\u002Fhub-avatar.baai.ac.cn\u002Fsso-user\u002F3846.png",tag_names:[{title:"讨论",id:3},{title:"预训练模型",id:ax}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:"336",remark_count:d,session_user_id:g},is_event:a,story_id:ay},{story_info:{id:aA,title:"扩散模型又杀疯了！这一次被攻占的领域是...",user_id:aB,created_at:"2022-06-22 12:47 分享",url:"https:\u002F\u002Fmp.weixin.qq.com\u002Fs\u002FWfrkccqsOPlrQDja6dPuaA",host:i,content:"扩散模型最早在图像生成领域大火，随后扩展到了其他连续域，例如语音、视频、点云数据，最近Google发布的用于文本到图像生成的GLIDE模型，更是让扩散模型从AI圈内火到了圈外。\n不过，虽然扩散模型的热度极高，但是面向离散变量的扩散模型的性能一直欠佳，特别是在语言，图等结构当中。\n最近，斯坦福大学自然语言处理研究组在利用扩散模型解决自然语言处理问题中取得了新的进展。\n具体说来，在可控自然语言生成任务上，研究者们利用连续扩散模型，对预训练的语言生成模型进行可插拔的操控，就能够在许多任务上达到甚至超过Fine-Tuning的效果，大幅度超越了之前的工作。\n这篇工作从方法和实验上都非常的新颖和扎实，短...",cover_url:"https:\u002F\u002Fsimg.baai.ac.cn\u002Fuploads\u002F2022\u002F06\u002F77facada5dd28d5fa472fe3e2510f1ac.png",story_show_user_name:ao,user_name:ao,user_avatar:aC,tag_names:[{title:"图像感知",id:24},{title:aD,id:aE}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:"204",remark_count:d,session_user_id:g},is_event:a,story_id:aA},{event_info:{id:"441",name:"AI TIME丨各大高校学者开启 ICLR 专场二",time_desc:"2022-06-23 13:40:00",start_time:"20220623T054000Z",end_time:"20220623T100000Z",image_url:"https:\u002F\u002Fticket-assets.baai.ac.cn\u002Fuploads\u002Fae69fab40b0d0bf8a3677535b132bbc8.jpeg",brief:"来自伊利诺伊大学厄巴纳-香槟分校、中国科学技术大学、香港中文大学、上海交通大学、清华大学、意大利特伦托大学、剑桥大学、腾讯人工智能实验室、麻省理工学院、亚利桑那州立大学、达特茅斯学院、RIKEN AIP 深度学习理论组、冲绳科学技术大学院大学的学者。",address:"线上会议",company:"AI TIME",button_msg:"立即报名",icon_msg:"报名中",color_status:l,order_status:a,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:"149",remark_count:d,session_user_id:g},is_event:l,story_id:18204},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:aF,title:"将有色液体图像转换成透明液体，CMU教机器人准确掌控向杯中倒多少水",user_id:aB,created_at:"2022-06-22 10:17 分享",url:"https:\u002F\u002Fmp.weixin.qq.com\u002Fs\u002FzjaP5-AB6ooKDECOOEdHoQ",host:i,content:"如果机器人可以倒液体，则可以帮助我们自动完成烹饪、将药品倒入药瓶或给植物浇水等任务。但是，透明液体在图像中很难被感知出来，完全透明的液体可以提供的唯一视觉信号是光线穿过液体的折射。此外，获得液体的深度测量同样不容易，因为液体会折射所投射的红外光。\n\n\n\n以往的工作已经探索了机器人在各种环境下倒水，但都需要在环境或数据收集方法上做出重大妥协。透明液体细分的方法需要在训练期间加热液体，以在热成像仪观察下获得真值标签。\n\n然而，为训练加热液体是一个单调乏味的过程，对可以轻松收集多少训练数据有限制。其他方法需要从多视角、背景、重量测量或液体运动等方面观察液体，这些施加在环境上的要求限制了这些方法的适用...",cover_url:"https:\u002F\u002Fsimg.baai.ac.cn\u002Fuploads\u002F2022\u002F06\u002F05a4e8f30300c61510ee389a143dad16.png",story_show_user_name:ao,user_name:ao,user_avatar:aC,tag_names:[{title:"科学应用",id:57},{title:aD,id:aE}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:131,remark_count:b,session_user_id:g},is_event:a,story_id:aF},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r},{story_info:{id:s,title:ag,user_id:g,created_at:ah,created_at_edit:ai,formart_created_at:j,url:aj,host:i,content:ak,cover_url:al,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:am,story_id:s,hot_score:G,coefficient:c,final_score:G,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:an,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:s},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:H,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:f,tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:a,remark_count:d},is_event:a,story_id:H},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r},{story_info:{id:s,title:ag,user_id:g,created_at:ah,created_at_edit:ai,formart_created_at:j,url:aj,host:i,content:ak,cover_url:al,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:am,story_id:s,hot_score:G,coefficient:c,final_score:G,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:an,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:s},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:H,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:f,tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:a,remark_count:d},is_event:a,story_id:H},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r},{story_info:{id:s,title:ag,user_id:g,created_at:ah,created_at_edit:ai,formart_created_at:j,url:aj,host:i,content:ak,cover_url:al,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:am,story_id:s,hot_score:G,coefficient:c,final_score:G,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:an,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:s},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:H,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:f,tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:a,remark_count:d},is_event:a,story_id:H},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r},{story_info:{id:s,title:ag,user_id:g,created_at:ah,created_at_edit:ai,formart_created_at:j,url:aj,host:i,content:ak,cover_url:al,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:am,story_id:s,hot_score:G,coefficient:c,final_score:G,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:an,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:s},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:H,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:f,tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:a,remark_count:d},is_event:a,story_id:H},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r},{story_info:{id:s,title:ag,user_id:g,created_at:ah,created_at_edit:ai,formart_created_at:j,url:aj,host:i,content:ak,cover_url:al,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:am,story_id:s,hot_score:G,coefficient:c,final_score:G,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:an,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:s},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:H,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:f,tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:a,remark_count:d},is_event:a,story_id:H},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r},{story_info:{id:s,title:ag,user_id:g,created_at:ah,created_at_edit:ai,formart_created_at:j,url:aj,host:i,content:ak,cover_url:al,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:am,story_id:s,hot_score:G,coefficient:c,final_score:G,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:an,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:s},{story_info:{id:n,title:I,user_id:g,created_at:J,created_at_edit:K,formart_created_at:j,url:m,content:L,cover_url:m,is_original:c,is_anonymous:c,is_following:c,merged_story_id:b,story_show_user_name:M,story_ext:{id:N,story_id:n,hot_score:t,coefficient:c,final_score:t,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:O,updated_at:y,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:z,remark_count:d},is_event:a,story_id:n},{story_info:{id:H,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:f,tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:a,remark_count:d},is_event:a,story_id:H},{story_info:{id:o,title:A,user_id:g,created_at:B,created_at_edit:C,formart_created_at:j,url:D,host:i,content:E,cover_url:F,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:P,story_id:o,hot_score:u,coefficient:c,final_score:u,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:Q,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:o},{story_info:{id:q,title:R,user_id:g,created_at:S,created_at_edit:T,formart_created_at:j,url:U,host:i,content:V,cover_url:m,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:W,story_id:q,hot_score:w,coefficient:c,final_score:w,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:X,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:v,remark_count:d},is_event:a,story_id:q},{story_info:{id:r,title:Y,user_id:g,created_at:Z,created_at_edit:_,formart_created_at:$,url:aa,host:i,content:ab,cover_url:ac,is_original:b,is_anonymous:b,is_following:c,merged_story_id:b,story_show_user_name:e,user_name:e,user_avatar:k,story_ext:{id:ad,story_id:r,hot_score:x,coefficient:c,final_score:x,comment_count:b,vote_count:b,read_count:b,deleted_at:f,created_at:ae,updated_at:p,remark_count:b,status:c},tag_names:[{title:h,id:c}],status:c,is_marked:a,is_voted:a,is_reported:a,can_editor:a,can_delete:a,comment_count:d,final_score:af,remark_count:d},is_event:a,story_id:r}],hasNextPage:l,pageIndex:7,error:f,loading:a},"/events":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/comments":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users/favorites":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users/activities":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users/events":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users/comments":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users/messages":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l},"/users/stories":{data:[],error:f,loading:l,pageIndex:c,hasNextPage:l}},searchForm:{searchValue:m,showSearchHistory:a,showSearchResults:a,showSearchForm:l,showCategoryMenu:a,hoverIndex:-1},system:{platform:{isTablet:a,isiPhone:a,isAndroid:a,isApp:a,isPc:l,isEdge:a,isNativeChrome:a,isSafari:a},isLogin:f,loginInfo:{},isNewMessage:a,browserRouteState:{}}},serverRendered:l,routePath:"\u002Fview\u002F30166",config:{_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:f}}}}(false,0,1,"0","@你到这干嘛来了1",null,16,"资讯","mp.weixin.qq.com","06\u002F17","https:\u002F\u002Fhub-avatar.baai.ac.cn\u002Fsso-user\u002F23.png",true,"",9364,9362,"2022-06-21T07:15:03.000000Z",9361,9360,9365,9.37,8.91,"9",8.9,7.15,"2022-06-21T07:15:04.000000Z","10","IJCAI2022|鲁棒的Node-NodeLevel自对齐图对比学习","2022-06-17 11:12 分享","2022-06-17 11:12:56","https:\u002F\u002Fmp.weixin.qq.com\u002Fs\u002FPy4vVQNTJcxKGx-NngTKgQ","\n&nbsp;\n©作者 | Dream\n单位&nbsp;| 浙江大学\n研究方向 | 图表示学习\n&nbsp;\n&nbsp;\n本文介绍一下我们自己的工作，该论文是一篇图自监督学习的工作，被 IJCAI 2022 接收。\n\n\n&nbsp;\n论文标题：\nRoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning\n论文链接：\nhttps:\u002F\u002Farxiv.org\u002Fabs\u002F2204.13846\n代码链接：\nhttps:\u002F\u002Fgithub.com\u002FZhuYun97\u002FRoSA\n&nbsp;\n近些年来，图自监督学习进...","https:\u002F\u002Fsimg.baai.ac.cn\u002Fhubview\u002F63cf59ac3c1886e3a5ff5cd6bbf2fa2c.gif",9.54,9363,"test12334444","2022-06-17 16:11","2022-06-17 16:11:59","&lt;section style=\"margin-bottom: 8px; margin-left: 0px; margin-right: 0px;\"&gt;&lt;img class=\"rich_pages wxw-img\" style=\"margin: 0px; padding: 0px; max-width: 100%; height: auto !important; vertical-align: bottom; font-size: 17px; font-style: normal; font-variant-ligatures: normal; font-variant-cap...","匿名",9319,"2022-06-17T08:11:59.000000Z",9318,"2022-06-17T03:12:56.000000Z","R.I.P,Jian.Wealreadymissyou.","2022-06-17 11:02 分享","2022-06-17 11:02:58","https:\u002F\u002Fmp.weixin.qq.com\u002Fs\u002Fi9PpK11GLcA8rbDngR0Kug","\n&nbsp;\n\n文\u002F印奇\n&nbsp;\n2022年6月14日凌晨，在睡梦中被命运的噩耗唤醒，我们永远的老师、朋友、战友孙剑离开了我们。没有告别，骤然离去。从不敢相信，到不愿接受，在过去的两天时间里，难以平复的悲痛充斥在每个角落，一切点滴过往如电影般涌现。\n&nbsp;\n跟孙剑的第一次见面，是在十四年前的夏天，我大二去 MSRA 参加暑期实习面试。那时的孙剑已是年轻的科研“大神”，手握 CVPR、SIGGRAPH 的顶会一作。孙剑给我的第一印象是特别安静，面试的具体内容记不太清了，只记得一道线性代数的题我答得不好。但后来，我还是幸运地拿到了实习生的 offer，正式开始了我的计算机视觉科研之路...",9317,"2022-06-17T03:02:58.000000Z","【深度学习】Rxn-hypergraph：基于图神经网络的化学反应编码","2022-06-16 10:02 分享","2022-06-16 10:02:07","06\u002F16","https:\u002F\u002Fmp.weixin.qq.com\u002Fs\u002FeyjJDfHMnBuzgT1McEuJUA","——背景——\n&nbsp;\n化学反应的表示和编码和化学分子的编码同样重要。合适的化学反应编码可以改善与化学反应有关的预测任务结果，例如反应产率预测、反应速率预测、化学反应分类等。来自加州大学欧文分校Pierre Baldi课题组的Mohammadamin Tavakoli和Alexander Shmakov二人指出，现有的化学反应编码方式存在四种不足：（1）普适性不够强，一些基于固定算法的编码方式，如Schneider等人提出的reactionFP[1]，不一定能兼容多种不同的预测任务；（2）鲁棒性不够高，基于语言模型的编码方式如Schwaller等人提出的rxnfp[2]，在输入表示同一反应...","https:\u002F\u002Fsimg.baai.ac.cn\u002Fhubview\u002F8df89d0422fe5f5152bc6b67f96b60b9.png",9316,"2022-06-16T02:02:07.000000Z","8","JeffDean等人新作：换个角度审视语言模型，规模不够发现不了","2022-06-17 17:56 分享","2022-06-17 17:56:22","https:\u002F\u002Fmp.weixin.qq.com\u002Fs\u002FlNbACINCpRi0F6-NS2ZcmQ","\n\n\n\n\n\n\n\n\n\n\n机器之心报道\n编辑：陈萍\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n这是一篇来自谷歌、斯坦福大学、北卡罗来纳大学教堂山分校以及 DeepMind 四个机构的研究，论文从「突现（emergence）」的角度介绍大模型，所谓的突现，即有些现象不存在于较小的模型中但存在于较大的模型中。\n\n\n\n近年来，语言模型对自然语言处理 (NLP) 产生了革命性影响。众所周知，扩展语言模型，例如参数等，可以在一系列下游 NLP 任务上带来更好的性能和样本效率。在许多情况下，扩展对性能的影响通常可以通过扩展定律进行预测，一直以来，绝大多数研究者都在研究可预测现象。\n&nbsp;\n相反，包括 Jeff Dea...","https:\u002F\u002Fsimg.baai.ac.cn\u002Fhubview\u002F33e541d334404fdd3dd625925c65b21b.png",9320,"2022-06-17T09:56:22.000000Z","苦行僧",30166,"SeqGPT是一款开源的大型语言模型，可以用于开放领域序列理解任务。该模型的代码已经上传到GitHub，同时也提供了在线体验地址。论文详细介绍了SeqGPT的设计和性能评估。","SeqGPT: 开箱即用的开放域自然语言理解大模型","2023-09-04 13:50:08","https:\u002F\u002Fsimg.baai.ac.cn\u002Fhub-detail\u002Fa0263e91a7131c9c0bebb42a41c78ac31693806602626.webp","NewBeeNLP",455,"2023-09-04T05:50:08.000000Z",90,18209,"戴一鸣",18207,330,"https:\u002F\u002Fhub-avatar.baai.ac.cn\u002Fsso-user\u002F4497.png","论文",1007,18198));</script><script src="/_nuxt/47317e0.js" defer></script><script src="/_nuxt/337bdbf.js" defer></script><script src="/_nuxt/02421f5.js" defer></script><script src="/_nuxt/ba2b37f.js" defer></script><script src="/_nuxt/9174bba.js" defer></script>
  </body>
</html>
