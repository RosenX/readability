<html lang="zh" data-ios="true" class="itcauecng" data-theme="light" data-rh="data-theme"><head><meta charset="utf-8"><title>[必读] LLM 应用开发全栈指南 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0,viewport-fit=cover"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=10,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-rh="true" name="keywords" content="LLM（大型语言模型）,Prompt工程,UI/UX"><meta data-rh="true" name="description" content="之前介绍过 Full Stack Deep Learning 这门课程，当之无愧是 Deep Learning 工程化产品化方面最好的课程（或许没有之一）。最近他们又顺应最近大模型领域的发展，推出了 Full Stack LLM Bootcamp 课程，同样也是非…"><meta data-rh="true" property="og:title" content="[必读] LLM 应用开发全栈指南"><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/629589593"><meta data-rh="true" property="og:description" content="之前介绍过 Full Stack Deep Learning 这门课程，当之无愧是 Deep Learning 工程化产品化方面最好的课程（或许没有之一）。最近他们又顺应最近大模型领域的发展，推出了 Full Stack LLM Bootcamp 课程，同样也是非…"><meta data-rh="true" property="og:image" content="https://pic1.zhimg.com/v2-5db37b62967d3d99a9fa05bbc2633f15_720w.jpg?source=172ae18b"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="og:site_name" content="知乎专栏"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png" sizes="152x152"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.d5793cac.png" sizes="120x120"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7abf3393.png" sizes="76x76"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.362a8eac.png" sizes="60x60"><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"><link rel="dns-prefetch" href="//static.zhimg.com"><link rel="dns-prefetch" href="//pica.zhimg.com"><link rel="dns-prefetch" href="//picx.zhimg.com"><link rel="dns-prefetch" href="//pic1.zhimg.com"><link rel="dns-prefetch" href="//pic2.zhimg.com"><link rel="dns-prefetch" href="//pic3.zhimg.com"><link rel="dns-prefetch" href="//pic4.zhimg.com"><link rel="dns-prefetch" href="//static.zhihu.com"><script nonce="72679e22-0770-4fc8-8c06-5c9b62cfed71" data-web-reporter-config="{&quot;platform&quot;:&quot;web&quot;,&quot;project&quot;:&quot;heifetz&quot;}">!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports):"function"==typeof define&&define.amd?define(["exports"],t):t((e=e||self).webReporter={})}(this,function(e){"use strict";var t={},n=!1,o=function(){var e,o,r,a,i;return n||(e=document.querySelector("script[data-web-reporter-config]"),o=e&&e.dataset.webReporterConfig||"{}",r=JSON.parse(o),a=r.platform,i=r.project,t={platform:a,project:i},n=!0),t};function r(e){return a(function(){return localStorage.getItem(e)})()}function a(e){return function(){try{return e.apply(void 0,arguments)}catch(e){}}}var i=a(function(e,t){var n={platform:"web",project:o().project,clientTimestamp:+new Date};!function(e,t,n){"1"===r("weber:logenabled")&&console.log("[web-reporter]%o",{type:e,base:t,data:n})}(e,n,t),function(e,t){var n=btoa(JSON.stringify(t));if("undefined"!=typeof Blob&&window.navigator&&window.navigator.sendBeacon){var o=new Blob([n],{type:"text/plain"});navigator.sendBeacon(e,o)}else{var r=new XMLHttpRequest;r.open("POST",e),r.withCredentials=!1,r.setRequestHeader("Content-Type","text/plain;charset=UTF-8"),r.send(n)}}(r("weber:api")||"https://apm.zhihu.com/collector/web_json",{type:e,base:n,data:t})});e.report=i,Object.defineProperty(e,"__esModule",{value:!0})});
</script><link href="https://static.zhihu.com/heifetz/680.216a26f4.bc3dd4670546193a4781.css" crossorigin="" rel="stylesheet"><link href="https://static.zhihu.com/heifetz/column.216a26f4.3326da597f7431c1ea67.css" crossorigin="" rel="stylesheet"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/GoodsRecommendGoodsCardList.216a26f4.d95ce79191cdf8d7ac28.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/3280.216a26f4.8bfc371d6d7cfdc6aeec.css" crossorigin="anonymous"><script nonce="72679e22-0770-4fc8-8c06-5c9b62cfed71">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"824-bcf32e16\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script><script crossorigin="anonymous" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;824-bcf32e16&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrorsPreset&quot;:&quot;ReactApp&quot;,&quot;tags&quot;:{&quot;app_name&quot;:&quot;heifetz&quot;}}" src="https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js"></script><style data-emotion-css="uzm3ri">.css-uzm3ri{position:fixed;top:0;right:0;left:0;z-index:101;display:none;height:2px;pointer-events:none;background:#056DE8;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}</style><style data-emotion-css="15ro776">.css-15ro776{margin-right:4px;}</style><style data-emotion-css="183aq3r">.css-183aq3r{border-radius:24px;padding:0 15px;font-size:13px;line-height:28px;-webkit-flex:none;-ms-flex:none;flex:none;}</style><style data-emotion-css="1ie3c6f">.css-1ie3c6f{fill:#999999;margin:0 10px;}</style><style data-emotion-css="78p1r9">.css-78p1r9{box-sizing:border-box;margin:0;min-width:0;margin-left:auto;margin-right:auto;max-width:690px;margin-top:0;}@media screen and (min-width:40em){.css-78p1r9{margin-top:1em;}}</style><style data-emotion-css="8do0fs">.css-8do0fs{position:relative;padding-bottom:52.5%;height:0;border-radius:inherit;}</style><style data-emotion-css="1rb5503">.css-1rb5503{box-sizing:border-box;margin:0;min-width:0;position:relative;padding-bottom:52.5%;height:0;border-radius:inherit;}</style><style data-emotion-css="1ld0bim">.css-1ld0bim{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;}</style><style data-emotion-css="1ujtx97">.css-1ujtx97{object-fit:cover;background-color:#F6F6F6;}</style><style data-emotion-css="uodor8">.css-uodor8{border-radius:50%;}</style><style data-emotion-css="kl6aur">.css-kl6aur{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:34px;height:34px;border-radius:50%;}</style><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1yuhvjn">.css-1yuhvjn{margin-top:16px;}</style><style data-emotion-css="376mun">.css-376mun{position:relative;display:inline;}</style><style data-emotion-css="1hhle02">.css-1hhle02 .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1hhle02 .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1hhle02 .FileLinkCard-info{margin-left:12px;}.css-1hhle02 .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1hhle02 .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1hhle02 .FileLinkCard-source{white-space:pre;}.css-1hhle02 img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1r0wf39">.css-1r0wf39 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1r0wf39 .LinkCard.new,.css-1r0wf39 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1r0wf39 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1r0wf39 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1r0wf39 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1r0wf39 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1r0wf39 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1r0wf39 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1r0wf39 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1r0wf39 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1r0wf39 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1r0wf39 .LinkCard.old,.css-1r0wf39 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="3np2dk">.css-3np2dk .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-3np2dk .LinkCard.old,.css-3np2dk .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-3np2dk .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-3np2dk .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-3np2dk .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-3np2dk .LinkCard.new,.css-3np2dk .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-3np2dk .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-3np2dk .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-3np2dk .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-3np2dk .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-3np2dk .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-3np2dk .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-3np2dk .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-3np2dk .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-3np2dk .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-3np2dk .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-3np2dk .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-3np2dk .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-3np2dk .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-3np2dk .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-3np2dk .FileLinkCard-info{margin-left:12px;}.css-3np2dk .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-3np2dk .FileLinkCard-source{white-space:pre;}.css-3np2dk img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1t538q animation-1yvu044">.css-1t538q{word-break:break-word;line-height:1.6;}.css-1t538q > [data-first-child]{margin-top:0;}.css-1t538q > :last-child{margin-bottom:0;}.css-1t538q h1,.css-1t538q h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:500;}.css-1t538q h3,.css-1t538q h4,.css-1t538q h5,.css-1t538q h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:500;}.css-1t538q u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #444444;}.css-1t538q b{font-weight:500;}.css-1t538q sup{font-size:0.8em;}.css-1t538q sup[data-draft-type='reference']{color:#175199;}.css-1t538q a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-1t538q a:focus{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(5,109,232,0.3);}.css-1t538q a.ztext-link,.css-1t538q a.internal,.css-1t538q a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #808080;}.css-1t538q a.ztext-link:hover,.css-1t538q a.internal:hover,.css-1t538q a.external:hover{color:#175199;border-bottom:1px solid #175199;}.css-1t538q a.ztext-link > .ellipsis::after,.css-1t538q a.internal > .ellipsis::after,.css-1t538q a.external > .ellipsis::after{content:'...';}.css-1t538q a.ztext-link > .invisible,.css-1t538q a.internal > .invisible,.css-1t538q a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-1t538q a.ztext-link u,.css-1t538q a.internal u,.css-1t538q a.external u{border:none;}.css-1t538q a.member_mention{color:#175199;}.css-1t538q a.member_mention:hover{border-bottom:1px solid #175199;}.css-1t538q a.UserLink-link{color:#175199;}.css-1t538q a.UserLink-link:hover{border-bottom:1px solid #175199;}.css-1t538q p{margin:1.4em 0;}.css-1t538q p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-1t538q p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-1t538q hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #D3D3D3;}.css-1t538q img[eeimg]{max-width:100%;vertical-align:middle;}.css-1t538q img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-1t538q img[eeimg="2"]{margin:1.4em auto;display:block;}.css-1t538q blockquote{margin:1.4em 0;padding-left:1em;color:#646464;border-left:3px solid #D3D3D3;}.css-1t538q ol,.css-1t538q ul{margin:1.4em 0;padding:0;width:100%;}.css-1t538q ol ol,.css-1t538q ul ol,.css-1t538q ol ul,.css-1t538q ul ul{margin:0;}.css-1t538q ol li::before,.css-1t538q ul li::before{width:1em;}.css-1t538q ol > ol,.css-1t538q ul > ol,.css-1t538q ol > ul,.css-1t538q ul > ul{display:table-row;}.css-1t538q ol > ol::before,.css-1t538q ul > ol::before,.css-1t538q ol > ul::before,.css-1t538q ul > ul::before{display:table-cell;content:'';}.css-1t538q ul{display:table;}.css-1t538q ul>li{display:table-row;list-style:none;}.css-1t538q ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-1t538q ol{display:table;counter-reset:ol;}.css-1t538q ol > li{display:table-row;list-style:none;}.css-1t538q ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-1t538q ol ol{counter-reset:ol2;}.css-1t538q ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-1t538q ol ol ol{counter-reset:ol3;}.css-1t538q ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-1t538q ol ol ol ol{counter-reset:ol4;}.css-1t538q ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-1t538q figure{margin:1.4em 0;}.css-1t538q figure .content_image,.css-1t538q figure .origin_image{margin:0 auto;}.css-1t538q figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#999999;}.css-1t538q figure + figure{margin-top:calc(1.4em * 1.6);}.css-1t538q figure[data-size='small'],.css-1t538q figure:not([data-size]) > [data-size='small']{clear:both;}.css-1t538q figure[data-size='left'],.css-1t538q figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-1t538q figure[data-size='right'],.css-1t538q figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-1t538q figure[data-size='collapse']{margin-bottom:0;}.css-1t538q figure[data-size='collapse'] + figure{margin-top:0;}.css-1t538q .content_image,.css-1t538q .origin_image{display:block;max-width:100%;height:auto;margin:1.4em auto;}.css-1t538q .content_image[data-size='small'],.css-1t538q .origin_image[data-size='small']{max-width:40%;}.css-1t538q .content_image.zh-lightbox-thumb,.css-1t538q .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-1t538q code{margin:0 2px;padding:3px 4px;border-radius:3px;font-family:Menlo,Monaco,Consolas,'Andale Mono','lucida console','Courier New',monospace;font-size:0.9em;background-color:#F6F6F6;}.css-1t538q pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#F6F6F6;border-radius:4px;}.css-1t538q pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-1t538q li pre{white-space:pre-wrap;}.css-1t538q table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-1t538q table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-1t538q table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#F6F6F6;}.css-1t538q table[data-draft-type='table'] td,.css-1t538q table[data-draft-type='table'] th{border:1px solid #D3D3D3;line-height:24px;height:24px;padding:3px 12px;}.css-1t538q table[data-draft-type='table'] th{background:#EBEBEB;color:#121212;font-weight:500;}.css-1t538q .video-box,.css-1t538q .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #EBEBEB;border-radius:4px;}.css-1t538q .lazy[data-lazy-status]{background-color:#F6F6F6;}.css-1t538q .lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1yvu044 0.5s ease-in;animation:animation-1yvu044 0.5s ease-in;}.css-1t538q .highlight{margin:1em 0;}.css-1t538q .highlight pre{margin:0;}.css-1t538q .highlight .hll{background-color:#FDFDFD;}.css-1t538q .highlight .c{font-style:italic;color:#999999;}.css-1t538q .highlight .err{color:#F1403C;}.css-1t538q .highlight .k{font-weight:500;}.css-1t538q .highlight .o{font-weight:500;}.css-1t538q .highlight .cm{font-style:italic;color:#999999;}.css-1t538q .highlight .cp{font-weight:500;color:#999999;}.css-1t538q .highlight .c1{font-style:italic;color:#999999;}.css-1t538q .highlight .cs{font-style:italic;font-weight:500;color:#999999;}.css-1t538q .highlight .gd{color:#FF3366;}.css-1t538q .highlight .ge{font-style:italic;}.css-1t538q .highlight .gr{color:#F1403C;}.css-1t538q .highlight .gh{color:#999999;}.css-1t538q .highlight .gi{color:#12b370;}.css-1t538q .highlight .go{color:#808080;}.css-1t538q .highlight .gp{color:#646464;}.css-1t538q .highlight .gs{font-weight:500;}.css-1t538q .highlight .gu{color:#999999;}.css-1t538q .highlight .gt{color:#F1403C;}.css-1t538q .highlight .kc{font-weight:500;}.css-1t538q .highlight .kd{font-weight:500;}.css-1t538q .highlight .kn{font-weight:500;}.css-1t538q .highlight .kp{font-weight:500;}.css-1t538q .highlight .kr{font-weight:500;}.css-1t538q .highlight .kt{font-weight:500;color:#175199;}.css-1t538q .highlight .m{color:#056DE8;}.css-1t538q .highlight .s{color:#F1403C;}.css-1t538q .highlight .na{color:#056DE8;}.css-1t538q .highlight .nb{color:#056DE8;}.css-1t538q .highlight .nc{font-weight:500;color:#175199;}.css-1t538q .highlight .no{color:#056DE8;}.css-1t538q .highlight .ni{color:#5555DD;}.css-1t538q .highlight .ne{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nf{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nn{color:#646464;}.css-1t538q .highlight .nt{color:#175199;}.css-1t538q .highlight .nv{color:#056DE8;}.css-1t538q .highlight .ow{font-weight:500;}.css-1t538q .highlight .w{color:#BFBFBF;}.css-1t538q .highlight .mf{color:#056DE8;}.css-1t538q .highlight .mh{color:#056DE8;}.css-1t538q .highlight .mi{color:#056DE8;}.css-1t538q .highlight .mo{color:#056DE8;}.css-1t538q .highlight .sb{color:#F1403C;}.css-1t538q .highlight .sc{color:#F1403C;}.css-1t538q .highlight .sd{color:#F1403C;}.css-1t538q .highlight .s2{color:#F1403C;}.css-1t538q .highlight .se{color:#F1403C;}.css-1t538q .highlight .sh{color:#F1403C;}.css-1t538q .highlight .si{color:#F1403C;}.css-1t538q .highlight .sx{color:#F1403C;}.css-1t538q .highlight .sr{color:#A5542F;}.css-1t538q .highlight .s1{color:#F1403C;}.css-1t538q .highlight .ss{color:#F1403C;}.css-1t538q .highlight .bp{color:#999999;}.css-1t538q .highlight .vc{color:#056DE8;}.css-1t538q .highlight .vg{color:#056DE8;}.css-1t538q .highlight .vi{color:#056DE8;}.css-1t538q .highlight .il{color:#056DE8;}.css-1t538q .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(18,18,18,0.5);border-radius:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(18,18,18,0.6);}.css-1t538q .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1t538q .LinkCard.old,.css-1t538q .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1t538q .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1t538q .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-1t538q .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1t538q .LinkCard.new,.css-1t538q .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1t538q .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1t538q .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1t538q .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1t538q .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1t538q .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1t538q .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1t538q .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1t538q .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1t538q .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1t538q .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1t538q .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1t538q .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1t538q .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1t538q .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1t538q .FileLinkCard-info{margin-left:12px;}.css-1t538q .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1t538q .FileLinkCard-source{white-space:pre;}.css-1t538q img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}@-webkit-keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}@keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}</style><style data-emotion-css="1k6fd7f">.css-1k6fd7f{margin:0;padding-top:15px;}</style><style data-emotion-css="1any501">.css-1any501{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:40px;height:40px;border-radius:50%;}</style><style data-emotion="css"></style></head><body class="WhiteBg-body PostIndex-body Body--Mobile Body--iOS Body--isAppleDevice" aria-basefontsize="16" data-rh="class"><a id="ariaTipText" role="pagedescription" aria-label="链接，无障碍模式读屏软件服务通道。" aria-atomic="true" href="javascript:void(0)" class="skipAutoFix" onclick="aria.wzaStart();" style="width: 1px; height: 1px;"><img src="" style="width:1px !important;height:1px !important;position:absolute;top:0;"></a><div id="root"><div class="App"><div class="LoadingBar  css-uzm3ri"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content Post-content-mobile" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;字节&quot;,&quot;itemId&quot;:629589593,&quot;title&quot;:&quot;[必读] LLM 应用开发全栈指南&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;629589593&quot;}}}"><div><header class="Sticky MobileAppHeader" style="line-height:50px"><div class="MobileAppHeader-inner"><a class="MobileAppHeader-logo" href="//www.zhihu.com?utm_source=zhihu&amp;utm_campaign=guest_feed&amp;utm_content=guide&amp;utm_medium=zhuanlan&amp;utm_id=0" aria-label="知乎"><svg viewBox="0 0 64 30" fill="#056DE8" width="52" height="24.375"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><div class="MobileAppHeader-actions"><label class="MobileAppHeader-searchBox MobileAppHeader-searchBoxWithUnlogin Input-wrapper"><svg width="16" height="16" viewBox="0 0 24 24" fill="#999" class="ZDI ZDI--Search24 css-15ro776"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M11.5 18.389c3.875 0 7-3.118 7-6.945 0-3.826-3.125-6.944-7-6.944s-7 3.118-7 6.944 3.125 6.945 7 6.945Zm0 1.5c4.694 0 8.5-3.78 8.5-8.445C20 6.781 16.194 3 11.5 3S3 6.78 3 11.444c0 4.664 3.806 8.445 8.5 8.445Z"></path><path d="M16.47 16.97a.75.75 0 0 1 1.06 0l3.5 3.5a.75.75 0 1 1-1.06 1.06l-3.5-3.5a.75.75 0 0 1 0-1.06Z"></path></g></svg><input type="search" value="" class="Input" placeholder="搜索"></label><a class="MobileAppHeader-authLink" href="https://www.zhihu.com/signin?next=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F629589593" data-za-detail-view-name="注册或登录"><svg width="24" height="24" viewBox="0 0 24 24" style="vertical-align:middle;margin-bottom:1px" class="ZDI ZDI--User24" fill="currentColor"><path fill-rule="evenodd" d="M7.25 8A4.75 4.75 0 0 1 12 3.25 4.75 4.75 0 0 1 16.75 8 4.75 4.75 0 0 1 12 12.75 4.75 4.75 0 0 1 7.25 8ZM12 1.75A6.25 6.25 0 0 0 5.75 8a6.248 6.248 0 0 0 3.275 5.498c-2.993 1.03-5.222 3.572-5.521 6.681a.75.75 0 1 0 1.493.144c.31-3.209 3.277-5.819 7.006-5.819.025 0 .05-.001.075-.004 3.692.036 6.622 2.634 6.93 5.823a.75.75 0 1 0 1.492-.144c-.3-3.11-2.527-5.652-5.52-6.684A6.248 6.248 0 0 0 18.25 8 6.25 6.25 0 0 0 12 1.75Z" clip-rule="evenodd"></path></svg></a><button type="button" class="Button css-183aq3r Button--blue">打开App</button><svg width="22" height="22" viewBox="0 0 24 24" class="ZDI ZDI--Dots24 css-1ie3c6f" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></div></div><div></div></header></div><div class="css-78p1r9"><div class="css-1rb5503"><div class="css-1ld0bim"><img src="https://pic1.zhimg.com/v2-5db37b62967d3d99a9fa05bbc2633f15_720w.jpg?source=172ae18b" alt="[必读] LLM 应用开发全栈指南" width="100%" height="100%" class="css-1phd9a0" srcset="https://pic1.zhimg.com/v2-5db37b62967d3d99a9fa05bbc2633f15_200x0.jpg?source=172ae18b 200w,https://pic1.zhimg.com/v2-5db37b62967d3d99a9fa05bbc2633f15_qhd.jpg?source=172ae18b 480w,https://pic1.zhimg.com/v2-5db37b62967d3d99a9fa05bbc2633f15_720w.jpg?source=172ae18b 720w,https://pic1.zhimg.com/v2-5db37b62967d3d99a9fa05bbc2633f15_1440w.jpg?source=172ae18b 1440w" loading="lazy"></div></div></div><article class="Post-Main Post-Main-Mobile" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">[必读] LLM 应用开发全栈指南</h1></header><div class="Post-TimeExtra">1 个月前<!-- --> · 来自专栏 <!-- -->RandomGenerator</div><div class="Post-Author Post-Author-Mobile"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><div class="AuthorInfo"><meta itemprop="name" content="字节"><meta itemprop="image" content="https://picx.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/zijie0"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar AuthorInfo-avatar css-kl6aur" src="https://picx.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b 2x" alt="字节"></a></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">字节</a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText css-0">天地大观，志存高远</div></div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path fill-rule="evenodd" d="M13.25 3.25a1.25 1.25 0 1 0-2.5 0v7.5h-7.5a1.25 1.25 0 1 0 0 2.5h7.5v7.5a1.25 1.25 0 1 0 2.5 0v-7.5h7.5a1.25 1.25 0 0 0 0-2.5h-7.5v-7.5Z" clip-rule="evenodd"></path></svg></span>关注</button></div><div class="Post-RichTextContainer"><div class="css-1yuhvjn"><div class="css-376mun"><div class="RichText ztext Post-RichText css-1t538q" options="[object Object]"><p data-first-child="" data-pid="NG--4eUt">之前介绍过 <a href="https://zhuanlan.zhihu.com/p/218468169" class="internal" data-za-detail-view-id="1043">Full Stack Deep Learning</a> 这门课程，当之无愧是 Deep Learning 工程化产品化方面最好的课程（或许没有之一）。最近他们又顺应最近大模型领域的发展，推出了 <a href="https://link.zhihu.com/?target=https%3A//fullstackdeeplearning.com/llm-bootcamp/" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Full Stack LLM Bootcamp</a> 课程，同样也是非常的高质量。目前已经放出了大部分的视频，周末花了点时间快速看了一遍，记录一下相关收获，也强烈推荐从事 LLM 应用开发的同学关注学习。</p><h2>Launch an LLM App in One Hour</h2><p data-pid="BMgDdGvW">整个讲座的一个导论，信息量不大，先做个热身。</p><p data-pid="dmPcTR_L">介绍了这波 AI 浪潮的一些背景，如大语言模型强大之处，一个模型就能搞定很多不同的任务。进而解锁了 Language User Interface 的很多可能。</p><p data-pid="UnA-YTDC">回顾了下之前的 AI winter，主要原因是<b>期望过高，交付的产品远远无法兑现承诺</b>。而在当前这波浪潮中，已经有很多有价值的产品出现了，比如 ChatGPT，GitHub Copilot 等。自然引导到了基于 LLM 的应用的开发这个主题上来。</p><p data-pid="YkQ-M-fd"><b>开发 MVP 的方式</b></p><ul><li data-pid="rjM64olG">先用各种 playground 或者 chat 界面来做原型。</li><li data-pid="8W60PBJL">利用开源框架来开发应用，优化 prompts。</li></ul><p data-pid="MtY2U26x">Frye 举了个例子，比如先手动把 arxiv 上的 paper 摘要贴给模型，再给模型提问，就能拿到正确答案。接下来再在 notebook 里一步步把流程自动化，并加上更多的优化，如文档下载，分片，index 构建与搜索等。整个流程的确半小时就能搞定。</p><p data-pid="mLf-dy92"><b>部署 MVP 的方式</b></p><ul><li data-pid="WMNfqvNB">使用云平台可以快速进行部署，不过要记得限制 API 开销。</li><li data-pid="Yh_9sAdS">使用简单的 UI，快速上线，收集用户反馈并迭代。</li></ul><p data-pid="I6uuDpay">以他们的 discord bot app 为例，具体使用的 stack 包括：</p><ul><li data-pid="3PitOtNu">模型：OpenAI</li><li data-pid="9vouq5KE">数据存储：MongoDB</li><li data-pid="PCZuYwEc">向量存储：Pinecone</li><li data-pid="T8BmuE6K">Serverless Backend：Modal</li><li data-pid="aV7zkOnB">Discord Bot Server: AWS EC2</li></ul><p data-pid="4luUa4PA">他提到要处理 300 多个 PDF，速度很慢。但利用像 <a href="https://link.zhihu.com/?target=https%3A//modal.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Modal</a> 这样的云服务，可以同时启动上百个 container 来同步执行，速度一下子就快了很多。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-50b584a8e9d3a762a00e4bfc7229018c_b.jpg" data-size="normal" data-rawwidth="2744" data-rawheight="1490" class="origin_image zh-lightbox-thumb" width="2744" data-original="https://pic1.zhimg.com/v2-50b584a8e9d3a762a00e4bfc7229018c_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2744' height='1490'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2744" data-rawheight="1490" class="origin_image zh-lightbox-thumb lazy" width="2744" data-original="https://pic1.zhimg.com/v2-50b584a8e9d3a762a00e4bfc7229018c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-50b584a8e9d3a762a00e4bfc7229018c_b.jpg" data-original-token="v2-159d1e631f323cbe43b5d325d53bc997"></div><figcaption>一键并发载入 pdf</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="5Me3h9ji">Twitter 上也有个类似的帖子讨论 <a href="https://link.zhihu.com/?target=https%3A//twitter.com/ompemi/status/1653032136193060865" class=" wrap external" target="_blank" rel="nofollow noreferrer">当下热门的 LLM 开发 stack 构成</a>，评论区也有很多信息可供参考。</p><h2>LLM Foundations</h2><h3>技术原理</h3><p data-pid="jmaE8Rzg">前面介绍机器学习、深度学习的基础，transformer，embedding 等原理，model hub 等就不展开了，应该大多数同学都了解。作为一名“老机器学习工程师”，看这段都有点恍如隔世的感觉  如果对于动手实现 transformer 有兴趣，推荐可以看下 Karpathy 的这个 <a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1E14y1M75n/" class=" wrap external" target="_blank" rel="nofollow noreferrer">手把手实现 GPT 的教学视频</a>。</p><p data-pid="P7PboSgw">作者也提到了为何 transformer 为何如此有效的一些想法，例如：</p><ul><li data-pid="vtJp7eT9">表达能力很强，feed forward + attention 的海量参数。</li><li data-pid="4LCnyFg2">可优化，通过反向传播算法，而且相比 RNN 这类更容易优化一些？</li><li data-pid="OeJ9Vw9Q">高效，可以<b>有效地扩展利用并行计算资源</b>。这一点非常重要，也是 OpenAI 当年选择 transformer 的一个主要原因。</li></ul><p data-pid="Wo067TWd"><a href="https://link.zhihu.com/?target=https%3A//aizi.substack.com/p/how-does-gpt-3-spend-its-175b-parameters" class=" wrap external" target="_blank" rel="nofollow noreferrer">大语言模型中的参数都用在哪了</a>？可以看到在百亿参数量以上，差不多三分之二的参数实际上是 FFN 参数，剩下的基本都是 attention 参数。所以虽然论文名叫 attention is all you need，但实际上 FFN 仍然起到了很重要的作用。</p><p data-pid="7s_xWEku">另外也提到了一篇来自 Anthropic 的文章 <a href="https://link.zhihu.com/?target=https%3A//transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">In-context Learning and Induction Heads</a>，深入探索了大语言模型 in-context learning 能力的来源。从对 in-context learning 能力的定义，特定的评估方法，再到对各种规格的模型训练过程的细致观察与各种干预实验都非常有意思，很值得一读。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-db6659696afa0f777621094f5776409b_b.jpg" data-size="normal" data-rawwidth="1456" data-rawheight="763" class="origin_image zh-lightbox-thumb" width="1456" data-original="https://pic4.zhimg.com/v2-db6659696afa0f777621094f5776409b_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1456' height='763'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1456" data-rawheight="763" class="origin_image zh-lightbox-thumb lazy" width="1456" data-original="https://pic4.zhimg.com/v2-db6659696afa0f777621094f5776409b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-db6659696afa0f777621094f5776409b_b.jpg" data-original-token="v2-c578e569efafa8d6e8cc4af42b1f68d1"></div><figcaption>Induction Heads</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>LLM 走马观花</h3><p data-pid="Lh5oFRfK">作者依次介绍了一些值得一提的大语言模型，个人感觉当前应用 LLM 的热点主要在 prompting，而训练 LLM 最重要的可能就是<b>高质量数据集的构建</b>了。所以在回看这些模型论文时，可以更多关注一下他们使用了什么样的数据集，以及如何进行清洗和处理。</p><p data-pid="oXiC73Hy"><b>BERT</b></p><p data-pid="xD5dm2XY">Pre-train + fine tune 的任务设计，强大的模型效果，也是当年在 NLP 界引起巨大轰动的一个模型。不过 BERT 是 encoder only 架构，从后续发展来看可能是“刷分”导向带歪了路。</p><p data-pid="j-4RsOOi"><b>T5</b></p><p data-pid="2x7YlgCE">Encoder + decoder 架构。把各种 NLP 任务都统一成 text to text 的转换是一大创新。</p><p data-pid="V9Ke-h0m"><b>GPT/GPT-2</b></p><p data-pid="zPABxxWB">Decoder only 的架构引领了现在的潮流，但在当初的影响力并不大。他们使用的 Byte Pair Encoding 值得关注，在使用词典和 UTF-8 字节码之间找到一个平衡。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-0a4e240dfb4badd095f71230df3ea257_b.jpg" data-size="normal" data-rawwidth="2778" data-rawheight="1606" class="origin_image zh-lightbox-thumb" width="2778" data-original="https://pic4.zhimg.com/v2-0a4e240dfb4badd095f71230df3ea257_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2778' height='1606'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2778" data-rawheight="1606" class="origin_image zh-lightbox-thumb lazy" width="2778" data-original="https://pic4.zhimg.com/v2-0a4e240dfb4badd095f71230df3ea257_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0a4e240dfb4badd095f71230df3ea257_b.jpg" data-original-token="v2-bee32dd538bc123ff0c1b9b1461048fd"></div><figcaption>Byte Pair Encoding</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="L34RxMss"><b>GPT-3</b></p><p data-pid="zVBBo7sl">体现出了强大的 few-shot 和 zero-shot learning 能力，引领了 prompt engineering 风潮。另外有意思的是他们准备了 500B token 的训练数据，但实际只训练了 300B 就停止了。也就是<b>所有训练数据模型只看了一次</b>，跟他们分享中提到的“无损压缩”的思路一致。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-21f3c9652a72bfb449e399a85f096b5e_b.jpg" data-size="normal" data-rawwidth="2794" data-rawheight="1524" class="origin_image zh-lightbox-thumb" width="2794" data-original="https://pic3.zhimg.com/v2-21f3c9652a72bfb449e399a85f096b5e_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2794' height='1524'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2794" data-rawheight="1524" class="origin_image zh-lightbox-thumb lazy" width="2794" data-original="https://pic3.zhimg.com/v2-21f3c9652a72bfb449e399a85f096b5e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-21f3c9652a72bfb449e399a85f096b5e_b.jpg" data-original-token="v2-8c2cf31c686000606c474d7e6e065135"></div><figcaption>GPT-3 的训练数据</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="uSQFxddb"><b>Chinchilla</b></p><p data-pid="h9Qz8Aa_">探索了 scaling law，用 70B 参数加上<b>更多的训练数据</b>达到了 280B Gopher 模型的同等效果。</p><p data-pid="oBeyP3uJ"><b>LLaMA</b></p><p data-pid="Px2-3qil">Chinchilla-optimal 模型，开源发布但不允许商用。最近的 RedPajama 项目中尝试“复现”了 <a href="https://link.zhihu.com/?target=https%3A//www.together.xyz/blog/redpajama" class=" wrap external" target="_blank" rel="nofollow noreferrer">LLaMA 的训练数据集</a>，可以说是功德无量了。</p><p data-pid="WJj2GNTj">在这个讲座里还引用了很多 <a href="https://link.zhihu.com/?target=https%3A//yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1" class=" wrap external" target="_blank" rel="nofollow noreferrer">Yao Fu 大佬的文章</a> 内容，包括为何要在训练中包括代码数据，GPT 模型家族谱系图，alignment tax 等。</p><p data-pid="lrpHcgEA">时下流行的 LLM 大多数也都在 pre-train 阶段之后做了 instruction fine tuning 以及 RLHF。作者也介绍了一下很多开源模型采用的 GPT 生成 instruction following 数据的方案，以及 23 年 4 月发布的 <a href="https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/OpenAssistant/oasst1" class=" wrap external" target="_blank" rel="nofollow noreferrer">Open Assistant 数据集</a>。对于 RLHF，个人也额外推荐两个最近看过的资料，一个是 <a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DhhiLw5Q_UFg" class=" wrap external" target="_blank" rel="nofollow noreferrer">John Schulman 分享的通过 RL 来实现 Truthfulness</a>，个人感觉还是比较能体现 RL 相对于 SFT 的优势的。另一个是 <a href="https://link.zhihu.com/?target=https%3A//www.anthropic.com/index/claudes-constitution" class=" wrap external" target="_blank" rel="nofollow noreferrer">Anthropic 的 Constitutional AI</a>，展现了或许可以不借助人工反馈也能实现价值观对齐。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-bf874c83554cefe704100f1ed352ab1f_b.jpg" data-size="normal" data-rawwidth="3000" data-rawheight="1305" class="origin_image zh-lightbox-thumb" width="3000" data-original="https://pic4.zhimg.com/v2-bf874c83554cefe704100f1ed352ab1f_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='3000' height='1305'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="3000" data-rawheight="1305" class="origin_image zh-lightbox-thumb lazy" width="3000" data-original="https://pic4.zhimg.com/v2-bf874c83554cefe704100f1ed352ab1f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-bf874c83554cefe704100f1ed352ab1f_b.jpg" data-original-token="v2-2d457274f6450dfce32165ed4d80b9cf"></div><figcaption>Constitutional AI</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>训练与推理</h3><p data-pid="YEwPFEou">如果看课程 ppt，可以看到最后还有一块讲大模型训练与推理方面的内容。其中提到了 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2205.01068.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">OPT 训练的血泪史</a>，<a href="https://link.zhihu.com/?target=https%3A//lilianweng.github.io/posts/2023-01-10-inference-optimization/" class=" wrap external" target="_blank" rel="nofollow noreferrer">模型 inference 优化的手段</a> 等。不过对于应用开发话题来说的确目前这些可能都用不太上。</p><h2>Learn to Spell: Prompt Engineering</h2><h3>Prompt 是一种魔法咒语</h3><p data-pid="KH6HiRgh">终于来到魔法学堂的主要课程了！Frye 把 prompt 魔法分成了三类，并使用一些比喻来让大家更好理解。</p><p data-pid="dxB32Ajf">当应用于 pre-train 模型时，prompt 像是《瞬息全宇宙》中的传送器，能让模型瞬间拥有某个平行宇宙中的特殊能力。更多的 prompt 内容会更多限定模型后续输出的空间，从而达到了一种让模型进入到不同模式来实现不同任务的效果。</p><p data-pid="pVgLjWCO">当应用于 instruction-tuned 模型时，prompt 就像对着阿拉丁神灯许愿。许愿的内容自然也是越精确清晰越好。作者引用了来自 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.07830.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Reframing Instructional Prompts to GPTk’s Language</a> 这篇文章中的一些建议：</p><ul><li data-pid="6ezFNtTB">使用<b>非常细节具体的 pattern 示例</b>，而不是需要背景知识的术语。比如“复杂的”，“专业的”这种形容就不如直接给一些具体句式效果更好。</li><li data-pid="wEMrd5j1">将描述<b>通过 bullet point 的形式</b>逐项说明，如果放在一个长句里，模型很容易忽略后面的部分。如果有否定语句，转换成断言的形式。</li><li data-pid="zLBNXgti">尽可能将一个任务分解成多个简单的任务。这个分而治之的技巧在很多地方都有被提到。</li><li data-pid="Xrbp7Yh2">添加明确的对于输出的约束条件说明。比如 ReAct，AutoGPT 中都对于模型的输出形式做了很具体的限定。</li><li data-pid="sY87QSAa">给出具体的指令。比如不要泛泛地说回答以下问题，而是根据你需要的输出，给出具体操作的建议。</li></ul><p data-pid="Z6tmcZfJ">还有一个比较有意思的思考原则是，当前很多模型在做 instruction tuning 时所采用的数据都是人工打标的，所以你可以想象着<b>在给一个新上手的打标人员描述你所需要完成的任务</b>，就能得到一个效果不错的 prompt。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-d2874e2654419f76e48e8bbcc6ae1ba3_b.jpg" data-size="normal" data-rawwidth="1850" data-rawheight="682" class="origin_image zh-lightbox-thumb" width="1850" data-original="https://pic4.zhimg.com/v2-d2874e2654419f76e48e8bbcc6ae1ba3_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1850' height='682'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1850" data-rawheight="682" class="origin_image zh-lightbox-thumb lazy" width="1850" data-original="https://pic4.zhimg.com/v2-d2874e2654419f76e48e8bbcc6ae1ba3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-d2874e2654419f76e48e8bbcc6ae1ba3_b.jpg" data-original-token="v2-162d67cd4cc3c052bcfb31f7fc001c50"></div><figcaption>可以把模型当作一个新手标记员</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="U_CFVLWf">而在时下火热的 LLM agent 方向上，prompt 就像是能够创建一个有生命的机器人。最常见的例子是网上很多 prompt 的例子都有种让 LLM 做“角色扮演”的感觉。作者对于这种角色扮演所产出的效果质量给出了一个很好的总结：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-2f5150a38f150889b20796bba4d7b250_b.jpg" data-size="normal" data-rawwidth="1150" data-rawheight="1192" class="origin_image zh-lightbox-thumb" width="1150" data-original="https://pic1.zhimg.com/v2-2f5150a38f150889b20796bba4d7b250_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1150' height='1192'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1150" data-rawheight="1192" class="origin_image zh-lightbox-thumb lazy" width="1150" data-original="https://pic1.zhimg.com/v2-2f5150a38f150889b20796bba4d7b250_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2f5150a38f150889b20796bba4d7b250_b.jpg" data-original-token="v2-8df45a8cde723aa7cab9b9ee737c9b89"></div><figcaption>LLM 角色扮演的效果</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="03KzuET7">对于那些没法很好“模仿”的场景，我们需要通过例如 chain-of-thought 提示，调用外部工具等方式来提升效果。</p><h3>Prompt 技术</h3><p data-pid="sUGEcDM2">Frye 表示，few-shot learning 很多时候可能并不是一个好主意。举了几篇论文中的例子：</p><ul><li data-pid="tcs5zp5A"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.07350" class=" wrap external" target="_blank" rel="nofollow noreferrer">Prompt Programming for Large Language Models</a> 中，设计良好的 zero-shot prompt 表现与 few-shot 相比同样出色。</li><li data-pid="_zjfYU-L"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2202.12837" class=" wrap external" target="_blank" rel="nofollow noreferrer">Rethinking the Role of Demonstrations</a> 和 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2303.03846" class=" wrap external" target="_blank" rel="nofollow noreferrer">Larger language models do in-context learning differently</a> 中都尝试了将 few-shot 的例子 label 进行转换，但模型仍然主要按照其固有知识来做回答。所以模型可能只是学了任务形式，并没有把注意力放在 label 的具体信息上进行“学习”。</li></ul><p data-pid="bEQSQaiM">前面提到了 GPT 的 BPE tokenization 方式也值得注意，模型可能因此不擅长做单词倒着拼写这类任务。一个 workaround 是在这种任务中<b>给每个字母前后加上空格，就会识别为单个 token</b>。包括在教 GPT 做长数字的加法时这个方法也有奇效 </p><p data-pid="kX8SaXML">一些常见模式：</p><ul><li data-pid="Hf3KCeqs">给出“结构化”的文本给模型操作。比如在 ReAct 中看到的 thought，action，action input，observation 这种固定结构的演示。</li><li data-pid="qYtt8NJO"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.02406" class=" wrap external" target="_blank" rel="nofollow noreferrer">Decomposed Prompting</a> 等方法来拆解复杂任务，以及像 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.03350" class=" wrap external" target="_blank" rel="nofollow noreferrer">self-ask</a>，<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.03629" class=" wrap external" target="_blank" rel="nofollow noreferrer">ReAct</a> 那样自动化这个过程。</li><li data-pid="4vpqcNXO"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2201.11903" class=" wrap external" target="_blank" rel="nofollow noreferrer">Chain-of-Thought prompting</a>，<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2205.11916" class=" wrap external" target="_blank" rel="nofollow noreferrer">let's think step-by-step</a>。这个应该已经人尽皆知了。</li><li data-pid="NlArBQTS"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2303.17491" class=" wrap external" target="_blank" rel="nofollow noreferrer">Self-criticism</a>，让模型不断自我审视与修正回答。</li><li data-pid="92KFxQ1L"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2203.11171" class=" wrap external" target="_blank" rel="nofollow noreferrer">Self-consistency</a>，通过略微不同的 prompt 以及稍高一点的 temperature 设定，让模型多生成几个回答，最后投票来选择最终的回答。通过这种方式也能大大提升准确率。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-c253d1ac93bbbb6b5e4964b650f0424d_b.jpg" data-size="normal" data-rawwidth="2190" data-rawheight="1014" class="origin_image zh-lightbox-thumb" width="2190" data-original="https://pic2.zhimg.com/v2-c253d1ac93bbbb6b5e4964b650f0424d_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2190' height='1014'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2190" data-rawheight="1014" class="origin_image zh-lightbox-thumb lazy" width="2190" data-original="https://pic2.zhimg.com/v2-c253d1ac93bbbb6b5e4964b650f0424d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c253d1ac93bbbb6b5e4964b650f0424d_b.jpg" data-original-token="v2-2cfed364ddd7d96775ad9a56580c0d81"></div><figcaption>Self-consistency</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="KEsl2uZJ">这些模式还可以组合起来使用，以达到更好的效果。最后作者也总结了一下这些方法在速度和开销上的一些 trade-off 考量。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-443f02c1af178c69bfa9aada09f96463_b.jpg" data-size="normal" data-rawwidth="1364" data-rawheight="1334" class="origin_image zh-lightbox-thumb" width="1364" data-original="https://pic4.zhimg.com/v2-443f02c1af178c69bfa9aada09f96463_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1364' height='1334'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1364" data-rawheight="1334" class="origin_image zh-lightbox-thumb lazy" width="1364" data-original="https://pic4.zhimg.com/v2-443f02c1af178c69bfa9aada09f96463_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-443f02c1af178c69bfa9aada09f96463_b.jpg" data-original-token="v2-a27a4081a761056efe1406bb856a78e1"></div><figcaption>Prompt 模式 trade-off</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>其它</h3><p data-pid="uqHkDHfB">在 ppt 的最后一部分，作者还讨论了一下当前的 LLM 是否拥有 theory of mind，感兴趣的同学可以阅读一下。</p><p data-pid="H3SrUsdo">另外关于 prompt engineering 还有很多非常好的学习资料：</p><ul><li data-pid="HD2QzLxi"><a href="https://link.zhihu.com/?target=https%3A//github.com/openai/openai-cookbook" class=" wrap external" target="_blank" rel="nofollow noreferrer">OpenAI Cookbook</a></li><li data-pid="jwibiHqH"><a href="https://link.zhihu.com/?target=https%3A//www.pinecone.io/learn/langchain/" class=" wrap external" target="_blank" rel="nofollow noreferrer">LangChain AI Handbook</a></li><li data-pid="zrWR5-eW"><a href="https://link.zhihu.com/?target=https%3A//learnprompting.org/docs/intro" class=" wrap external" target="_blank" rel="nofollow noreferrer">Learn Prompting</a></li><li data-pid="wHiDPIob"><a href="https://link.zhihu.com/?target=https%3A//github.com/dair-ai/Prompt-Engineering-Guide" class=" wrap external" target="_blank" rel="nofollow noreferrer">Prompt Engineering Guide</a></li><li data-pid="AtxZ4aa4"><a href="https://link.zhihu.com/?target=https%3A//lilianweng.github.io/posts/2023-03-15-prompt-engineering/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lilian Weng's blog</a></li></ul><h2>Augment Language Models</h2><p data-pid="wPWs719Q">作者提出了一个很有意思的观点，<b>LLM 擅长于一般的语言理解与推理，而不是某个具体的知识点</b>。所以 OpenAI 也一直没有急着把 21 年以后的数据扔进去训练个 up to date 的 ChatGPT。</p><p data-pid="8TqwnVkC">所以一个很自然的想法就是通过各种手段来“增强”LLM，典型的方法包括信息获取，LLM Chains（通过 LLM 调用来增强 context），以及各类外部工具的使用。一眼看过去这不就是 LangChain 提供的核心功能嘛。</p><h3>Retrieval</h3><p data-pid="jKhChyT1">常见的各类基于 LLM 做问答的应用都结合了 information retrieval 的方式来构建 context，从而让 LLM 能够很好地根据特定信息作出回答。作者很贴心地给大家做了下这块的科普，包括倒排索引，BM25 等经典方法。当然 AI 领域用的最多的还是基于 embedding 的“语义搜索”。</p><p data-pid="xzZb3mjf">Embedding 的技术原理大家应该都挺熟悉了。在具体选择 embedding 模型时，可以参考 <a href="https://link.zhihu.com/?target=https%3A//huggingface.co/spaces/mteb/leaderboard" class=" wrap external" target="_blank" rel="nofollow noreferrer">mteb 的 leaderboard</a>。其中 <a href="https://link.zhihu.com/?target=https%3A//www.sbert.net/" class=" wrap external" target="_blank" rel="nofollow noreferrer">sentence-transformers</a> 是一个非常不错的 baseline，使用也很方便。大多数情况下大家应该都是直接使用 OpenAI 的<code>text-embedding-ada-002</code>，效果好，便宜，直接一个 API 调用搞定。另外榜单上的第一名 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.09741" class=" wrap external" target="_blank" rel="nofollow noreferrer">Instructor</a> 也值得关注，其思想有点像经过 instruction tuning 的 embedding 模型。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-a3d1ae37921e61676d985e88b9404610_b.jpg" data-size="normal" data-rawwidth="2242" data-rawheight="1032" class="origin_image zh-lightbox-thumb" width="2242" data-original="https://pic1.zhimg.com/v2-a3d1ae37921e61676d985e88b9404610_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2242' height='1032'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2242" data-rawheight="1032" class="origin_image zh-lightbox-thumb lazy" width="2242" data-original="https://pic1.zhimg.com/v2-a3d1ae37921e61676d985e88b9404610_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a3d1ae37921e61676d985e88b9404610_b.jpg" data-original-token="v2-3f0321557cfb68cd6d29d61ef122a9b2"></div><figcaption>Instructor 模型</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="yCDyaIfv">有了 embedding 模型之后，在做问答时的方式就是把 query 转换成向量，然后在文档向量库中做相似度搜索。在文档数量不超过百万量级时，其实<b>简单的 numpy 计算相似度来做搜索就足够用了</b>，不会跟那些近似搜索算法有多少体感上的差距。如果考虑到 LLM 本身调用的时间开销，这点差距可能就更不值一提了。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-7e78bec238963110fa75789261c3b1ce_b.jpg" data-size="normal" data-rawwidth="1280" data-rawheight="960" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-7e78bec238963110fa75789261c3b1ce_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1280' height='960'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1280" data-rawheight="960" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-7e78bec238963110fa75789261c3b1ce_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-7e78bec238963110fa75789261c3b1ce_b.jpg" data-original-token="v2-4e44516eaefcb65909c57428bc919a28"></div><figcaption>numpy vs. hnsw</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="BbCXWSU5">作者的建议是在做原型时直接用 numpy 就行，如果未来上生产环境，那么 IR 系统的选择会更加重要。比如选择一个整体的数据库解决方案，而不是重点考虑具体的 ANN 算法。</p><p data-pid="lLdooMQK">在数据库的选择上，作者也是非常的 practical，<b>直接选你现在用的数据库大概率就可以</b>，比如 pgvector，elasticsearch，redis 之类。看了下 LangChain 里的 vectorstores，这些也都已经支持了。</p><p data-pid="v6ugRiEm">不过呢，一些复杂场景下，embedding 这块也是有不少挑战的，例如：</p><ul><li data-pid="FDHp4Q25">数据库本身的可扩展性和可靠性，以及如果引入向量数据库怎么保持多个系统之间的一致性</li><li data-pid="Rymakr9X">文档比较长怎么做 split</li><li data-pid="NDXTC3ad">应该选择什么 embedding 方法，是否可以切换</li><li data-pid="l3Me9b3t">是否能在相似度搜索基础上支持 metadata 条件查询</li><li data-pid="Mn9xFH9A">是否支持多种类型的用户 query，例如关键词搜索，文档总结，多个文档之间的对比等</li><li data-pid="JH_VJ4Le">是否能支持复杂的 index 结构，例如有层级关系的 index</li></ul><p data-pid="AuWuIfbV">为了解决这些问题，你可能需要考虑上个向量数据库，作者也给出了一个很贴心的对比图：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-17a612baaabe07dc112edda885523ec8_b.jpg" data-size="normal" data-rawwidth="2716" data-rawheight="1308" class="origin_image zh-lightbox-thumb" width="2716" data-original="https://pic1.zhimg.com/v2-17a612baaabe07dc112edda885523ec8_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2716' height='1308'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2716" data-rawheight="1308" class="origin_image zh-lightbox-thumb lazy" width="2716" data-original="https://pic1.zhimg.com/v2-17a612baaabe07dc112edda885523ec8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-17a612baaabe07dc112edda885523ec8_b.jpg" data-original-token="v2-e1199ef7ddb14e307190da97542bfcc9"></div><figcaption>向量数据库对比</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="XmZW-XzF">总结来说如果想快速验证，Pinecone 是个不错的选择。如果想拥有更灵活的查询方式，可以考虑 Vespa 或 Weaviate，如果需要更好的 scalability/reliability，那么经过大客户验证的 Vespa 或 Milvus 可能是不错的选择。</p><p data-pid="zOu-T3ZH">如果玩过 retrieval + LLM 组合的应用的同学，可能会碰到一些问题导致召回质量不理想，例如：</p><ul><li data-pid="yD4WrZWq">用户的问题往往很短且形式多样</li><li data-pid="ex_EWgu6">而相应的文档很长</li><li data-pid="D_s9-TN-">embedding 模型并不是在你的任务上训练的</li></ul><p data-pid="jGOZv_st">针对这些问题，可以考虑自己 train embedding 模型，或者基于 OpenAI embedding 基础上 train 一个简单的转换模型。另外像 LangChain，LlamaIndex 项目里也有很多方案可以尝试，例如 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.10496" class=" wrap external" target="_blank" rel="nofollow noreferrer">HyDE</a>，<a href="https://link.zhihu.com/?target=https%3A//blog.reachsumit.com/posts/2023/03/llm-for-text-ranking/" class=" wrap external" target="_blank" rel="nofollow noreferrer">re-ranking</a>，以及各种复杂的 tree/keyword table index，query transformer，route retriever，compact and refine synthesize 等技术。如果对于这些细节内容感兴趣，也可以看一下我之前 <a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1Yk4y1L7Vh/" class=" wrap external" target="_blank" rel="nofollow noreferrer">关于 LlamaIndex 的简单分享</a>。</p><p data-pid="hiRKqOAc">这部分的最后是个 case study，介绍了 GitHub Copilot 如何通过 retrieval 来增强 context。主要依据来自于 <a href="https://link.zhihu.com/?target=https%3A//thakkarparth007.github.io/copilot-explorer/posts/copilot-internals" class=" wrap external" target="_blank" rel="nofollow noreferrer">这篇对 Copilot plugin 的逆向工程</a>。具体做法是：</p><ul><li data-pid="ppHEXk61">召回：编辑器中最近访问的 20 个同类型文件。可以看到有时候规则可能也足够了。</li><li data-pid="wD6DeHIG">后处理：当前光标前后的代码片段，以及从前面召回中通过相似度搜索最相近的文件片段。</li><li data-pid="qj6S9pDG">排序：通过一些规则来对这些信息排序，最后会根据 context size 限制按排序选取尽可能多的内容。</li></ul><p data-pid="2RxvYLGR">最后作者也展示了下目前最为广泛应用的 QA 场景中具体是如何结合 retrieval 的，也提到了通过不断 refine 的模式来突破 context size 限制，覆盖更多文档内容的方法。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-23a0c185b37ee4de6638a38fa1b6bf92_b.jpg" data-size="normal" data-rawwidth="2512" data-rawheight="1202" class="origin_image zh-lightbox-thumb" width="2512" data-original="https://pic3.zhimg.com/v2-23a0c185b37ee4de6638a38fa1b6bf92_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2512' height='1202'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2512" data-rawheight="1202" class="origin_image zh-lightbox-thumb lazy" width="2512" data-original="https://pic3.zhimg.com/v2-23a0c185b37ee4de6638a38fa1b6bf92_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-23a0c185b37ee4de6638a38fa1b6bf92_b.jpg" data-original-token="v2-bb56b23c3091a12c466341102fde8a30"></div><figcaption>Retrieval 应用与问答场景</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>Chains</h3><p data-pid="oUerrZy1">从上一个话题自然延伸，有时候<b>最好的 context 信息并不直接存在于各种外部文档中，而是需要另一个 LLM 的输出来进行构建</b>。比如前面提到的 HyDE，就是先通过 LLM 来不依赖外部信息回答问题，然后再将回答内容和问题拿去做 embedding，相似度搜索，形成最终的 QA prompt。另外像 summary 场景中“map-reduce”的做法应该大家也都很熟悉了。</p><p data-pid="fnjEq0bg">针对 Chain 这方面需求最典型的开源框架就是 LangChain 了，是一个超级火热更新速度超快的库。不过这部分的课程并没有展开介绍细节，感兴趣的同学也可以参考我之前的这个 <a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1DY4y1Q7Te/" class=" wrap external" target="_blank" rel="nofollow noreferrer">分享视频</a>。</p><h3>Tools</h3><p data-pid="TjHIVdsf">很多人觉得 LLM 距离 AGI 的一大差距是没法与真实世界连接，但其实已经有很多工作（例如 Toolformer 等）在尝试让 LLM 自主使用外部工具了。作者以 SQL 工具为例展示了下 LLM 如何来利用外部工具。大致为以下几个步骤：</p><ul><li data-pid="ssjqm3O7">用户问了一个问题</li><li data-pid="hTn7TreC">将用户问题和数据库的 meta 信息放到 prompt 里，让 LLM 去生成 SQL</li><li data-pid="InNV3s1v">利用数据库来执行这个 SQL 查询，这就是工具的调用</li><li data-pid="4HMX9XP4">将数据库查询结果与问题再扔给 LLM 做最终回答</li></ul><p data-pid="MDNNiM5-">当然这个步骤可以说是由 Chain 定义固定下来的，也可以采用类似 agent/plugin 的方式来让 LLM 自行决定在何时使用什么工具。用户只需要提供 API 的 spec 和描述，就可以快速接入到 plugin 体系中。</p><p data-pid="dyM_LyS5">这两种方式主要的权衡在于<b>可靠性或者是流程的确定程度</b>。Chain 的运作流程是人工定义好的，流程不会出错，且对 LLM 来说生成具体的工具指令也会准确率更高。而 plugin 的优势在于极大的流程灵活度，可以用统一入口满足用户各类诉求。虽然可靠性会下降不少，但也可以考虑引入人工交互来弥补。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-f93bab761db292049d1a80d9a6d07537_b.jpg" data-size="normal" data-rawwidth="2622" data-rawheight="1226" class="origin_image zh-lightbox-thumb" width="2622" data-original="https://pic4.zhimg.com/v2-f93bab761db292049d1a80d9a6d07537_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2622' height='1226'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2622" data-rawheight="1226" class="origin_image zh-lightbox-thumb lazy" width="2622" data-original="https://pic4.zhimg.com/v2-f93bab761db292049d1a80d9a6d07537_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-f93bab761db292049d1a80d9a6d07537_b.jpg" data-original-token="v2-c16dfb1699fcb7ef3ef534cb80203634"></div><figcaption>两种应用工具的模式</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="1J3yjRM0">最后还有一篇 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2302.07842" class=" wrap external" target="_blank" rel="nofollow noreferrer">关于 augmented 语言模型的 survey 文章</a> 可供参考学习。</p><h2>Project Walkthrough</h2><p data-pid="Dsbrc9fJ">带着大家过了一下 <a href="https://link.zhihu.com/?target=https%3A//github.com/the-full-stack/ask-fsdl" class=" wrap external" target="_blank" rel="nofollow noreferrer">askFSDL</a> 这个项目，live coding 的感觉很爽。</p><p data-pid="laR_9Cfn">对于算法工程师来说，能学到不少 Python 工程方面的最佳实践，比如 pre-commit，makefile，用 <a href="https://link.zhihu.com/?target=https%3A//gradio.app/" class=" wrap external" target="_blank" rel="nofollow noreferrer">gradio</a> 来写简单的界面，通过 modal 来管理 infra 等。</p><p data-pid="oWOaH8QH">对于软件工程师来说，可能数据接入这块之前接触的并不多，可以学习一下如何接入 markdown，PDF，Youtube transcript 等类型的文件，并尽可能多地保留原始信息。还有包括通过 <a href="https://link.zhihu.com/?target=https%3A//gantry.io/" class=" wrap external" target="_blank" rel="nofollow noreferrer">gantry</a> 来收集用户行为与反馈数据，并借助 LLM 来进行分析的方法应该也挺有启发。</p><h2>UX for Language User Interface</h2><h3>UI Principles</h3><p data-pid="YnB6Q-dP">开头介绍了 user interface 的历史，以及一些设计原则。其中提到的诸如<b>同理心，找真实用户进行测试</b>个人还是很有感触的。对这方面感兴趣的同学还可以参考我之前的这篇 <a href="https://zhuanlan.zhihu.com/p/574184394" class="internal">如何打造产品</a>。要知道 Sam Altman 最出名的可能就是他对于 PMF 的深刻理解了 </p><p data-pid="E-QYzVpG">具体到 AI 产品上，我们可以将 AI 能力以及决策错误的后果作为两个维度来进行分析：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-9afa76a60cc4400f4477d90081dd993d_b.jpg" data-size="normal" data-rawwidth="2614" data-rawheight="1274" class="origin_image zh-lightbox-thumb" width="2614" data-original="https://pic2.zhimg.com/v2-9afa76a60cc4400f4477d90081dd993d_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2614' height='1274'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2614" data-rawheight="1274" class="origin_image zh-lightbox-thumb lazy" width="2614" data-original="https://pic2.zhimg.com/v2-9afa76a60cc4400f4477d90081dd993d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9afa76a60cc4400f4477d90081dd993d_b.jpg" data-original-token="v2-519bbea992f15f0a5d4f1be2ce35aad0"></div><figcaption>不同情况下 AI 与用户的协作关系</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="cTz_eZVh">设计良好的交互，不光能让用户用得更爽，还能很自然地收集到很多用户反馈信息，建立起<b>数据飞轮</b>。例如在 Midjourney 中，用户必须通过明确的点击来选定四个备选图像中的一张做 variation 或者 upscale 并下载。</p><h3>LUI Patterns</h3><p data-pid="gajjhZx2">当前 Language User Interface 的几种常见 pattern 包括：</p><ul><li data-pid="M68UaAkv">Click-to-complete，例如 OpenAI Playground。</li><li data-pid="29xxisde">Auto-complete，例如 GitHub Copilot。</li><li data-pid="fIOQ_jel">Command palette，例如 Replit。</li><li data-pid="qDuUyS4v">One-on-one chat，例如 ChatGPT。</li></ul><p data-pid="gyrtb75C">作者进而提出一个框架来分析这几类 pattern 对于产品的要求，包括了几个角度。我们以 GitHub Copilot 为例来看下具体分析。</p><ul><li data-pid="g1_8wSCA">UI 的边界是什么。这一点 Copilot 非常自然，直接在 IDE 里提供补全，用户不需要做任何切换动作。</li><li data-pid="lIHhQLyo">对于准确率的要求有多高。相对来说不高，因为用户完全可以不理会建议，或者接受后再做少量修改。</li><li data-pid="EkDzeg6O">对于延迟要求有多高。要求比较高，大多数用户对于自动补全的习惯性期待肯定得在 1 秒以内。</li><li data-pid="TqZWIN5W">是否鼓励用户给出反馈。这一点也比较好，如果用户接受了建议，是一个很强烈的反馈信号。</li></ul><p data-pid="muqAZqqi">大家也可以用这个框架来审视一下自己的应用。尤其是第四点<b>如何鼓励用户给出反馈</b>，还是挺需要好好思考一下的。除了前面提到的 Midjourney 外，像 ChatGPT 里 regenerate response 和后面带的问题这种形式也很好，用户体验很流畅，同时又能拿到信号非常强烈的反馈。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-be4c407d82d4f5a40e3321f5e66fc16a_b.jpg" data-size="normal" data-rawwidth="1436" data-rawheight="1910" class="origin_image zh-lightbox-thumb" width="1436" data-original="https://pic3.zhimg.com/v2-be4c407d82d4f5a40e3321f5e66fc16a_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1436' height='1910'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1436" data-rawheight="1910" class="origin_image zh-lightbox-thumb lazy" width="1436" data-original="https://pic3.zhimg.com/v2-be4c407d82d4f5a40e3321f5e66fc16a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-be4c407d82d4f5a40e3321f5e66fc16a_b.jpg" data-original-token="v2-5f04af748cc9ef0c308a81da0daf0243"></div><figcaption>ChatGPT UI 中的设计亮点</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>Case Studies</h3><p data-pid="jbMIF65E">接下来一部分的 case study 个人感觉非常精彩，分享了对于 GitHub Copilot 和 Bing Chat 两个产品用户交互方面的分析。</p><p data-pid="qPEjptO_"><b>GitHub Copilot</b></p><p data-pid="KOxcjQNX">在训练了代码生成模型后，他们一开始在很多可能的产品方向进行了分析与探索，包括：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-7299eec84c9ad9e9537f285e8d652ed8_b.jpg" data-size="normal" data-rawwidth="2660" data-rawheight="1948" class="origin_image zh-lightbox-thumb" width="2660" data-original="https://pic1.zhimg.com/v2-7299eec84c9ad9e9537f285e8d652ed8_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2660' height='1948'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2660" data-rawheight="1948" class="origin_image zh-lightbox-thumb lazy" width="2660" data-original="https://pic1.zhimg.com/v2-7299eec84c9ad9e9537f285e8d652ed8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-7299eec84c9ad9e9537f285e8d652ed8_b.jpg" data-original-token="v2-d5d021c76213d65bbc4b8aba805868a3"></div><figcaption>尝试各种 idea</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="BKzcVMrM">很快他们就发现，当前的模型效果只能很好地支持 auto-complete 产品，而无法支持前两者。</p><p data-pid="akuJvQ_3">选定方向后，他们针对用户界面和体验方面做了很多 ab 测试，主要依据的指标是用户对于代码提示的接受率以及 30 天后的用户留存率。获取到了很多有价值的信息，最终打造出了一款用户喜爱且能产生很多实际价值的产品。</p><p data-pid="1YkoUcvV"><b>Bing Chat</b></p><p data-pid="MlVusFGc">Bing Chat 相对来说在用户体验方面的考量就没有那么全面，更像是为了抢占市场而急忙推出的一个产品。网上也持续有关于 Bing Chat 出问题的各种负面反馈出现，例如回答不友好，会出现胡言乱语，没法理解用户意图，“泄漏”prompt，甚至出现威胁用户等。作者认为他们可能犯了几个错误：</p><ul><li data-pid="oB173X_x">急于推出产品，底层的模型可能没有经过 RLHF 做 alignment，导致了很多网上出现的很多有问题的回复案例。</li><li data-pid="x3z5rfi_">没有注意到<b>潜在的反馈循环</b>。跟 ChatGPT 相比，Bing Chat 是“联网”的，所以每当它产生一些奇怪回复后，用户会贴到网上，然后搜索引擎又会很快索引这些信息，反过来不断增强出现这些奇怪回复的可能性。</li><li data-pid="q4y5YDgK"><b>用户界面的“引导”与产品实际提供的能力不符</b>。很多做 AI 应用的同学可能都觉得为了让产品更酷炫，应该尽可能让交互界面像真人。比如生成一个真人头像，利用 D-ID，ElevenLabs 等技术让它能够像真人一样用非常流畅自然的语音回答。但是这会让用户的期望值拉得非常高，如果你的模型不能够达到真人交互的水平，那么用户的失望感就会非常强烈。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-6496750b2087ad4c908aeb5cc2e37aad_b.jpg" data-size="normal" data-rawwidth="2008" data-rawheight="1950" class="origin_image zh-lightbox-thumb" width="2008" data-original="https://pic2.zhimg.com/v2-6496750b2087ad4c908aeb5cc2e37aad_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2008' height='1950'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2008" data-rawheight="1950" class="origin_image zh-lightbox-thumb lazy" width="2008" data-original="https://pic2.zhimg.com/v2-6496750b2087ad4c908aeb5cc2e37aad_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-6496750b2087ad4c908aeb5cc2e37aad_b.jpg" data-original-token="v2-60aee58fffcf89ef6d525f716f6fc400"></div><figcaption>LUI 应该强调自己是个机器人</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h2>LLMOps</h2><p data-pid="GrSvOe8r">这一节也非常有信息量，推荐观看。</p><h3>选择基础模型</h3><p data-pid="aynOWJpb">从几个维度来考虑选择哪个模型，包括<b>模型的效果，推理速度，价格开销，能否微调，数据安全，许可协议</b>等。</p><p data-pid="S4MSACIK">就 23 年 5 月这个时间节点来说，对于私有模型的建议：</p><ul><li data-pid="ycLxDvp0">绝大多数情况都可以直接选择 GPT-4 作为尝试的开始。后续如果有成本和速度的考量可以再切换到 GPT-3.5。</li><li data-pid="yjcfBVvx">Claude 也是个不错的选择，无论是模型效果还是训练的完善程度上，再加上现在支持了超大的 context size，赶忙去申请了 wait-list。</li><li data-pid="68_b2Stz">如果需要做 fine tune，也可以考虑 Cohere 的 command 系列。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-d64a8dd05af98f6fc3c6004bf01c2617_b.jpg" data-size="normal" data-rawwidth="4866" data-rawheight="2260" class="origin_image zh-lightbox-thumb" width="4866" data-original="https://pic4.zhimg.com/v2-d64a8dd05af98f6fc3c6004bf01c2617_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='4866' height='2260'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="4866" data-rawheight="2260" class="origin_image zh-lightbox-thumb lazy" width="4866" data-original="https://pic4.zhimg.com/v2-d64a8dd05af98f6fc3c6004bf01c2617_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-d64a8dd05af98f6fc3c6004bf01c2617_b.jpg" data-original-token="v2-0ade15371e5503ca63d1a8992dad3e18"></div><figcaption>私有模型对比一览</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="go21h-SI">开源模型这块发展很快，最近几周都有新模型出来。这块的许可协议也很复杂，例如有些模型的不同版本因为用了特殊的数据就导致无法作为商业用途。在讲座的时间节点，作者的几个推荐是：</p><ul><li data-pid="JNGkhCkj">如果希望完全开放的使用，T5/Flan-T5 是个不错的选择，效果也还行。</li><li data-pid="arKbyQEe">开源可商用这块可以考虑最近的 Dolly，StableLM。</li><li data-pid="EyynAcdL">如果用于研究用途，LLaMA 系列是目前比较主流的。如果对于 2020 年的 GPT-3 复现与实验感兴趣，可以用 OPT。</li><li data-pid="Xc_v32c-">其它基本不太用考虑，包括表上的 Bloom 和 GLM。不过这个表的更新迭代速度应该会很快。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-03fd35ca0cbffe47d6c40cdd80e24bc8_b.jpg" data-size="normal" data-rawwidth="4890" data-rawheight="2282" class="origin_image zh-lightbox-thumb" width="4890" data-original="https://pic1.zhimg.com/v2-03fd35ca0cbffe47d6c40cdd80e24bc8_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='4890' height='2282'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="4890" data-rawheight="2282" class="origin_image zh-lightbox-thumb lazy" width="4890" data-original="https://pic1.zhimg.com/v2-03fd35ca0cbffe47d6c40cdd80e24bc8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-03fd35ca0cbffe47d6c40cdd80e24bc8_b.jpg" data-original-token="v2-3ad03eee5e92ddc9130c725227fbbd64"></div><figcaption>开源模型对比一览</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="sTV0HluV">总体来说在当前私有模型的能力大大超过了开源模型，对于应用开发来说估计 23 年的主流都是使用私有模型。</p><h3>Prompt 迭代开发</h3><p data-pid="yBW-nAIf">传统深度学习里对于实验追踪与记录有着非常完善的支持，但目前的 prompt 开发与迭代还在很早期的阶段，主要还是因为不同 prompt 产生的效果并不好自动化评估。</p><p data-pid="qKDCfwHc">因此现阶段比较常见的做法就是通过 git 来管理 prompt 版本。如果有更复杂的需求，例如希望把 prompt 的应用逻辑解耦，或者引入业务人员来优化 prompt，以及通过单独的产品工具来快速评估管理不同的 prompt 甚至模型接口，那么就需要引入更加复杂的产品。这方面可以持续关注之前的 experiment tracking 产品，包括 WandB，MLFlow 等。</p><h3>测试</h3><p data-pid="8oidKCmR">LLM 的能力非常强大，能处理各种任务，这对其评估造成了很大的困难，比如我们很难判断一篇总结是否比另外一篇总结写得更好。对于不同的 prompt，模型甚至 fine tune 的效果，如何进行快速，低成本且准确的评估是一个大问题。目前的常见做法是：</p><ul><li data-pid="kfSrAY5Z">构建一个针对你所需要完成任务的评估数据集，一开始可以完全人工生成，后续逐渐完善。</li><li data-pid="DCXa7oZG">除了通过人工检验的方式，也可以<b>借助 LLM 来做评估</b>。可以参考 <a href="https://link.zhihu.com/?target=https%3A//github.com/langchain-ai/auto-evaluator" class=" wrap external" target="_blank" rel="nofollow noreferrer">auto-evaluator</a> 项目。</li><li data-pid="HLIHokVE">在添加新的评估数据时，需要考虑这条样本带来的“额外价值”，比如是否是一个比较困难的问题，以及与已有评估数据是不是非常不一样。</li><li data-pid="RTkTZ9Fm">思考“AI 测试覆盖率”，你收集的评估数据集能多大程度上覆盖生产环境的所有情况？</li></ul><p data-pid="gLvqs9Xb">通过 LLM 来做评估的具体方法包括：</p><ul><li data-pid="iLZiBdH6">如果有完全精确的答案判定，可以用传统指标，不需要借助 LLM。</li><li data-pid="39R6pXuI">如果你有标准答案，可以测试语义相似度，或者询问 LLM：两个回答是否一致？</li><li data-pid="XOjRYWPP">如果有上一个版本的回答，可以询问 LLM：哪一个回答更好？</li><li data-pid="pOealCyq">如果有用户填写的反馈信息，可以询问 LLM：用户的反馈是否已经包含在回答中了？</li><li data-pid="v7QvkBWO">其它情况，可以通过外部工具来检查是否是个合法的格式，或者让 LLM 给回答做个打分。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-11b8eebad9d57c9b1fd218373c01266f_b.jpg" data-size="normal" data-rawwidth="4118" data-rawheight="2012" class="origin_image zh-lightbox-thumb" width="4118" data-original="https://pic4.zhimg.com/v2-11b8eebad9d57c9b1fd218373c01266f_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='4118' height='2012'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="4118" data-rawheight="2012" class="origin_image zh-lightbox-thumb lazy" width="4118" data-original="https://pic4.zhimg.com/v2-11b8eebad9d57c9b1fd218373c01266f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-11b8eebad9d57c9b1fd218373c01266f_b.jpg" data-original-token="v2-ae0bdf99f06240d5127660328a1a6155"></div><figcaption>LLM 模型评估</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>部署</h3><p data-pid="BpMYQ2T9">简单的应用可以直接从前端发起模型请求即可。如果业务逻辑复杂，再考虑单独开发个后端服务。这个示范 stack 也在前面有提到。</p><p data-pid="W-KpiP-k">私有化部署 LLM 不在本课程讨论范围内……</p><p data-pid="yRz31gIi">一些提升 LLM 输出稳定性的手段：</p><ul><li data-pid="Or6v9IOG">Self-critique</li><li data-pid="9OsjyTwf">多采样几次，选最好的那次</li><li data-pid="WoxiNG5q">多采样几次，投票</li></ul><p data-pid="uG8dILjS">可以参考这个比较新的 <a href="https://link.zhihu.com/?target=https%3A//github.com/ShreyaR/guardrails" class=" wrap external" target="_blank" rel="nofollow noreferrer">guardrails</a> 项目。</p><h3>监控</h3><p data-pid="qPpVVz6a">这里应该也是一些标准做法了，可以结合前面的 UX 设计，主要思考如何系统性地获取并持续监控用户反馈。越是对用户来说没有什么负担的操作，越是信息含量高的操作，对于实际的业务监控越有效。</p><p data-pid="wLDnGue1">一些常见的可能出问题的点：</p><ul><li data-pid="HPQO_hhK">UI 问题，延迟太大。这也是出现最多的一类。</li><li data-pid="WmpNZYVK">错误的回答，hallucinations。</li><li data-pid="VG3tAy_V">冗长无用的回答。</li><li data-pid="wcqByp08">拒绝回答。</li><li data-pid="cjJ2XFZg">Prompt injection。</li><li data-pid="2BnbT_ox">违背价值观的回答。</li></ul><h3>持续优化与 fine tune</h3><p data-pid="YPbx2YrK">如果监控或者收集到上述问题的用户反馈，后续可以通过 prompt 优化或者 fine tune 的手段来持续改进。一般来说<b>优先选择前者</b>，尤其是当前开源模型，fine tune 技术都没有那么成熟的情况下。Slides 上有一些 fine tune 相关的内容介绍，不过作者认为当前应该多数情况下不需要，就跳过了  什么时候需要 fine tune 呢？</p><ul><li data-pid="Km1mf2_y">你需要节省成本，比如用更小的模型，不想每次都带一大段 prompt 之类。</li><li data-pid="Wbg4BL2s">你有大量的数据，且 retrieval 的方法表现不够理想。</li></ul><p data-pid="0UD4vzbu">大家如果有成功应用 fine tune 模式的例子，也欢迎交流分享。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-138f578cc5f3b7286456bd2cc7366257_b.jpg" data-size="normal" data-rawwidth="4224" data-rawheight="2106" class="origin_image zh-lightbox-thumb" width="4224" data-original="https://pic4.zhimg.com/v2-138f578cc5f3b7286456bd2cc7366257_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='4224' height='2106'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="4224" data-rawheight="2106" class="origin_image zh-lightbox-thumb lazy" width="4224" data-original="https://pic4.zhimg.com/v2-138f578cc5f3b7286456bd2cc7366257_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-138f578cc5f3b7286456bd2cc7366257_b.jpg" data-original-token="v2-4511ae1b5bf41c63f10b455173a1b606"></div><figcaption>LLM 应用迭代优化流程</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h2>What's Next</h2><p data-pid="pyG0pDW5">最后一个 session，展望一下未来，也是笑点最多的一集。</p><h3>大模型的下一步发展方向</h3><p data-pid="FXgVnmuM">作者认为一个很有希望的领域是多模态与机器人的结合。介绍了包括 ViT，PaLM-E，<a href="https://link.zhihu.com/?target=https%3A//github.com/Vision-CAIR/MiniGPT-4" class=" wrap external" target="_blank" rel="nofollow noreferrer">MiniGPT-4</a>，以及将 LLM 应用工具的思想拓展到机器人领域等工作。</p><h3>大模型如何继续 scale</h3><p data-pid="9CCQ7hTi"><b>Transformer 就是终极架构吗？</b></p><p data-pid="JEcIoEkG">之前看 RNN 相对来说很容易达到性能瓶颈，而且不能有效利用并行计算资源。不过看起来 <a href="https://link.zhihu.com/?target=https%3A//github.com/BlinkDL/RWKV-LM" class=" wrap external" target="_blank" rel="nofollow noreferrer">RWKV</a> 可能会是 RNN 的“逆袭”机会？</p><p data-pid="Q_HKjGmj"><b>钱，算力，数据哪个会成为大模型继续 scale 的瓶颈？</b></p><p data-pid="bZIyeP2h">总体来说最有可能成为瓶颈的是数据。比如 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2211.04325" class=" wrap external" target="_blank" rel="nofollow noreferrer">Will we run out of data?</a> 这篇文章认为我们在 2026 年之前就会碰到高质量数据增长跟不上算力提升的速度。而如果从 Chinchilla 论文中的 <a href="https://link.zhihu.com/?target=https%3A//www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications" class=" wrap external" target="_blank" rel="nofollow noreferrer">scaling law 公式</a> 来推算，在特定数据量下即使是<b>无限的参数量</b>都没法打败拥有更多数据量训练出来的有限参数量的模型。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-71ed6b62ee977ad4aca5f644b698af96_b.jpg" data-size="normal" data-rawwidth="592" data-rawheight="509" class="origin_image zh-lightbox-thumb" width="592" data-original="https://pic3.zhimg.com/v2-71ed6b62ee977ad4aca5f644b698af96_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='592' height='509'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="592" data-rawheight="509" class="origin_image zh-lightbox-thumb lazy" width="592" data-original="https://pic3.zhimg.com/v2-71ed6b62ee977ad4aca5f644b698af96_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-71ed6b62ee977ad4aca5f644b698af96_b.jpg" data-original-token="v2-cf4733b034ec81e61923584c1301dda7"></div><figcaption>通过 scaling law 推算无限参数/数据情况下的模型性能</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="g52uoM_S"><b>小模型能够走多远？</b></p><p data-pid="_c77pLtA">因为 retrieval 模式非常有效，所以大家自然会有想法说是不是不需要那么大的模型来记住各种知识点，而只需要一个<b>拥有推理能力的小模型</b>就可以？另外像 Alpaca 这些从 ChatGPT“蒸馏”训练的方式目前看起来在简单场景上还挺有效的。小模型可以在手机端，机器人设备上直接部署使用，想象空间还是非常大的。</p><h3>AGI 已经到来了吗？</h3><p data-pid="2qqh2CLo">作者觉得有可能已经到了，只是我们还没有认识到。一些论点：</p><ul><li data-pid="7zqcJlQg">现有模型能做什么，还需要我们花很多时间去挖掘。一个很有名的例子是一开始以为 LLM 不能做推理，但后来发现加一个 let's think step by step 就把准确率从 17.7%提升到了 78.7%。还有多少这样的现象是我们还没发现的？</li><li data-pid="ni0k7ihd">模型已经可以自己探索和发现自己的能力了。比如在 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2211.01910" class=" wrap external" target="_blank" rel="nofollow noreferrer">Large Language Models Are Human-Level Prompt Engineers</a> 中，作者发现模型可以自己设计 prompt，甚至超过人类水平。</li><li data-pid="ccETsSU2">模型可能已经可以做到自我提升了。比如 Anthropic 的 Constitutional AI，再比如让模型自己学会写代码和 debug，是不是未来也可能自己写 GPT-X 的训练优化代码自己提升？还有像 AutoGPT，BabyAGI 这些赋予 agent 使用工具和长期记忆能力的尝试，也是一个可能的方向。</li></ul><p data-pid="WwpTixv8">作者认为可以把 GPT-4 理解为一种新的 CPU，它的 context 相当于内存。我们现在的 prompt 还处在一个很原始的应用这种新型计算机的阶段（接近机器码？），还远没有出现更高阶的智能计算编程语言与框架。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-a652ac90357c3218cfb807a36cf7533e_b.jpg" data-size="normal" data-rawwidth="2798" data-rawheight="1462" class="origin_image zh-lightbox-thumb" width="2798" data-original="https://pic3.zhimg.com/v2-a652ac90357c3218cfb807a36cf7533e_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2798' height='1462'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2798" data-rawheight="1462" class="origin_image zh-lightbox-thumb lazy" width="2798" data-original="https://pic3.zhimg.com/v2-a652ac90357c3218cfb807a36cf7533e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-a652ac90357c3218cfb807a36cf7533e_b.jpg" data-original-token="v2-13656274cc02a4eb8463e5d380de53bc"></div><figcaption>GPT 是认知计算机的 CPU</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>安全问题</h3><p data-pid="qpYQAHNn">前面也看到了很多关于大模型应用的安全问题，包括 prompt 注入，“越狱”让模型做一些原本不应该做的事情，连接上工具之后影响与操控真实世界。这一节也举了非常多的例子。</p><p data-pid="kaLqugaj">具体怎么做呢？这个应该也是各人都有不同的看法。或许 OpenAI 的逐渐发布更强大的模型让大家适应，同时密切关注安全，价值观对其等技术手段，并持续监控模型失控的信号算是目前看起来比较合理的方案。</p><p data-pid="OJiKgASG">最后一页 PPT 也是非常幽默，作为整个系列讲座的结尾送给大家。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-8ef97853d02ea3050cc568d11f6aea8e_b.jpg" data-size="normal" data-rawwidth="2372" data-rawheight="1202" class="origin_image zh-lightbox-thumb" width="2372" data-original="https://pic3.zhimg.com/v2-8ef97853d02ea3050cc568d11f6aea8e_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2372' height='1202'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2372" data-rawheight="1202" class="origin_image zh-lightbox-thumb lazy" width="2372" data-original="https://pic3.zhimg.com/v2-8ef97853d02ea3050cc568d11f6aea8e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-8ef97853d02ea3050cc568d11f6aea8e_b.jpg" data-original-token="v2-75e8ff5bc65a46ff5aeeb004c9e6f55e"></div><figcaption>想起 Dr. Strangelove</figcaption></figure><p></p></div></div></div></div><div class="Post-ReadMark"></div><div role="button" tabindex="0" class="ContentItem-time">发布于 2023-05-15 19:32<!-- -->・IP 属地浙江</div></article><div class="KfeCollection-VipRecommendCard KfeCollection-VipRecommendCard-article Post-VipRecommendCard"><div class="KfeCollection-VipRecommendCard-title">你看过后觉得最虐心的小说是什么？</div><div class="KfeCollection-VipRecommendCard-author"><div class="KfeCollection-VipRecommendCard-author-avatar"><img src="https://pic3.zhimg.com/v2-d7dea818a153ec912ca529aae7e5155b.jpg"></div><div class="KfeCollection-VipRecommendCard-author-name">故事档案局</div></div><div class="KfeCollection-VipRecommendCard-content">夫君有个已经嫁人的白月光，我一直都装不知道。直到他跪在我面前，告诉我：她成了寡妇，他要娶她当平妻。01十八岁那年，我嫁进武安侯府，成了世子夫人。大婚后，我和世子盛修瑾并排跪在武安侯和侯夫人面前敬茶。侯夫人一脸慈爱，拉着场我的手：「好孩子，你嫁进来就是我盛家的儿媳妇，若是修瑾欺负你，或是让你受了委屈，你定要跟我说，我来给你做主。」我是新妇，脸皮薄，闻言立刻羞红脸，还没来得及说话，就听到旁边传来一阵嘲讽。「一个低贱屠户的女儿，能嫁进堂堂武安侯府，就已经是天大的福气，她能受什么委屈！就因为娶了她这种粗鄙村妇，才让哥哥沦为满京城的笑柄！委屈的分明是哥哥！」说话的是盛修瑾的嫡亲妹妹，侯府千金盛明珠。侯夫人当即冷脸，呵斥女儿：「住口！菖蒲以后是你嫂子，不得无礼！」盛明珠视线斜睨着我，留下一句：「不管你们怎么说，我不承认她赵菖蒲是我嫂子！」起身离开。房间里陷入诡异的尴尬。我脸色惨白，都不知道自己是怎么走出正院，回到世子所居的清晖院。直到丫鬟拢翠问我何时传膳，我才回过神来。「世子呢？」我问。拢翠吱吱呜呜：「世子出门访友，留话说今晚会很外回来，让您别等着，早点休息。」拢翠怕我难过，连忙安慰：「世子爷经常外出访友，并不是有意要冷落您，您可千万别往心里去……」我故作不在意：「没事。既然世子不在，早膳就摆在我屋里吧。你快去弄，我早就饿了。」很快，一桌四菜一汤丰盛早膳摆上。我不习惯有人看着我吃饭，就让丫鬟们下去。我坐在桌前，品尝着这些以前只在我梦里才有的美味珍馐，吃着吃着，一行行清泪夺眶而出。我胡乱抹着眼泪，警告自己：「赵菖蒲！几句难听话算什么！现在已经很好了！不用嫁给村东头的老瘸子，你该知足！」一个月前，大伯开价十五两银子，把我卖给了村东头的瘸腿老木匠，那是个凶狠暴戾的男人，已经逼死逼疯三任老婆。成婚当天，我趁人不备逃走了。逃婚路上，我救了个意外落水的富贵公子。当时，我只想着能凭借救命之恩，能去他家里当个丫鬟，赚钱养自己。没想到富贵公子脱困后居然要娶我。直到武安侯世子要娶屠户女的事闹得满城风雨，我才知道，他是武安侯府的世子，名叫盛修瑾。02盛修瑾为什么铁了心要娶我？这个问题我问过他。当时他捧着我的脸，回答我说：「娘子花容月貌，令我一见钟情。又想起有句古话『救命之恩，以身相许』。这辈子，你我就是你的人了。」我当时羞红了脸。可我坐在梳妆镜前。精致的铜镜里映着我只算是清秀的容貌，完全称不上花容月貌。我怀疑盛修瑾在骗我。可拢翠打趣我，说情人眼里出西施。盛修瑾是因为爱我，才觉得我美。晚上，我坐在床上，一边给盛修瑾缝制寝衣，一边等他回来。夜半三更，小厮扶着醉醺醺的盛修瑾回房。我连忙把他扶上床，喂了他醒酒汤。忙前忙后照顾。等一切安置妥当，房里只剩我和他。他蹙着眉，睡在床上，像是睡梦中仍然有无数烦心事在让他困扰。眉眼是那样好看，不该被烦扰破坏。鬼使神差，我伸手想熨开他紧蹙的眉头。谁知手指刚触上他眉心，他骤然惊醒。他紧紧攥着我的手指。「疼。」我痛呼。盛修瑾似乎稍稍从恢复清醒，他看到是我。他才放下防备：「你回来了？你知不知道，我很想你。」可见他醉得狠了，已经开始说胡话了。我顺着他的话说：「嗯，我也想你。」说完，我脸都羞红了。他断断续续说着，什么一日不见如隔三秋、生同一个衾死同一个椁……最后他将我箍在怀里，紧紧地：「你永远陪在我身边，好不好？」我整个人像煮熟的虾子，红透了。我猛点头。他俯身吻我，强烈缠绵的吻，让我无力招架，发出断断续续的嘤咛。突然，他一把推开我，翻身下床。「我突然想起还有公务没处理完。今晚我睡在书房。」说罢，他招呼小厮扶着，走去书房。我站在窗前，看着书房亮灯，看着他的身影映在窗前，看着烛火吹灭，书房重归平静。我很想冲过去，把他带回来。可是不行。我不配。03自从醉酒亲吻我以后，盛修瑾开始躲着我，仿佛我是洪水猛兽。我不明白自己做错了什么。一晃成婚已经三月。盛修瑾从不在我房里过夜。渐渐地，侯府里流言纷纷，都说盛修瑾嫌弃我是屠户女出身，不愿与我同床共枕。拢翠为了这件事，没少跟碎嘴的丫鬟婆子们打架。我劝拢翠：「嘴巴长在她们身上，让她们说去。反正我又不会掉一块肉。」拢翠嘴巴气鼓鼓的：「夫人，您都不生气吗？」我心中暗道，盛修瑾若是因为嫌弃肯看我一眼也好，可惜，在他眼里，我仿佛是透明的，不存在的。比厌恶更伤人的，是无视。但这话我不能跟拢翠说，于是只好沉默不语。恰在此时，盛修瑾让小厮给我送来一些书。全都是一些游记、话本、小说故事之类的闲书。小厮回禀我：「这些书是世子找来，给您打发时间用的。您若是不识字，可以让拢翠读给您听。」我是读过书的。父亲还在世的时候，对我极是疼宠。我那当屠夫的父亲曾给我攒下一百两的嫁妆，希望我能嫁给一个读书人，成为让村里人艳羡的秀才娘子。只天有不测风云，父亲患了急症去世。大伯一家抢了我的家产，从此我就像是大伯家的丫鬟，受尽欺凌，最后还险些被卖掉。此时，我心里更多是气闷，成婚三月，盛修瑾他竟然还不知道我是认字的。在他眼里，我这个屠户之女究竟不堪到何种地步？我刚要说明情况，小厮一句话将我未出口的话堵回来：「世子说，留言伤人。让夫人您最近几天都您待在清晖院，别出门。」我只觉得心里一惊。盛修瑾这是……要把我禁足，还是单纯怕我被流言所伤，想办法帮我消磨寂寞？可没等我打听，小厮传完话就离开了。04树欲静而风不止。我想在清晖院蜗居，但有事情主动来惹我突然，正院的丫鬟传话来，侯夫人要见我。我急忙赶去正院。几个月来，侯夫人待我很慈和。我很喜欢这位婆母。进入正院卧房，侯夫人一见到我，立刻招呼我到她身边去。她脸色蜡黄，病恹恹的样子。我顺势凑在她床前：「母亲，您什么时候病了？怎么竟然不然我们知晓？」「一点小病而已，没什么大不了的。」我本以为她是要跟我谈，世子三月不和我同房的事情。可是我料错了。只见她让人捧来一个托盘，那是一套华丽的金石头面。「高阳公主准备在十日后举行赏花会，邀请京城名媛贵妇参加。刚刚咱们侯府接到帖子。你是世子夫人，该由你去。」说着，指着那套头面：「这是我刚嫁进侯府时，娘家送的陪嫁。我连明珠都没舍得给，就是留着要给我的儿媳。」我连呼惶恐。侯夫人拉进我的手：「我只愿你和修瑾能和和美美的。现在我身体不好，你是世子夫人，应该开始学习打理家事。参加宴会的规矩和注意事项，我让人教你。」我立刻答应：「请母亲放心，我会好好学习的。」侯夫人大概是个雷厉风行的性格。我刚回清晖院，教导我礼仪的女先生立刻就到了。不学不知道，原来世家贵女高门贵妇之间相处有没那么多弯弯绕绕。不像我们村里的农妇，有什么恩怨，指着对方鼻子便可以破口大骂那般直接肆意。那些繁琐的规矩，弄得我头昏脑涨。可我愿意去学，在我心底有个小小的角落，萌生了这样念头：是不是学会这些，我和盛修瑾的距离会接近一点点……抱着这样隐秘的心思，我学得格外起劲。这天我头上顶着一摞厚厚的书，正在后花园凉亭里练习走路仪态，盛明珠突然来了。她气呼呼看着我：「你在干什么？」我乖乖回答：「母亲让我练规矩，要参加高阳公主赏花宴。」盛明珠的脸色瞬间黑了：「不许练！不准去！那不是赏花宴是鸿门宴！你去了只会出丑，只会丢我哥的脸！」我以为，她只是觉得我屠户女的身份。又在侮辱我。没想到，盛明珠突然凑到我身边，小声嘀咕：「高阳公主一直喜欢我哥，她早就放话，你若去赏花宴，她定要剥掉你一层皮！」说完，盛明珠风风火火走了，只留我怔在原地。一直待我慈善的婆母让我参加赏花宴，盛明珠却说，赏花宴是鸿门宴。究竟是谁在骗我？05我不想相信盛明珠的话，可是，怀疑的种子已经在我心底生根发芽。我让人出去打听，确实打听到，高阳公主是个霸道跋扈的女人，对人动辄打骂。高阳公主爱慕武安侯世子盛修瑾，凡是靠近盛修瑾的女子，都被她各种教训，据说一手鞭子使得非常好，已经抽得几个千金小姐破相了。当晚，我又是一夜无眠。转天早晨，盛修瑾破天荒主动来找我。我高兴坏了。他给我送来一些华美的不料，叮嘱我马上要入秋，记得添置衣服。盛修瑾突如其来的关心，让我生出贪念。如果可以……我能不能为留在他身边，主动出击，争取一下下……我故作不经意，上前挽住他的胳膊。在他微微愣住的眼神中，把他按坐在餐桌前。今天早晨，我的早膳是包子。包子薄皮大馅，个头有成年人一个手掌大。与平素里侯府吃的那种小笼包，完全不是一个风格。「世子你尝尝看，这是我家里常吃的一种包子。拢翠特意让厨房做的。很好吃的。」我塞给他一个包子。他虽然动作僵硬，但是没有拒绝。我和他并肩坐着，一起用膳。我俩安安静静啃包子。拢翠笑眯了眼，毕竟这是成婚以来世子和世子夫人第一次同桌用膳。拢翠似乎是为了调节气氛，主动说起了我刻苦学习规矩，准备参加高阳公主赏花宴的事。盛修瑾笑着夸我：「很好。菖蒲进步很大。到了赏花宴一定能一鸣惊人。」我装作漫不经心，故意问他：「听说高阳公主是个很温和的女子，不知道我能不能讨她高兴？」我心里暗暗期待，期待他能给我一句实话。盛修瑾沉默一瞬。最终还是对我说：「高阳公主跟咱们家交情不错，到了赏花宴，你可以主动去给她请安。她会善待你的。」那一刻，我整个人都是冷的，如坠冰窟。06早膳时，我拒绝参加赏花宴。盛修瑾一脸难以置信：「为什么？」我只说自己出身粗鄙，规矩学的也不像样子，不想去出丑。不论盛修瑾怎么劝，我都不肯去。最后，盛修瑾冷着脸，拂袖离开了。自从早膳争吵以后，盛修瑾一直没有回家。盛明珠每天来清晖院，拜她所赐，我对盛修瑾的行踪了如指掌。「昨晚我哥去了丽春馆。点了里面最有名的花魁娘子。每天听我说这些，你的心不痛吗？」盛明珠说道。我心痛，心痛如绞。明知他只是想利用我去赏花宴，让我承担高阳公主的怒火，可我还是放不下他。得知他花天酒地，我心痛的几乎不能呼吸。盛明珠掏出一叠银票，放在我面前：「赵菖蒲，你和我哥不是一个世界的人，强行绑在一起，你痛苦，他也痛苦。收下这些钱，你离开他吧。」我翻看银票，里面有一千两，有五百两，一沓大约有四五千两银子。在我们村子里，三两银子就能买一亩上好的水田，这笔银子对我来说，无疑是一笔巨款。盛明珠看着我：「只要你答应，我可以弄来一种假死药。到时买通大夫说你暴毙而死，你带着这些钱随便去哪都可以……」不得不承认，我看人的眼光不行。我以为盛明珠羞辱我的恶人，可在我落入陷阱之时，她第一个出来警告我。我以为盛修瑾、侯夫人待我好，可他们联手坑我进陷阱里。我抬头看着盛明珠尚带稚气的小脸。她被我看得不自在。气鼓鼓鼓起腮帮：「你看什么看！」我轻声婉拒她的提议：「我不会离开的。」盛明珠惊讶：「你为什么不走？你看不出来吗？我哥不喜欢你。」我当然知道。但是，我喜欢他啊。我在心里卑微的喜欢着他。所以才会死皮赖脸待在他身边。但我不想这份卑微，被人发觉。于是，我对盛明珠道：「我贪慕武安侯府的荣华富贵，舍不得走。」气得盛明珠扭头就走，不搭理我了。07转眼，赏花宴临近。盛修瑾终于踏入清晖院。他直勾勾看着我：「我只问你一句话，赏花宴，你去还是不去？」我苦笑：「去如何？不去又如何？」盛修瑾只说：「你若去，我们还是夫妻。」言外之意，就是如果我不去，我们就不再是夫妻了。我抬头环视清晖院，树上的叶子黄了，扑簌簌往下落，一派萧条的景象。我伸手接下一片落叶：「天冷了，我一个人睡会害怕。等我从赏花宴回来，你搬回卧房，好不好？」盛修瑾瞪大眼睛。显然，他已经看出，我明知危险仍然答应。最终，他缓缓点头。盛修瑾为我画上精致的妆容，又帮我披上华丽的秋装。临行前，他将一个小小瓶药交到我手里：「赏花之地，多有蛇虫。这些药丸你带上，如果有需要就拿出来用。这都是宫里太医亲手调配的，止痛效果很好的。」被他拉着手，感受他体温的时候，我几乎要哭出来。为了这一丝丝的温暖，我像是一只飞蛾，拼命飞向烛火。我和拢翠坐上马车，前往高阳公主在郊外的别庄。我心怀忐忑，时不时撩开车帘往外看。可看着看着，我发现情况不对。和拢翠对视一眼，拢翠瞬间明白。拢翠探头出去：「老张，怎么回事？这似乎不是去高阳公主别庄的路。」前头驾车的老张，是武安侯府的老仆人，一向稳重。他回头朝我回禀：「每次高阳公主举行宴会，都会有很多人参加。那路堵得，根本过不去。这是我发现的一条新路，虽然有些绕远，但是胜在人少。不会耽误事。」我这才放松，暗道自己多心。马车突然停下。老张颤颤巍巍的声音响起：「世……世子夫人……前面有人拦路……」拦路？抢劫吗？我瞬间紧绷，手不自觉摸了摸藏在袖子里的匕首。我在村子里，打架是个好手。就是不知，面对劫匪，我能有几成把握？08我本以为时遭遇拦路抢劫。可等我探头出去看，才发现不对。拦路的是个穿着火红色劲装的姑娘，她骑着一匹白色骏马，手里捏着黑色短马鞭。头上胳膊脚腕上装饰着华美的配饰。她身后，是一行十几个护卫。看穿着是侍卫。老张慌忙跪倒：「参见高阳公主。」我这才知道，她就是我之前好奇的高阳公主。高阳公主策马而来，视线死死锁定我：「你就是修瑾哥哥新娶的妻子？」她口中。修瑾哥哥四个字温柔婉转，满含情愫。拢翠将我扶下车。我冲她行礼：「参见公主。」突然，高阳公主一脚将我踹倒。「你一个卑贱的屠户女，给修瑾哥哥提鞋都不配！」高阳公主对身旁宫女下令：「来人！赏她四十巴掌，让她清楚清楚自己身份！」啪啪啪。巴掌狠狠抽在我脸上。我恨不得冲上去踹死高阳公主。可是我被两个侍卫死死按住，动弹不得。高阳公主把玩着鞭子，充用充满恶意的眼神看向我。「你就是用这张脸，诱惑修瑾哥哥的吧。那我就毁了你那张狐媚脸孔。」高阳公主高高扬起鞭子。向我挥来。我闭着眼，等待疼痛到来。忽然，我身后，哒哒马蹄声传来。高阳公主向受惊的小鹿，瞪大眼睛，手上的动作随之停止。我回头看去，盛修瑾。他下马，脱下披风盖在我身上，将我揽在怀里：「对不起，我后悔了。抱歉，我来晚了。」我紧紧抱着他的腰，泪如雨下：「不晚。一点都不晚。」他理都不理高阳公主，将我打横抱起，放在马上。他跳上马，将我整个人抱进怀里。两人共乘坐一骑，他的胸膛紧紧贴着我。我只觉的一阵心猿意马。高阳公主的哭着冲过来：「修瑾哥哥，你看都不看我，你不喜欢我了吗？」我悄悄抬头看他。盛修瑾板着脸，用最冷的声音回答：「公主请自重。」我以为这件事就到此为止了。然而，我们都低估了高阳公主的自尊心。一只匕首插在马屁股上，高阳公主惨笑：「得不到，我宁可毁了你。」09马骤然失控，让所有人都措手不及。盛修瑾用尽全了试图控制马匹，然而无用。跌落山崖那一刻，我心中甚至有种诡异的满足感，能和他死在一起，此生无憾了。但事实上，我们并没有死，坠崖过程中一颗长出石壁的松树，帮忙卸掉很大力量。跌到崖底时，我奇迹般只收了些爱轻伤，盛修瑾一条胳膊骨折了。我们在附近找到一处山洞，盛修瑾身上带着火折子，我们在山洞里生起一堆篝火。崖底寂静无声，只有我和他两个人。我盯着他的脸猛瞧，把他看得都不好意思了。我故意压低身子欺身过去。我问：「盛修瑾，告诉我实话，你为什么娶我？」盛修瑾沉吟片刻：「高阳公主逼我娶她，让我做驸马。可是本朝驸马不能参政，一旦和她成婚，我只能当个闲散人。迫于高阳的淫威，京城中没有千金小姐敢嫁我。正巧，你因为跳水救我，被我毁了名节。我就想，干脆娶了你就当报恩了。」我继续问：「那，让为什么坚持让我出席赏花宴？」「皇上怀疑武安侯府想造反，想把高阳公主嫁进侯府。我不得不先发制人。高阳公主一旦对你动手，我会设法让你暴毙。到时我会据此参奏高阳公主。这样她就不能嫁进侯府了。」我懂了。盛修瑾拉住我的手，焦急解释：「但是我后悔了！！」我打断他的话：「我知道。」我很开心：「马失控时，只要从马上跳下去，你就得救了。以你的武功自保不成问题的。但是，你没有跳。」盛修瑾扭头不语。我更开心：「是不是因为你想救我？哪怕冒着生命危险，你也想救我？你把我看得比你的命还重要？」一抹晕红爬上盛修瑾耳垂。猛然，我的心被重重一击。「盛修瑾……你是不是……也……喜欢我？」我问。我心里已经有了答案。10就像是一场梦，醒来还是很感动。清晨，窗外鸟鸣声中，我睁开惺忪睡眼，侧头一看，盛修瑾依然在睡着。这是我们被从崖底救出来的半个月后。就在昨晚，我和养好伤的盛修瑾圆房了。一想到昨晚的一幕幕，我整个人红的像是一只煮熟的虾子，连忙又缩回被子里。盛修瑾悠悠转醒，见状笑话我。我们又胡闹一番才起床。早晨正院传话过来，让我们一起去那用膳。当我和盛修瑾携手同时出现时出现，惊掉了满屋人的下巴。盛明珠瞪大眼睛，指着我们惊呼：「哥！你！你们……」盛修瑾举高我们相握的手：「如你所见。以后要对嫂子好一点。」侯夫人嘴角抽搐，强挤出笑容：「那就好。你们小夫妻就应该甜甜蜜蜜的。」侯夫人让我坐在她旁边，一如既往拉着我的手，亲切问候。可我早已提起十二分警惕。不想再跟她拐弯抹角浪费时间，我直奔主题：「母亲今天特意喊我们一起用早膳，是不是还有话要说？」盛明珠插嘴：「当然是有事情！」侯夫人轻咳一声：「是这样的，修瑾表妹半年前出嫁了，嫁进一户姓杨的清贵翰林家里。可就在三天前，她丈夫喝醉酒跌进护城河里淹死了。她一个柔弱女孩子，怎么受得了。修瑾，你去把你表妹接到侯府里来，让她散散心。」侯夫人说着呜呜哭起来。我看到盛修瑾表面无事，可拳头已经握得死紧。我敏锐感觉到，盛修瑾和他表妹之间，没那么简单。11表妹名叫沈伊伊。她和盛修瑾从小青梅竹马一起长大，感情很好。一度要谈婚论嫁。可就在半年前，表妹突然嫁给国子监祭酒杨翰林的儿子。之后不到一个月，盛修瑾顶着全京城达官显贵看笑话的眼光，娶了我这个屠户之女。拢翠向我汇报，她探听来关于表妹沈伊伊的情况。她低着头，不敢与我对视。看她这样，我立刻明白，她还有情况没说。在我再三逼迫下，拢翠终于说出实情：「厨房的张婆子说，世子夫人您跟表小姐的眉眼有三分相似。世子可能……是拿您，当表小姐的替身。」我一时间心神动摇。真的是这样吗？不，不会的。盛修瑾待我的好不会是假的。我一整天都在为此患得患失，心神焦躁。晚上，待盛修瑾回来，我便迫不及待扑到他怀里。「怎么了？」他轻柔亲吻我发顶，语气温柔宠溺，让我的心不自觉安静下来。我的脸紧靠在他胸膛，闷闷地说：「修瑾，表小姐是不是很漂亮。」盛修瑾微微一怔，继而笑得前仰后合。他捏着我的鼻子：「没想到，天不怕地不怕的菖蒲，居然是个小醋坛子。」我羞怒，使劲拧他。盛修瑾连连告饶，最后一把将我抱起，送到床上。一番云雨后，他抱着我说话。「我和表妹，确实曾经青梅竹马，也曾口头许过婚约。可是自从她出嫁后，我便只把她当妹妹。」他指尖轻拢着我乌黑的长发，爱不释手。我顺势缩到他怀里：「那……你有没有觉得……我和表小姐容貌又几分相似？」我鼓起勇气问出这个困扰我一整天的问题。12问题刚问出口我就后悔了。盛修瑾断然否认没有，不是，不可能。他手指敲我脑袋上，发出一声脆响，「你的小脑袋瓜里都在想些什么？」我捂着被敲得生疼的额头，示弱认错。盛修瑾叹气：「你放心，我不会把表妹接到家里来的。她丈夫新丧，又一堆事要料理，也没时间过来做客。」听闻表小姐不会来，我略安心。冥冥中我有种预感，表小姐会将我送入万劫不复之地。第二天一早，侯夫人再次派人来叫，我和盛修瑾再次前往正院。此时，武安侯已经去上朝，院里主子只有侯夫人一个人。侯夫人此刻急得团团转。见到盛修瑾，她眼睛一下子发了光：「修瑾！快去！快去救救伊伊！那些人要弄死她！」盛修瑾连忙扶住侯夫人：「娘，您说清楚，究竟发生了什么事？」在侯夫人带着哭腔断断续续讲述中，我终于弄清楚发生了什么事。是表小姐出事了！沈伊伊丈夫病逝后，杨翰林居然让她为亡夫殉节，逼着沈伊伊自杀。沈伊伊的丫鬟见状不对，立刻逃出来求救。沈伊伊的父亲是地方官吏，她父母并不在京城。于是丫鬟只能向侯府求救。「修瑾，你快去救人啊！再晚了，伊伊的命就没了！」侯夫人催促盛修瑾二话不说，让护卫待命，跟他一起去杨翰林家抢人。我守在后宅门口，焦急等着。我曾经被大伯以「失节」为由差点被抓去陈塘。我深知迂腐礼教对女人的迫害。我不停祈祷，希望表小姐安让无恙。这份感同身受，与她是否是我的情敌无关，只是人同此心罢了。一直到中午，一顶小轿被抬进来，盛修瑾站在轿外，时不时安慰里面的人。轿子停下，一只素手探出。盛修瑾极其自然握住，弯腰打横把人抱出来。看到这一幕，我骤然心头一紧。盛修瑾抱着沈伊伊停在我面前，向我解释：「沈姑娘的情况很不好，需要立刻请大夫。菖蒲你先回清晖院等我。安心，我很快回去。不会有事的。」盛修瑾让我安心，说不会有事。可我怎么能安心。盛修瑾抱着表现皆离开后，我一直忐忑不安。拢翠跑到侯府四处串联，消息不间断传过来，让我更加焦躁。直到夜幕四合，盛修瑾拖着疲惫的步伐回来。他跪在我面前：「我要娶沈伊伊为平妻。」我惊呆了。我想要哭嚎，想要撒泼，想要用各种手段让他回心转意。可是透过他坚定的眼神，我深知此事已无转圜的可能。那一晚，他宿在书房，我枯坐在床上，两间房灯火亮了一整夜，长夜无眠。13很快，侯府举行了一场小型婚礼。只有侯府众人参与，规模虽小，但礼仪完备。沈伊伊正式成为世子平妻。沈伊伊赢得了侯府上下的喜欢。甚至为了给沈伊伊出气，武安侯和盛修瑾一同出力，将沈伊伊的前公公杨翰林一家扳倒了。在沈伊伊婚礼时，杨翰林一家已经在流放的路上。我冷眼看着。从盛修瑾要娶沈伊伊后，我对他已经彻底失望了。如今清晖院里，只有我一个人住。盛修瑾和沈伊伊搬去了隔壁芙蓉院。仅仅一墙之隔，他们之间戏耍玩闹的声音不时传进我耳中，刺耳极了。深夜里，我时常将整个人裹进被子里，悄悄痛哭。拢翠常劝我，让我试着跟沈伊伊和平共处，那样盛修瑾会把宠爱分我一点。可是，不行啊。我那么贪心。我曾得到过他完完整整的爱，我尝过独占他的滋味。与人分享他的爱，我做不到。我将自己困在清晖院，不踏出一步。盛修瑾几次想进来见我，都被我拒绝了。他和她夜夜笙歌，好不快活。我无意参与其中。就在沈伊伊进府的三个月后，经太医确诊，她怀孕了。整个侯府欢腾着。就在这天，沈伊伊出现在我门前。她娇滴滴看着我，眼睛里藏着恶意：「姐姐，你不为我高兴吗？我腹中这是侯府第一个孙辈，也是你孩子，以后他也会叫你娘。」我直接让人关门。沈伊伊像是把向我请安，或者说向我炫耀当成一件工作，每天上午一次，下午一次，按时报到。我实在烦了。我心知她打什么算盘，但与其相互折磨，不如相互放过。在沈伊伊连续报到的一个月后，我踏出了清晖院大门。再次来到正院，屋里侯夫人、沈伊伊言笑晏晏，盛修瑾站在旁边安静聆听，好一派家庭和睦。我像个异类，刚一进入就打破美好。我跪在侯夫人面前，掏出早就写好的和离书：「儿媳自请下堂，请母亲允许。」一时间，所有人都震惊了。</div><div class="KfeCollection-VipRecommendCard-footer"><div class="KfeCollection-VipRecommendCard-footer-number">354 点赞 · 14 评论 · 盐选推荐</div></div></div><div class="Post-Sub Post-Sub-Mobile"><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><img class="Avatar css-1any501" src="https://picx.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b 2x" alt="RandomGenerator"></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span>RandomGenerator</span></h2></div></div></div></ul></div><div role="complementary" aria-label="推荐阅读" class=""><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class=""><a href="https://zhuanlan.zhihu.com/p/125655125" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">LLM 有没有必要选具体方向？</div><div class="MobilePostItem-Summary u-ellipsis">作者简介William，上海交大凯原法学院本硕，康奈尔法学院LLM，参与牛津出版社《The Japanese Way of Justice-Prosecuting Crime in Japan》一书中文版的翻译工作，在上海市方达律师事务所工…</div><div class="MobilePostItem-Footer">将军 · 发表于律政留学</div></div></a><a href="https://zhuanlan.zhihu.com/p/20797504" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">LLM这一年要学些什么？</div><div class="MobilePostItem-Summary u-ellipsis">2015年秋天在知行教育基金会（yes we do）的慈善晚宴活动上，听到清华经管学院院长钱颖一教授关于“无用知识的有用性” 的一番话，很有感触。钱教授举了两个例子，电磁学里的电磁理论和经济…</div><div class="MobilePostItem-Footer">何菁</div></div></a><a href="https://zhuanlan.zhihu.com/p/30089981" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">如何在LLM的学习中生存并完成学业</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">作者 | 学律原创团队 首发 | 学律留学顾问中心（微信公众号ID：Top…</div><div class="MobilePostItem-Footer">学律留学... · 发表于学律申请中心</div></div><img src="https://picx.zhimg.com/v2-d402ece2be62edb571d0fe26b099b861_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-d402ece2be62edb571d0fe26b099b861_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/v2-d402ece2be62edb571d0fe26b099b861_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="如何在LLM的学习中生存并完成学业"></a><a href="https://zhuanlan.zhihu.com/p/400066620" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">一些IP LLM 及非学位课程信息</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">原先很想再读个LLM，搜了很多信息，但是毕业后，感觉非常想再工作…</div><div class="MobilePostItem-Footer">akia没读LLM</div></div><img src="https://picx.zhimg.com/v2-71f9942003ec3b9a939522ac90a9b99b_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-71f9942003ec3b9a939522ac90a9b99b_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/v2-71f9942003ec3b9a939522ac90a9b99b_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="一些IP LLM 及非学位课程信息"></a></ul></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 390px; bottom: 0px; left: 16px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;629589593&quot;}}}"><span><button aria-label="赞同 460 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></span>赞同 460</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down VoteButton--mobileDown"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleDown" fill="currentColor"><path fill-rule="evenodd" d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023Z" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Comment Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span>3 条评论</button><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 0 0 .165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 0 0-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 0 0-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 0 0-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 0 0 .164-.12l2.378-4.122Z"></path></svg></span></button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover1-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover1-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Dots Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></span></button></div></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px; height: 54px;"></div></div></div></div></main></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fapi\u002F","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","allowSignUp":true,"refreshValidityPeriod":"30","release":"824-bcf32e16","currentEntry":"column","isMobileEntry":false,"apollo":{"env":"prod","globalSilence":"","ncgModeSign":"3f8e56febda4fb3bbea72e379d76de1e","topstory_rec_adp":"1","test_canary":"member|0-100,1-0","use_new_player":"member|0-0,1-100","player_vendor":"member|0-0,1-100,2-0","use_hevc":"member|0-0,1-100","upload_use_signature":"member|0-0,1-100","use_backdrop_blur":"member|0-0,1-100","article_title_imagex":"member|0-50,1-50","play_station":"member|0-0,1-100"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"entities":{"users":{"zijie0":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"629589593":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGJ-QhvjYHlDBQ==&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"id":629589593,"title":"[必读] LLM 应用开发全栈指南","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F629589593","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5db37b62967d3d99a9fa05bbc2633f15_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5db37b62967d3d99a9fa05bbc2633f15_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-159d1e631f323cbe43b5d325d53bc997_200x112.png\" data-caption=\"一键并发载入 pdf\" data-size=\"normal\" data-rawwidth=\"2744\" data-rawheight=\"1490\" data-watermark=\"watermark\" data-original-src=\"v2-159d1e631f323cbe43b5d325d53bc997\" data-watermark-src=\"v2-50b584a8e9d3a762a00e4bfc7229018c\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-159d1e631f323cbe43b5d325d53bc997_r.png\"\u002F\u003E之前介绍过 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F218468169\" class=\"internal\"\u003EFull Stack Deep Learning\u003C\u002Fa\u003E 这门课程，当之无愧是 Deep Learning 工程化产品化方面最好的课程（或许没有之一）。最近他们又顺应最近大模型领域的发展，推出了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Ffullstackdeeplearning.com\u002Fllm-bootcamp\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EFull Stack LLM Bootcamp\u003C\u002Fa\u003E 课程，同样也是非常的高质量。目前已经放出了大部分的视频，…","created":1684150360,"updated":1684150360,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","ipInfo":"IP 属地浙江","imageWidth":1200,"imageHeight":630,"content":"\u003Cp data-pid=\"NG--4eUt\"\u003E之前介绍过 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F218468169\" class=\"internal\"\u003EFull Stack Deep Learning\u003C\u002Fa\u003E 这门课程，当之无愧是 Deep Learning 工程化产品化方面最好的课程（或许没有之一）。最近他们又顺应最近大模型领域的发展，推出了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Ffullstackdeeplearning.com\u002Fllm-bootcamp\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EFull Stack LLM Bootcamp\u003C\u002Fa\u003E 课程，同样也是非常的高质量。目前已经放出了大部分的视频，周末花了点时间快速看了一遍，记录一下相关收获，也强烈推荐从事 LLM 应用开发的同学关注学习。\u003C\u002Fp\u003E\u003Ch2\u003ELaunch an LLM App in One Hour\u003C\u002Fh2\u003E\u003Cp data-pid=\"BMgDdGvW\"\u003E整个讲座的一个导论，信息量不大，先做个热身。\u003C\u002Fp\u003E\u003Cp data-pid=\"dmPcTR_L\"\u003E介绍了这波 AI 浪潮的一些背景，如大语言模型强大之处，一个模型就能搞定很多不同的任务。进而解锁了 Language User Interface 的很多可能。\u003C\u002Fp\u003E\u003Cp data-pid=\"UnA-YTDC\"\u003E回顾了下之前的 AI winter，主要原因是\u003Cb\u003E期望过高，交付的产品远远无法兑现承诺\u003C\u002Fb\u003E。而在当前这波浪潮中，已经有很多有价值的产品出现了，比如 ChatGPT，GitHub Copilot 等。自然引导到了基于 LLM 的应用的开发这个主题上来。\u003C\u002Fp\u003E\u003Cp data-pid=\"YkQ-M-fd\"\u003E\u003Cb\u003E开发 MVP 的方式\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"rjM64olG\"\u003E先用各种 playground 或者 chat 界面来做原型。\u003C\u002Fli\u003E\u003Cli data-pid=\"8W60PBJL\"\u003E利用开源框架来开发应用，优化 prompts。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"MtY2U26x\"\u003EFrye 举了个例子，比如先手动把 arxiv 上的 paper 摘要贴给模型，再给模型提问，就能拿到正确答案。接下来再在 notebook 里一步步把流程自动化，并加上更多的优化，如文档下载，分片，index 构建与搜索等。整个流程的确半小时就能搞定。\u003C\u002Fp\u003E\u003Cp data-pid=\"mLf-dy92\"\u003E\u003Cb\u003E部署 MVP 的方式\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"WMNfqvNB\"\u003E使用云平台可以快速进行部署，不过要记得限制 API 开销。\u003C\u002Fli\u003E\u003Cli data-pid=\"Yh_9sAdS\"\u003E使用简单的 UI，快速上线，收集用户反馈并迭代。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"I6uuDpay\"\u003E以他们的 discord bot app 为例，具体使用的 stack 包括：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"3PitOtNu\"\u003E模型：OpenAI\u003C\u002Fli\u003E\u003Cli data-pid=\"9vouq5KE\"\u003E数据存储：MongoDB\u003C\u002Fli\u003E\u003Cli data-pid=\"PCZuYwEc\"\u003E向量存储：Pinecone\u003C\u002Fli\u003E\u003Cli data-pid=\"T8BmuE6K\"\u003EServerless Backend：Modal\u003C\u002Fli\u003E\u003Cli data-pid=\"aV7zkOnB\"\u003EDiscord Bot Server: AWS EC2\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"4luUa4PA\"\u003E他提到要处理 300 多个 PDF，速度很慢。但利用像 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fmodal.com\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EModal\u003C\u002Fa\u003E 这样的云服务，可以同时启动上百个 container 来同步执行，速度一下子就快了很多。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-50b584a8e9d3a762a00e4bfc7229018c_b.jpg\" data-size=\"normal\" data-rawwidth=\"2744\" data-rawheight=\"1490\" class=\"origin_image zh-lightbox-thumb\" width=\"2744\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-50b584a8e9d3a762a00e4bfc7229018c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2744&#39; height=&#39;1490&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2744\" data-rawheight=\"1490\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2744\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-50b584a8e9d3a762a00e4bfc7229018c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-50b584a8e9d3a762a00e4bfc7229018c_b.jpg\" data-original-token=\"v2-159d1e631f323cbe43b5d325d53bc997\"\u002F\u003E\u003Cfigcaption\u003E一键并发载入 pdf\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"5Me3h9ji\"\u003ETwitter 上也有个类似的帖子讨论 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Ftwitter.com\u002Fompemi\u002Fstatus\u002F1653032136193060865\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E当下热门的 LLM 开发 stack 构成\u003C\u002Fa\u003E，评论区也有很多信息可供参考。\u003C\u002Fp\u003E\u003Ch2\u003ELLM Foundations\u003C\u002Fh2\u003E\u003Ch3\u003E技术原理\u003C\u002Fh3\u003E\u003Cp data-pid=\"jmaE8Rzg\"\u003E前面介绍机器学习、深度学习的基础，transformer，embedding 等原理，model hub 等就不展开了，应该大多数同学都了解。作为一名“老机器学习工程师”，看这段都有点恍如隔世的感觉  如果对于动手实现 transformer 有兴趣，推荐可以看下 Karpathy 的这个 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.bilibili.com\u002Fvideo\u002FBV1E14y1M75n\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E手把手实现 GPT 的教学视频\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp data-pid=\"P7PboSgw\"\u003E作者也提到了为何 transformer 为何如此有效的一些想法，例如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"vtJp7eT9\"\u003E表达能力很强，feed forward + attention 的海量参数。\u003C\u002Fli\u003E\u003Cli data-pid=\"4LCnyFg2\"\u003E可优化，通过反向传播算法，而且相比 RNN 这类更容易优化一些？\u003C\u002Fli\u003E\u003Cli data-pid=\"OeJ9Vw9Q\"\u003E高效，可以\u003Cb\u003E有效地扩展利用并行计算资源\u003C\u002Fb\u003E。这一点非常重要，也是 OpenAI 当年选择 transformer 的一个主要原因。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"Wo067TWd\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Faizi.substack.com\u002Fp\u002Fhow-does-gpt-3-spend-its-175b-parameters\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E大语言模型中的参数都用在哪了\u003C\u002Fa\u003E？可以看到在百亿参数量以上，差不多三分之二的参数实际上是 FFN 参数，剩下的基本都是 attention 参数。所以虽然论文名叫 attention is all you need，但实际上 FFN 仍然起到了很重要的作用。\u003C\u002Fp\u003E\u003Cp data-pid=\"7s_xWEku\"\u003E另外也提到了一篇来自 Anthropic 的文章 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Ftransformer-circuits.pub\u002F2022\u002Fin-context-learning-and-induction-heads\u002Findex.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EIn-context Learning and Induction Heads\u003C\u002Fa\u003E，深入探索了大语言模型 in-context learning 能力的来源。从对 in-context learning 能力的定义，特定的评估方法，再到对各种规格的模型训练过程的细致观察与各种干预实验都非常有意思，很值得一读。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db6659696afa0f777621094f5776409b_b.jpg\" data-size=\"normal\" data-rawwidth=\"1456\" data-rawheight=\"763\" class=\"origin_image zh-lightbox-thumb\" width=\"1456\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db6659696afa0f777621094f5776409b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1456&#39; height=&#39;763&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1456\" data-rawheight=\"763\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1456\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db6659696afa0f777621094f5776409b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db6659696afa0f777621094f5776409b_b.jpg\" data-original-token=\"v2-c578e569efafa8d6e8cc4af42b1f68d1\"\u002F\u003E\u003Cfigcaption\u003EInduction Heads\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003ELLM 走马观花\u003C\u002Fh3\u003E\u003Cp data-pid=\"Lh5oFRfK\"\u003E作者依次介绍了一些值得一提的大语言模型，个人感觉当前应用 LLM 的热点主要在 prompting，而训练 LLM 最重要的可能就是\u003Cb\u003E高质量数据集的构建\u003C\u002Fb\u003E了。所以在回看这些模型论文时，可以更多关注一下他们使用了什么样的数据集，以及如何进行清洗和处理。\u003C\u002Fp\u003E\u003Cp data-pid=\"oXiC73Hy\"\u003E\u003Cb\u003EBERT\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"xD5dm2XY\"\u003EPre-train + fine tune 的任务设计，强大的模型效果，也是当年在 NLP 界引起巨大轰动的一个模型。不过 BERT 是 encoder only 架构，从后续发展来看可能是“刷分”导向带歪了路。\u003C\u002Fp\u003E\u003Cp data-pid=\"j-4RsOOi\"\u003E\u003Cb\u003ET5\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"2x7YlgCE\"\u003EEncoder + decoder 架构。把各种 NLP 任务都统一成 text to text 的转换是一大创新。\u003C\u002Fp\u003E\u003Cp data-pid=\"V9Ke-h0m\"\u003E\u003Cb\u003EGPT\u002FGPT-2\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"zPABxxWB\"\u003EDecoder only 的架构引领了现在的潮流，但在当初的影响力并不大。他们使用的 Byte Pair Encoding 值得关注，在使用词典和 UTF-8 字节码之间找到一个平衡。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4e240dfb4badd095f71230df3ea257_b.jpg\" data-size=\"normal\" data-rawwidth=\"2778\" data-rawheight=\"1606\" class=\"origin_image zh-lightbox-thumb\" width=\"2778\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4e240dfb4badd095f71230df3ea257_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2778&#39; height=&#39;1606&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2778\" data-rawheight=\"1606\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2778\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4e240dfb4badd095f71230df3ea257_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4e240dfb4badd095f71230df3ea257_b.jpg\" data-original-token=\"v2-bee32dd538bc123ff0c1b9b1461048fd\"\u002F\u003E\u003Cfigcaption\u003EByte Pair Encoding\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"L34RxMss\"\u003E\u003Cb\u003EGPT-3\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"zVBBo7sl\"\u003E体现出了强大的 few-shot 和 zero-shot learning 能力，引领了 prompt engineering 风潮。另外有意思的是他们准备了 500B token 的训练数据，但实际只训练了 300B 就停止了。也就是\u003Cb\u003E所有训练数据模型只看了一次\u003C\u002Fb\u003E，跟他们分享中提到的“无损压缩”的思路一致。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21f3c9652a72bfb449e399a85f096b5e_b.jpg\" data-size=\"normal\" data-rawwidth=\"2794\" data-rawheight=\"1524\" class=\"origin_image zh-lightbox-thumb\" width=\"2794\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21f3c9652a72bfb449e399a85f096b5e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2794&#39; height=&#39;1524&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2794\" data-rawheight=\"1524\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2794\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21f3c9652a72bfb449e399a85f096b5e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21f3c9652a72bfb449e399a85f096b5e_b.jpg\" data-original-token=\"v2-8c2cf31c686000606c474d7e6e065135\"\u002F\u003E\u003Cfigcaption\u003EGPT-3 的训练数据\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"uSQFxddb\"\u003E\u003Cb\u003EChinchilla\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"h9Qz8Aa_\"\u003E探索了 scaling law，用 70B 参数加上\u003Cb\u003E更多的训练数据\u003C\u002Fb\u003E达到了 280B Gopher 模型的同等效果。\u003C\u002Fp\u003E\u003Cp data-pid=\"oBeyP3uJ\"\u003E\u003Cb\u003ELLaMA\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"Px2-3qil\"\u003EChinchilla-optimal 模型，开源发布但不允许商用。最近的 RedPajama 项目中尝试“复现”了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.together.xyz\u002Fblog\u002Fredpajama\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELLaMA 的训练数据集\u003C\u002Fa\u003E，可以说是功德无量了。\u003C\u002Fp\u003E\u003Cp data-pid=\"WJj2GNTj\"\u003E在这个讲座里还引用了很多 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fyaofu.notion.site\u002FHow-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EYao Fu 大佬的文章\u003C\u002Fa\u003E 内容，包括为何要在训练中包括代码数据，GPT 模型家族谱系图，alignment tax 等。\u003C\u002Fp\u003E\u003Cp data-pid=\"lrpHcgEA\"\u003E时下流行的 LLM 大多数也都在 pre-train 阶段之后做了 instruction fine tuning 以及 RLHF。作者也介绍了一下很多开源模型采用的 GPT 生成 instruction following 数据的方案，以及 23 年 4 月发布的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fdatasets\u002FOpenAssistant\u002Foasst1\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EOpen Assistant 数据集\u003C\u002Fa\u003E。对于 RLHF，个人也额外推荐两个最近看过的资料，一个是 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.youtube.com\u002Fwatch%3Fv%3DhhiLw5Q_UFg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EJohn Schulman 分享的通过 RL 来实现 Truthfulness\u003C\u002Fa\u003E，个人感觉还是比较能体现 RL 相对于 SFT 的优势的。另一个是 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.anthropic.com\u002Findex\u002Fclaudes-constitution\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EAnthropic 的 Constitutional AI\u003C\u002Fa\u003E，展现了或许可以不借助人工反馈也能实现价值观对齐。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bf874c83554cefe704100f1ed352ab1f_b.jpg\" data-size=\"normal\" data-rawwidth=\"3000\" data-rawheight=\"1305\" class=\"origin_image zh-lightbox-thumb\" width=\"3000\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bf874c83554cefe704100f1ed352ab1f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;3000&#39; height=&#39;1305&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"3000\" data-rawheight=\"1305\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3000\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bf874c83554cefe704100f1ed352ab1f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bf874c83554cefe704100f1ed352ab1f_b.jpg\" data-original-token=\"v2-2d457274f6450dfce32165ed4d80b9cf\"\u002F\u003E\u003Cfigcaption\u003EConstitutional AI\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E训练与推理\u003C\u002Fh3\u003E\u003Cp data-pid=\"YEwPFEou\"\u003E如果看课程 ppt，可以看到最后还有一块讲大模型训练与推理方面的内容。其中提到了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F2205.01068.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EOPT 训练的血泪史\u003C\u002Fa\u003E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Flilianweng.github.io\u002Fposts\u002F2023-01-10-inference-optimization\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E模型 inference 优化的手段\u003C\u002Fa\u003E 等。不过对于应用开发话题来说的确目前这些可能都用不太上。\u003C\u002Fp\u003E\u003Ch2\u003ELearn to Spell: Prompt Engineering\u003C\u002Fh2\u003E\u003Ch3\u003EPrompt 是一种魔法咒语\u003C\u002Fh3\u003E\u003Cp data-pid=\"KH6HiRgh\"\u003E终于来到魔法学堂的主要课程了！Frye 把 prompt 魔法分成了三类，并使用一些比喻来让大家更好理解。\u003C\u002Fp\u003E\u003Cp data-pid=\"dxB32Ajf\"\u003E当应用于 pre-train 模型时，prompt 像是《瞬息全宇宙》中的传送器，能让模型瞬间拥有某个平行宇宙中的特殊能力。更多的 prompt 内容会更多限定模型后续输出的空间，从而达到了一种让模型进入到不同模式来实现不同任务的效果。\u003C\u002Fp\u003E\u003Cp data-pid=\"pVgLjWCO\"\u003E当应用于 instruction-tuned 模型时，prompt 就像对着阿拉丁神灯许愿。许愿的内容自然也是越精确清晰越好。作者引用了来自 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F2109.07830.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EReframing Instructional Prompts to GPTk’s Language\u003C\u002Fa\u003E 这篇文章中的一些建议：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"6ezFNtTB\"\u003E使用\u003Cb\u003E非常细节具体的 pattern 示例\u003C\u002Fb\u003E，而不是需要背景知识的术语。比如“复杂的”，“专业的”这种形容就不如直接给一些具体句式效果更好。\u003C\u002Fli\u003E\u003Cli data-pid=\"wEMrd5j1\"\u003E将描述\u003Cb\u003E通过 bullet point 的形式\u003C\u002Fb\u003E逐项说明，如果放在一个长句里，模型很容易忽略后面的部分。如果有否定语句，转换成断言的形式。\u003C\u002Fli\u003E\u003Cli data-pid=\"zLBNXgti\"\u003E尽可能将一个任务分解成多个简单的任务。这个分而治之的技巧在很多地方都有被提到。\u003C\u002Fli\u003E\u003Cli data-pid=\"Xrbp7Yh2\"\u003E添加明确的对于输出的约束条件说明。比如 ReAct，AutoGPT 中都对于模型的输出形式做了很具体的限定。\u003C\u002Fli\u003E\u003Cli data-pid=\"sY87QSAa\"\u003E给出具体的指令。比如不要泛泛地说回答以下问题，而是根据你需要的输出，给出具体操作的建议。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"Z6tmcZfJ\"\u003E还有一个比较有意思的思考原则是，当前很多模型在做 instruction tuning 时所采用的数据都是人工打标的，所以你可以想象着\u003Cb\u003E在给一个新上手的打标人员描述你所需要完成的任务\u003C\u002Fb\u003E，就能得到一个效果不错的 prompt。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d2874e2654419f76e48e8bbcc6ae1ba3_b.jpg\" data-size=\"normal\" data-rawwidth=\"1850\" data-rawheight=\"682\" class=\"origin_image zh-lightbox-thumb\" width=\"1850\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d2874e2654419f76e48e8bbcc6ae1ba3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1850&#39; height=&#39;682&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1850\" data-rawheight=\"682\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1850\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d2874e2654419f76e48e8bbcc6ae1ba3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d2874e2654419f76e48e8bbcc6ae1ba3_b.jpg\" data-original-token=\"v2-162d67cd4cc3c052bcfb31f7fc001c50\"\u002F\u003E\u003Cfigcaption\u003E可以把模型当作一个新手标记员\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"U_CFVLWf\"\u003E而在时下火热的 LLM agent 方向上，prompt 就像是能够创建一个有生命的机器人。最常见的例子是网上很多 prompt 的例子都有种让 LLM 做“角色扮演”的感觉。作者对于这种角色扮演所产出的效果质量给出了一个很好的总结：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f5150a38f150889b20796bba4d7b250_b.jpg\" data-size=\"normal\" data-rawwidth=\"1150\" data-rawheight=\"1192\" class=\"origin_image zh-lightbox-thumb\" width=\"1150\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f5150a38f150889b20796bba4d7b250_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1150&#39; height=&#39;1192&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1150\" data-rawheight=\"1192\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1150\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f5150a38f150889b20796bba4d7b250_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f5150a38f150889b20796bba4d7b250_b.jpg\" data-original-token=\"v2-8df45a8cde723aa7cab9b9ee737c9b89\"\u002F\u003E\u003Cfigcaption\u003ELLM 角色扮演的效果\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"03KzuET7\"\u003E对于那些没法很好“模仿”的场景，我们需要通过例如 chain-of-thought 提示，调用外部工具等方式来提升效果。\u003C\u002Fp\u003E\u003Ch3\u003EPrompt 技术\u003C\u002Fh3\u003E\u003Cp data-pid=\"sUGEcDM2\"\u003EFrye 表示，few-shot learning 很多时候可能并不是一个好主意。举了几篇论文中的例子：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"tcs5zp5A\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2102.07350\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EPrompt Programming for Large Language Models\u003C\u002Fa\u003E 中，设计良好的 zero-shot prompt 表现与 few-shot 相比同样出色。\u003C\u002Fli\u003E\u003Cli data-pid=\"_zjfYU-L\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2202.12837\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ERethinking the Role of Demonstrations\u003C\u002Fa\u003E 和 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2303.03846\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELarger language models do in-context learning differently\u003C\u002Fa\u003E 中都尝试了将 few-shot 的例子 label 进行转换，但模型仍然主要按照其固有知识来做回答。所以模型可能只是学了任务形式，并没有把注意力放在 label 的具体信息上进行“学习”。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"bEQSQaiM\"\u003E前面提到了 GPT 的 BPE tokenization 方式也值得注意，模型可能因此不擅长做单词倒着拼写这类任务。一个 workaround 是在这种任务中\u003Cb\u003E给每个字母前后加上空格，就会识别为单个 token\u003C\u002Fb\u003E。包括在教 GPT 做长数字的加法时这个方法也有奇效 \u003C\u002Fp\u003E\u003Cp data-pid=\"kX8SaXML\"\u003E一些常见模式：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"Hf3KCeqs\"\u003E给出“结构化”的文本给模型操作。比如在 ReAct 中看到的 thought，action，action input，observation 这种固定结构的演示。\u003C\u002Fli\u003E\u003Cli data-pid=\"qYtt8NJO\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2210.02406\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EDecomposed Prompting\u003C\u002Fa\u003E 等方法来拆解复杂任务，以及像 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2210.03350\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Eself-ask\u003C\u002Fa\u003E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2210.03629\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EReAct\u003C\u002Fa\u003E 那样自动化这个过程。\u003C\u002Fli\u003E\u003Cli data-pid=\"4vpqcNXO\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2201.11903\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EChain-of-Thought prompting\u003C\u002Fa\u003E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2205.11916\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Elet&#39;s think step-by-step\u003C\u002Fa\u003E。这个应该已经人尽皆知了。\u003C\u002Fli\u003E\u003Cli data-pid=\"NlArBQTS\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2303.17491\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ESelf-criticism\u003C\u002Fa\u003E，让模型不断自我审视与修正回答。\u003C\u002Fli\u003E\u003Cli data-pid=\"92KFxQ1L\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2203.11171\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ESelf-consistency\u003C\u002Fa\u003E，通过略微不同的 prompt 以及稍高一点的 temperature 设定，让模型多生成几个回答，最后投票来选择最终的回答。通过这种方式也能大大提升准确率。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c253d1ac93bbbb6b5e4964b650f0424d_b.jpg\" data-size=\"normal\" data-rawwidth=\"2190\" data-rawheight=\"1014\" class=\"origin_image zh-lightbox-thumb\" width=\"2190\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c253d1ac93bbbb6b5e4964b650f0424d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2190&#39; height=&#39;1014&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2190\" data-rawheight=\"1014\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2190\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c253d1ac93bbbb6b5e4964b650f0424d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c253d1ac93bbbb6b5e4964b650f0424d_b.jpg\" data-original-token=\"v2-2cfed364ddd7d96775ad9a56580c0d81\"\u002F\u003E\u003Cfigcaption\u003ESelf-consistency\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"KEsl2uZJ\"\u003E这些模式还可以组合起来使用，以达到更好的效果。最后作者也总结了一下这些方法在速度和开销上的一些 trade-off 考量。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-443f02c1af178c69bfa9aada09f96463_b.jpg\" data-size=\"normal\" data-rawwidth=\"1364\" data-rawheight=\"1334\" class=\"origin_image zh-lightbox-thumb\" width=\"1364\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-443f02c1af178c69bfa9aada09f96463_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1364&#39; height=&#39;1334&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1364\" data-rawheight=\"1334\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1364\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-443f02c1af178c69bfa9aada09f96463_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-443f02c1af178c69bfa9aada09f96463_b.jpg\" data-original-token=\"v2-a27a4081a761056efe1406bb856a78e1\"\u002F\u003E\u003Cfigcaption\u003EPrompt 模式 trade-off\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E其它\u003C\u002Fh3\u003E\u003Cp data-pid=\"uqHkDHfB\"\u003E在 ppt 的最后一部分，作者还讨论了一下当前的 LLM 是否拥有 theory of mind，感兴趣的同学可以阅读一下。\u003C\u002Fp\u003E\u003Cp data-pid=\"H3SrUsdo\"\u003E另外关于 prompt engineering 还有很多非常好的学习资料：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"HD2QzLxi\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fopenai\u002Fopenai-cookbook\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EOpenAI Cookbook\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003Cli data-pid=\"jwibiHqH\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.pinecone.io\u002Flearn\u002Flangchain\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELangChain AI Handbook\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003Cli data-pid=\"zrWR5-eW\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Flearnprompting.org\u002Fdocs\u002Fintro\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELearn Prompting\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003Cli data-pid=\"wHiDPIob\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fdair-ai\u002FPrompt-Engineering-Guide\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EPrompt Engineering Guide\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003Cli data-pid=\"AtxZ4aa4\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Flilianweng.github.io\u002Fposts\u002F2023-03-15-prompt-engineering\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELilian Weng&#39;s blog\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch2\u003EAugment Language Models\u003C\u002Fh2\u003E\u003Cp data-pid=\"wPWs719Q\"\u003E作者提出了一个很有意思的观点，\u003Cb\u003ELLM 擅长于一般的语言理解与推理，而不是某个具体的知识点\u003C\u002Fb\u003E。所以 OpenAI 也一直没有急着把 21 年以后的数据扔进去训练个 up to date 的 ChatGPT。\u003C\u002Fp\u003E\u003Cp data-pid=\"8TqwnVkC\"\u003E所以一个很自然的想法就是通过各种手段来“增强”LLM，典型的方法包括信息获取，LLM Chains（通过 LLM 调用来增强 context），以及各类外部工具的使用。一眼看过去这不就是 LangChain 提供的核心功能嘛。\u003C\u002Fp\u003E\u003Ch3\u003ERetrieval\u003C\u002Fh3\u003E\u003Cp data-pid=\"jKhChyT1\"\u003E常见的各类基于 LLM 做问答的应用都结合了 information retrieval 的方式来构建 context，从而让 LLM 能够很好地根据特定信息作出回答。作者很贴心地给大家做了下这块的科普，包括倒排索引，BM25 等经典方法。当然 AI 领域用的最多的还是基于 embedding 的“语义搜索”。\u003C\u002Fp\u003E\u003Cp data-pid=\"xzZb3mjf\"\u003EEmbedding 的技术原理大家应该都挺熟悉了。在具体选择 embedding 模型时，可以参考 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fspaces\u002Fmteb\u002Fleaderboard\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Emteb 的 leaderboard\u003C\u002Fa\u003E。其中 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.sbert.net\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Esentence-transformers\u003C\u002Fa\u003E 是一个非常不错的 baseline，使用也很方便。大多数情况下大家应该都是直接使用 OpenAI 的\u003Ccode\u003Etext-embedding-ada-002\u003C\u002Fcode\u003E，效果好，便宜，直接一个 API 调用搞定。另外榜单上的第一名 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2212.09741\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EInstructor\u003C\u002Fa\u003E 也值得关注，其思想有点像经过 instruction tuning 的 embedding 模型。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a3d1ae37921e61676d985e88b9404610_b.jpg\" data-size=\"normal\" data-rawwidth=\"2242\" data-rawheight=\"1032\" class=\"origin_image zh-lightbox-thumb\" width=\"2242\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a3d1ae37921e61676d985e88b9404610_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2242&#39; height=&#39;1032&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2242\" data-rawheight=\"1032\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2242\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a3d1ae37921e61676d985e88b9404610_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a3d1ae37921e61676d985e88b9404610_b.jpg\" data-original-token=\"v2-3f0321557cfb68cd6d29d61ef122a9b2\"\u002F\u003E\u003Cfigcaption\u003EInstructor 模型\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"yCDyaIfv\"\u003E有了 embedding 模型之后，在做问答时的方式就是把 query 转换成向量，然后在文档向量库中做相似度搜索。在文档数量不超过百万量级时，其实\u003Cb\u003E简单的 numpy 计算相似度来做搜索就足够用了\u003C\u002Fb\u003E，不会跟那些近似搜索算法有多少体感上的差距。如果考虑到 LLM 本身调用的时间开销，这点差距可能就更不值一提了。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7e78bec238963110fa75789261c3b1ce_b.jpg\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"960\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7e78bec238963110fa75789261c3b1ce_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;960&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"960\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7e78bec238963110fa75789261c3b1ce_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7e78bec238963110fa75789261c3b1ce_b.jpg\" data-original-token=\"v2-4e44516eaefcb65909c57428bc919a28\"\u002F\u003E\u003Cfigcaption\u003Enumpy vs. hnsw\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"BbCXWSU5\"\u003E作者的建议是在做原型时直接用 numpy 就行，如果未来上生产环境，那么 IR 系统的选择会更加重要。比如选择一个整体的数据库解决方案，而不是重点考虑具体的 ANN 算法。\u003C\u002Fp\u003E\u003Cp data-pid=\"lLdooMQK\"\u003E在数据库的选择上，作者也是非常的 practical，\u003Cb\u003E直接选你现在用的数据库大概率就可以\u003C\u002Fb\u003E，比如 pgvector，elasticsearch，redis 之类。看了下 LangChain 里的 vectorstores，这些也都已经支持了。\u003C\u002Fp\u003E\u003Cp data-pid=\"v6ugRiEm\"\u003E不过呢，一些复杂场景下，embedding 这块也是有不少挑战的，例如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"FDHp4Q25\"\u003E数据库本身的可扩展性和可靠性，以及如果引入向量数据库怎么保持多个系统之间的一致性\u003C\u002Fli\u003E\u003Cli data-pid=\"Rymakr9X\"\u003E文档比较长怎么做 split\u003C\u002Fli\u003E\u003Cli data-pid=\"NDXTC3ad\"\u003E应该选择什么 embedding 方法，是否可以切换\u003C\u002Fli\u003E\u003Cli data-pid=\"l3Me9b3t\"\u003E是否能在相似度搜索基础上支持 metadata 条件查询\u003C\u002Fli\u003E\u003Cli data-pid=\"Mn9xFH9A\"\u003E是否支持多种类型的用户 query，例如关键词搜索，文档总结，多个文档之间的对比等\u003C\u002Fli\u003E\u003Cli data-pid=\"JH_VJ4Le\"\u003E是否能支持复杂的 index 结构，例如有层级关系的 index\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"AuWuIfbV\"\u003E为了解决这些问题，你可能需要考虑上个向量数据库，作者也给出了一个很贴心的对比图：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a612baaabe07dc112edda885523ec8_b.jpg\" data-size=\"normal\" data-rawwidth=\"2716\" data-rawheight=\"1308\" class=\"origin_image zh-lightbox-thumb\" width=\"2716\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a612baaabe07dc112edda885523ec8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2716&#39; height=&#39;1308&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2716\" data-rawheight=\"1308\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2716\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a612baaabe07dc112edda885523ec8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a612baaabe07dc112edda885523ec8_b.jpg\" data-original-token=\"v2-e1199ef7ddb14e307190da97542bfcc9\"\u002F\u003E\u003Cfigcaption\u003E向量数据库对比\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"XmZW-XzF\"\u003E总结来说如果想快速验证，Pinecone 是个不错的选择。如果想拥有更灵活的查询方式，可以考虑 Vespa 或 Weaviate，如果需要更好的 scalability\u002Freliability，那么经过大客户验证的 Vespa 或 Milvus 可能是不错的选择。\u003C\u002Fp\u003E\u003Cp data-pid=\"zOu-T3ZH\"\u003E如果玩过 retrieval + LLM 组合的应用的同学，可能会碰到一些问题导致召回质量不理想，例如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"yD4WrZWq\"\u003E用户的问题往往很短且形式多样\u003C\u002Fli\u003E\u003Cli data-pid=\"ex_EWgu6\"\u003E而相应的文档很长\u003C\u002Fli\u003E\u003Cli data-pid=\"D_s9-TN-\"\u003Eembedding 模型并不是在你的任务上训练的\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"jGOZv_st\"\u003E针对这些问题，可以考虑自己 train embedding 模型，或者基于 OpenAI embedding 基础上 train 一个简单的转换模型。另外像 LangChain，LlamaIndex 项目里也有很多方案可以尝试，例如 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2212.10496\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EHyDE\u003C\u002Fa\u003E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fblog.reachsumit.com\u002Fposts\u002F2023\u002F03\u002Fllm-for-text-ranking\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Ere-ranking\u003C\u002Fa\u003E，以及各种复杂的 tree\u002Fkeyword table index，query transformer，route retriever，compact and refine synthesize 等技术。如果对于这些细节内容感兴趣，也可以看一下我之前 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.bilibili.com\u002Fvideo\u002FBV1Yk4y1L7Vh\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E关于 LlamaIndex 的简单分享\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp data-pid=\"hiRKqOAc\"\u003E这部分的最后是个 case study，介绍了 GitHub Copilot 如何通过 retrieval 来增强 context。主要依据来自于 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fthakkarparth007.github.io\u002Fcopilot-explorer\u002Fposts\u002Fcopilot-internals\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E这篇对 Copilot plugin 的逆向工程\u003C\u002Fa\u003E。具体做法是：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"ppHEXk61\"\u003E召回：编辑器中最近访问的 20 个同类型文件。可以看到有时候规则可能也足够了。\u003C\u002Fli\u003E\u003Cli data-pid=\"wD6DeHIG\"\u003E后处理：当前光标前后的代码片段，以及从前面召回中通过相似度搜索最相近的文件片段。\u003C\u002Fli\u003E\u003Cli data-pid=\"qj6S9pDG\"\u003E排序：通过一些规则来对这些信息排序，最后会根据 context size 限制按排序选取尽可能多的内容。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"2RxvYLGR\"\u003E最后作者也展示了下目前最为广泛应用的 QA 场景中具体是如何结合 retrieval 的，也提到了通过不断 refine 的模式来突破 context size 限制，覆盖更多文档内容的方法。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-23a0c185b37ee4de6638a38fa1b6bf92_b.jpg\" data-size=\"normal\" data-rawwidth=\"2512\" data-rawheight=\"1202\" class=\"origin_image zh-lightbox-thumb\" width=\"2512\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-23a0c185b37ee4de6638a38fa1b6bf92_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2512&#39; height=&#39;1202&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2512\" data-rawheight=\"1202\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2512\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-23a0c185b37ee4de6638a38fa1b6bf92_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-23a0c185b37ee4de6638a38fa1b6bf92_b.jpg\" data-original-token=\"v2-bb56b23c3091a12c466341102fde8a30\"\u002F\u003E\u003Cfigcaption\u003ERetrieval 应用与问答场景\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003EChains\u003C\u002Fh3\u003E\u003Cp data-pid=\"oUerrZy1\"\u003E从上一个话题自然延伸，有时候\u003Cb\u003E最好的 context 信息并不直接存在于各种外部文档中，而是需要另一个 LLM 的输出来进行构建\u003C\u002Fb\u003E。比如前面提到的 HyDE，就是先通过 LLM 来不依赖外部信息回答问题，然后再将回答内容和问题拿去做 embedding，相似度搜索，形成最终的 QA prompt。另外像 summary 场景中“map-reduce”的做法应该大家也都很熟悉了。\u003C\u002Fp\u003E\u003Cp data-pid=\"fnjEq0bg\"\u003E针对 Chain 这方面需求最典型的开源框架就是 LangChain 了，是一个超级火热更新速度超快的库。不过这部分的课程并没有展开介绍细节，感兴趣的同学也可以参考我之前的这个 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.bilibili.com\u002Fvideo\u002FBV1DY4y1Q7Te\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E分享视频\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Ch3\u003ETools\u003C\u002Fh3\u003E\u003Cp data-pid=\"TjHIVdsf\"\u003E很多人觉得 LLM 距离 AGI 的一大差距是没法与真实世界连接，但其实已经有很多工作（例如 Toolformer 等）在尝试让 LLM 自主使用外部工具了。作者以 SQL 工具为例展示了下 LLM 如何来利用外部工具。大致为以下几个步骤：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"ssjqm3O7\"\u003E用户问了一个问题\u003C\u002Fli\u003E\u003Cli data-pid=\"hTn7TreC\"\u003E将用户问题和数据库的 meta 信息放到 prompt 里，让 LLM 去生成 SQL\u003C\u002Fli\u003E\u003Cli data-pid=\"InNV3s1v\"\u003E利用数据库来执行这个 SQL 查询，这就是工具的调用\u003C\u002Fli\u003E\u003Cli data-pid=\"4HMX9XP4\"\u003E将数据库查询结果与问题再扔给 LLM 做最终回答\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"MDNNiM5-\"\u003E当然这个步骤可以说是由 Chain 定义固定下来的，也可以采用类似 agent\u002Fplugin 的方式来让 LLM 自行决定在何时使用什么工具。用户只需要提供 API 的 spec 和描述，就可以快速接入到 plugin 体系中。\u003C\u002Fp\u003E\u003Cp data-pid=\"dyM_LyS5\"\u003E这两种方式主要的权衡在于\u003Cb\u003E可靠性或者是流程的确定程度\u003C\u002Fb\u003E。Chain 的运作流程是人工定义好的，流程不会出错，且对 LLM 来说生成具体的工具指令也会准确率更高。而 plugin 的优势在于极大的流程灵活度，可以用统一入口满足用户各类诉求。虽然可靠性会下降不少，但也可以考虑引入人工交互来弥补。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f93bab761db292049d1a80d9a6d07537_b.jpg\" data-size=\"normal\" data-rawwidth=\"2622\" data-rawheight=\"1226\" class=\"origin_image zh-lightbox-thumb\" width=\"2622\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f93bab761db292049d1a80d9a6d07537_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2622&#39; height=&#39;1226&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2622\" data-rawheight=\"1226\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2622\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f93bab761db292049d1a80d9a6d07537_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f93bab761db292049d1a80d9a6d07537_b.jpg\" data-original-token=\"v2-c16dfb1699fcb7ef3ef534cb80203634\"\u002F\u003E\u003Cfigcaption\u003E两种应用工具的模式\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"1J3yjRM0\"\u003E最后还有一篇 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2302.07842\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E关于 augmented 语言模型的 survey 文章\u003C\u002Fa\u003E 可供参考学习。\u003C\u002Fp\u003E\u003Ch2\u003EProject Walkthrough\u003C\u002Fh2\u003E\u003Cp data-pid=\"Dsbrc9fJ\"\u003E带着大家过了一下 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fthe-full-stack\u002Fask-fsdl\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EaskFSDL\u003C\u002Fa\u003E 这个项目，live coding 的感觉很爽。\u003C\u002Fp\u003E\u003Cp data-pid=\"laR_9Cfn\"\u003E对于算法工程师来说，能学到不少 Python 工程方面的最佳实践，比如 pre-commit，makefile，用 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgradio.app\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Egradio\u003C\u002Fa\u003E 来写简单的界面，通过 modal 来管理 infra 等。\u003C\u002Fp\u003E\u003Cp data-pid=\"oWOaH8QH\"\u003E对于软件工程师来说，可能数据接入这块之前接触的并不多，可以学习一下如何接入 markdown，PDF，Youtube transcript 等类型的文件，并尽可能多地保留原始信息。还有包括通过 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgantry.io\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Egantry\u003C\u002Fa\u003E 来收集用户行为与反馈数据，并借助 LLM 来进行分析的方法应该也挺有启发。\u003C\u002Fp\u003E\u003Ch2\u003EUX for Language User Interface\u003C\u002Fh2\u003E\u003Ch3\u003EUI Principles\u003C\u002Fh3\u003E\u003Cp data-pid=\"YnB6Q-dP\"\u003E开头介绍了 user interface 的历史，以及一些设计原则。其中提到的诸如\u003Cb\u003E同理心，找真实用户进行测试\u003C\u002Fb\u003E个人还是很有感触的。对这方面感兴趣的同学还可以参考我之前的这篇 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F574184394\" class=\"internal\"\u003E如何打造产品\u003C\u002Fa\u003E。要知道 Sam Altman 最出名的可能就是他对于 PMF 的深刻理解了 \u003C\u002Fp\u003E\u003Cp data-pid=\"E-QYzVpG\"\u003E具体到 AI 产品上，我们可以将 AI 能力以及决策错误的后果作为两个维度来进行分析：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9afa76a60cc4400f4477d90081dd993d_b.jpg\" data-size=\"normal\" data-rawwidth=\"2614\" data-rawheight=\"1274\" class=\"origin_image zh-lightbox-thumb\" width=\"2614\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9afa76a60cc4400f4477d90081dd993d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2614&#39; height=&#39;1274&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2614\" data-rawheight=\"1274\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2614\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9afa76a60cc4400f4477d90081dd993d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9afa76a60cc4400f4477d90081dd993d_b.jpg\" data-original-token=\"v2-519bbea992f15f0a5d4f1be2ce35aad0\"\u002F\u003E\u003Cfigcaption\u003E不同情况下 AI 与用户的协作关系\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"cTz_eZVh\"\u003E设计良好的交互，不光能让用户用得更爽，还能很自然地收集到很多用户反馈信息，建立起\u003Cb\u003E数据飞轮\u003C\u002Fb\u003E。例如在 Midjourney 中，用户必须通过明确的点击来选定四个备选图像中的一张做 variation 或者 upscale 并下载。\u003C\u002Fp\u003E\u003Ch3\u003ELUI Patterns\u003C\u002Fh3\u003E\u003Cp data-pid=\"gajjhZx2\"\u003E当前 Language User Interface 的几种常见 pattern 包括：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"M68UaAkv\"\u003EClick-to-complete，例如 OpenAI Playground。\u003C\u002Fli\u003E\u003Cli data-pid=\"29xxisde\"\u003EAuto-complete，例如 GitHub Copilot。\u003C\u002Fli\u003E\u003Cli data-pid=\"fIOQ_jel\"\u003ECommand palette，例如 Replit。\u003C\u002Fli\u003E\u003Cli data-pid=\"qDuUyS4v\"\u003EOne-on-one chat，例如 ChatGPT。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"gyrtb75C\"\u003E作者进而提出一个框架来分析这几类 pattern 对于产品的要求，包括了几个角度。我们以 GitHub Copilot 为例来看下具体分析。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"g1_8wSCA\"\u003EUI 的边界是什么。这一点 Copilot 非常自然，直接在 IDE 里提供补全，用户不需要做任何切换动作。\u003C\u002Fli\u003E\u003Cli data-pid=\"lIHhQLyo\"\u003E对于准确率的要求有多高。相对来说不高，因为用户完全可以不理会建议，或者接受后再做少量修改。\u003C\u002Fli\u003E\u003Cli data-pid=\"EkDzeg6O\"\u003E对于延迟要求有多高。要求比较高，大多数用户对于自动补全的习惯性期待肯定得在 1 秒以内。\u003C\u002Fli\u003E\u003Cli data-pid=\"TqZWIN5W\"\u003E是否鼓励用户给出反馈。这一点也比较好，如果用户接受了建议，是一个很强烈的反馈信号。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"muqAZqqi\"\u003E大家也可以用这个框架来审视一下自己的应用。尤其是第四点\u003Cb\u003E如何鼓励用户给出反馈\u003C\u002Fb\u003E，还是挺需要好好思考一下的。除了前面提到的 Midjourney 外，像 ChatGPT 里 regenerate response 和后面带的问题这种形式也很好，用户体验很流畅，同时又能拿到信号非常强烈的反馈。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-be4c407d82d4f5a40e3321f5e66fc16a_b.jpg\" data-size=\"normal\" data-rawwidth=\"1436\" data-rawheight=\"1910\" class=\"origin_image zh-lightbox-thumb\" width=\"1436\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-be4c407d82d4f5a40e3321f5e66fc16a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1436&#39; height=&#39;1910&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1436\" data-rawheight=\"1910\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1436\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-be4c407d82d4f5a40e3321f5e66fc16a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-be4c407d82d4f5a40e3321f5e66fc16a_b.jpg\" data-original-token=\"v2-5f04af748cc9ef0c308a81da0daf0243\"\u002F\u003E\u003Cfigcaption\u003EChatGPT UI 中的设计亮点\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003ECase Studies\u003C\u002Fh3\u003E\u003Cp data-pid=\"jbMIF65E\"\u003E接下来一部分的 case study 个人感觉非常精彩，分享了对于 GitHub Copilot 和 Bing Chat 两个产品用户交互方面的分析。\u003C\u002Fp\u003E\u003Cp data-pid=\"qPEjptO_\"\u003E\u003Cb\u003EGitHub Copilot\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"KOxcjQNX\"\u003E在训练了代码生成模型后，他们一开始在很多可能的产品方向进行了分析与探索，包括：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7299eec84c9ad9e9537f285e8d652ed8_b.jpg\" data-size=\"normal\" data-rawwidth=\"2660\" data-rawheight=\"1948\" class=\"origin_image zh-lightbox-thumb\" width=\"2660\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7299eec84c9ad9e9537f285e8d652ed8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2660&#39; height=&#39;1948&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2660\" data-rawheight=\"1948\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2660\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7299eec84c9ad9e9537f285e8d652ed8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7299eec84c9ad9e9537f285e8d652ed8_b.jpg\" data-original-token=\"v2-d5d021c76213d65bbc4b8aba805868a3\"\u002F\u003E\u003Cfigcaption\u003E尝试各种 idea\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"BKzcVMrM\"\u003E很快他们就发现，当前的模型效果只能很好地支持 auto-complete 产品，而无法支持前两者。\u003C\u002Fp\u003E\u003Cp data-pid=\"akuJvQ_3\"\u003E选定方向后，他们针对用户界面和体验方面做了很多 ab 测试，主要依据的指标是用户对于代码提示的接受率以及 30 天后的用户留存率。获取到了很多有价值的信息，最终打造出了一款用户喜爱且能产生很多实际价值的产品。\u003C\u002Fp\u003E\u003Cp data-pid=\"1YkoUcvV\"\u003E\u003Cb\u003EBing Chat\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"MlVusFGc\"\u003EBing Chat 相对来说在用户体验方面的考量就没有那么全面，更像是为了抢占市场而急忙推出的一个产品。网上也持续有关于 Bing Chat 出问题的各种负面反馈出现，例如回答不友好，会出现胡言乱语，没法理解用户意图，“泄漏”prompt，甚至出现威胁用户等。作者认为他们可能犯了几个错误：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"oB173X_x\"\u003E急于推出产品，底层的模型可能没有经过 RLHF 做 alignment，导致了很多网上出现的很多有问题的回复案例。\u003C\u002Fli\u003E\u003Cli data-pid=\"x3z5rfi_\"\u003E没有注意到\u003Cb\u003E潜在的反馈循环\u003C\u002Fb\u003E。跟 ChatGPT 相比，Bing Chat 是“联网”的，所以每当它产生一些奇怪回复后，用户会贴到网上，然后搜索引擎又会很快索引这些信息，反过来不断增强出现这些奇怪回复的可能性。\u003C\u002Fli\u003E\u003Cli data-pid=\"q4y5YDgK\"\u003E\u003Cb\u003E用户界面的“引导”与产品实际提供的能力不符\u003C\u002Fb\u003E。很多做 AI 应用的同学可能都觉得为了让产品更酷炫，应该尽可能让交互界面像真人。比如生成一个真人头像，利用 D-ID，ElevenLabs 等技术让它能够像真人一样用非常流畅自然的语音回答。但是这会让用户的期望值拉得非常高，如果你的模型不能够达到真人交互的水平，那么用户的失望感就会非常强烈。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6496750b2087ad4c908aeb5cc2e37aad_b.jpg\" data-size=\"normal\" data-rawwidth=\"2008\" data-rawheight=\"1950\" class=\"origin_image zh-lightbox-thumb\" width=\"2008\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6496750b2087ad4c908aeb5cc2e37aad_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2008&#39; height=&#39;1950&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2008\" data-rawheight=\"1950\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2008\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6496750b2087ad4c908aeb5cc2e37aad_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6496750b2087ad4c908aeb5cc2e37aad_b.jpg\" data-original-token=\"v2-60aee58fffcf89ef6d525f716f6fc400\"\u002F\u003E\u003Cfigcaption\u003ELUI 应该强调自己是个机器人\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003ELLMOps\u003C\u002Fh2\u003E\u003Cp data-pid=\"GrSvOe8r\"\u003E这一节也非常有信息量，推荐观看。\u003C\u002Fp\u003E\u003Ch3\u003E选择基础模型\u003C\u002Fh3\u003E\u003Cp data-pid=\"aynOWJpb\"\u003E从几个维度来考虑选择哪个模型，包括\u003Cb\u003E模型的效果，推理速度，价格开销，能否微调，数据安全，许可协议\u003C\u002Fb\u003E等。\u003C\u002Fp\u003E\u003Cp data-pid=\"S4MSACIK\"\u003E就 23 年 5 月这个时间节点来说，对于私有模型的建议：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"ycLxDvp0\"\u003E绝大多数情况都可以直接选择 GPT-4 作为尝试的开始。后续如果有成本和速度的考量可以再切换到 GPT-3.5。\u003C\u002Fli\u003E\u003Cli data-pid=\"yjcfBVvx\"\u003EClaude 也是个不错的选择，无论是模型效果还是训练的完善程度上，再加上现在支持了超大的 context size，赶忙去申请了 wait-list。\u003C\u002Fli\u003E\u003Cli data-pid=\"68_b2Stz\"\u003E如果需要做 fine tune，也可以考虑 Cohere 的 command 系列。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d64a8dd05af98f6fc3c6004bf01c2617_b.jpg\" data-size=\"normal\" data-rawwidth=\"4866\" data-rawheight=\"2260\" class=\"origin_image zh-lightbox-thumb\" width=\"4866\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d64a8dd05af98f6fc3c6004bf01c2617_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;4866&#39; height=&#39;2260&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"4866\" data-rawheight=\"2260\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"4866\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d64a8dd05af98f6fc3c6004bf01c2617_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d64a8dd05af98f6fc3c6004bf01c2617_b.jpg\" data-original-token=\"v2-0ade15371e5503ca63d1a8992dad3e18\"\u002F\u003E\u003Cfigcaption\u003E私有模型对比一览\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"go21h-SI\"\u003E开源模型这块发展很快，最近几周都有新模型出来。这块的许可协议也很复杂，例如有些模型的不同版本因为用了特殊的数据就导致无法作为商业用途。在讲座的时间节点，作者的几个推荐是：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"JNGkhCkj\"\u003E如果希望完全开放的使用，T5\u002FFlan-T5 是个不错的选择，效果也还行。\u003C\u002Fli\u003E\u003Cli data-pid=\"arKbyQEe\"\u003E开源可商用这块可以考虑最近的 Dolly，StableLM。\u003C\u002Fli\u003E\u003Cli data-pid=\"EyynAcdL\"\u003E如果用于研究用途，LLaMA 系列是目前比较主流的。如果对于 2020 年的 GPT-3 复现与实验感兴趣，可以用 OPT。\u003C\u002Fli\u003E\u003Cli data-pid=\"Xc_v32c-\"\u003E其它基本不太用考虑，包括表上的 Bloom 和 GLM。不过这个表的更新迭代速度应该会很快。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-03fd35ca0cbffe47d6c40cdd80e24bc8_b.jpg\" data-size=\"normal\" data-rawwidth=\"4890\" data-rawheight=\"2282\" class=\"origin_image zh-lightbox-thumb\" width=\"4890\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-03fd35ca0cbffe47d6c40cdd80e24bc8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;4890&#39; height=&#39;2282&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"4890\" data-rawheight=\"2282\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"4890\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-03fd35ca0cbffe47d6c40cdd80e24bc8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-03fd35ca0cbffe47d6c40cdd80e24bc8_b.jpg\" data-original-token=\"v2-3ad03eee5e92ddc9130c725227fbbd64\"\u002F\u003E\u003Cfigcaption\u003E开源模型对比一览\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"sTV0HluV\"\u003E总体来说在当前私有模型的能力大大超过了开源模型，对于应用开发来说估计 23 年的主流都是使用私有模型。\u003C\u002Fp\u003E\u003Ch3\u003EPrompt 迭代开发\u003C\u002Fh3\u003E\u003Cp data-pid=\"yBW-nAIf\"\u003E传统深度学习里对于实验追踪与记录有着非常完善的支持，但目前的 prompt 开发与迭代还在很早期的阶段，主要还是因为不同 prompt 产生的效果并不好自动化评估。\u003C\u002Fp\u003E\u003Cp data-pid=\"qKDCfwHc\"\u003E因此现阶段比较常见的做法就是通过 git 来管理 prompt 版本。如果有更复杂的需求，例如希望把 prompt 的应用逻辑解耦，或者引入业务人员来优化 prompt，以及通过单独的产品工具来快速评估管理不同的 prompt 甚至模型接口，那么就需要引入更加复杂的产品。这方面可以持续关注之前的 experiment tracking 产品，包括 WandB，MLFlow 等。\u003C\u002Fp\u003E\u003Ch3\u003E测试\u003C\u002Fh3\u003E\u003Cp data-pid=\"8oidKCmR\"\u003ELLM 的能力非常强大，能处理各种任务，这对其评估造成了很大的困难，比如我们很难判断一篇总结是否比另外一篇总结写得更好。对于不同的 prompt，模型甚至 fine tune 的效果，如何进行快速，低成本且准确的评估是一个大问题。目前的常见做法是：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"kfSrAY5Z\"\u003E构建一个针对你所需要完成任务的评估数据集，一开始可以完全人工生成，后续逐渐完善。\u003C\u002Fli\u003E\u003Cli data-pid=\"DCXa7oZG\"\u003E除了通过人工检验的方式，也可以\u003Cb\u003E借助 LLM 来做评估\u003C\u002Fb\u003E。可以参考 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Flangchain-ai\u002Fauto-evaluator\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Eauto-evaluator\u003C\u002Fa\u003E 项目。\u003C\u002Fli\u003E\u003Cli data-pid=\"HLIHokVE\"\u003E在添加新的评估数据时，需要考虑这条样本带来的“额外价值”，比如是否是一个比较困难的问题，以及与已有评估数据是不是非常不一样。\u003C\u002Fli\u003E\u003Cli data-pid=\"RTkTZ9Fm\"\u003E思考“AI 测试覆盖率”，你收集的评估数据集能多大程度上覆盖生产环境的所有情况？\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"gLvqs9Xb\"\u003E通过 LLM 来做评估的具体方法包括：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"iLZiBdH6\"\u003E如果有完全精确的答案判定，可以用传统指标，不需要借助 LLM。\u003C\u002Fli\u003E\u003Cli data-pid=\"39R6pXuI\"\u003E如果你有标准答案，可以测试语义相似度，或者询问 LLM：两个回答是否一致？\u003C\u002Fli\u003E\u003Cli data-pid=\"XOjRYWPP\"\u003E如果有上一个版本的回答，可以询问 LLM：哪一个回答更好？\u003C\u002Fli\u003E\u003Cli data-pid=\"pOealCyq\"\u003E如果有用户填写的反馈信息，可以询问 LLM：用户的反馈是否已经包含在回答中了？\u003C\u002Fli\u003E\u003Cli data-pid=\"v7QvkBWO\"\u003E其它情况，可以通过外部工具来检查是否是个合法的格式，或者让 LLM 给回答做个打分。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-11b8eebad9d57c9b1fd218373c01266f_b.jpg\" data-size=\"normal\" data-rawwidth=\"4118\" data-rawheight=\"2012\" class=\"origin_image zh-lightbox-thumb\" width=\"4118\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-11b8eebad9d57c9b1fd218373c01266f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;4118&#39; height=&#39;2012&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"4118\" data-rawheight=\"2012\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"4118\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-11b8eebad9d57c9b1fd218373c01266f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-11b8eebad9d57c9b1fd218373c01266f_b.jpg\" data-original-token=\"v2-ae0bdf99f06240d5127660328a1a6155\"\u002F\u003E\u003Cfigcaption\u003ELLM 模型评估\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E部署\u003C\u002Fh3\u003E\u003Cp data-pid=\"BpMYQ2T9\"\u003E简单的应用可以直接从前端发起模型请求即可。如果业务逻辑复杂，再考虑单独开发个后端服务。这个示范 stack 也在前面有提到。\u003C\u002Fp\u003E\u003Cp data-pid=\"W-KpiP-k\"\u003E私有化部署 LLM 不在本课程讨论范围内……\u003C\u002Fp\u003E\u003Cp data-pid=\"yRz31gIi\"\u003E一些提升 LLM 输出稳定性的手段：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"Or6v9IOG\"\u003ESelf-critique\u003C\u002Fli\u003E\u003Cli data-pid=\"9OsjyTwf\"\u003E多采样几次，选最好的那次\u003C\u002Fli\u003E\u003Cli data-pid=\"WoxiNG5q\"\u003E多采样几次，投票\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"uG8dILjS\"\u003E可以参考这个比较新的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002FShreyaR\u002Fguardrails\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Eguardrails\u003C\u002Fa\u003E 项目。\u003C\u002Fp\u003E\u003Ch3\u003E监控\u003C\u002Fh3\u003E\u003Cp data-pid=\"qPpVVz6a\"\u003E这里应该也是一些标准做法了，可以结合前面的 UX 设计，主要思考如何系统性地获取并持续监控用户反馈。越是对用户来说没有什么负担的操作，越是信息含量高的操作，对于实际的业务监控越有效。\u003C\u002Fp\u003E\u003Cp data-pid=\"wLDnGue1\"\u003E一些常见的可能出问题的点：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"HPQO_hhK\"\u003EUI 问题，延迟太大。这也是出现最多的一类。\u003C\u002Fli\u003E\u003Cli data-pid=\"WmpNZYVK\"\u003E错误的回答，hallucinations。\u003C\u002Fli\u003E\u003Cli data-pid=\"VG3tAy_V\"\u003E冗长无用的回答。\u003C\u002Fli\u003E\u003Cli data-pid=\"wcqByp08\"\u003E拒绝回答。\u003C\u002Fli\u003E\u003Cli data-pid=\"cjJ2XFZg\"\u003EPrompt injection。\u003C\u002Fli\u003E\u003Cli data-pid=\"2BnbT_ox\"\u003E违背价值观的回答。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch3\u003E持续优化与 fine tune\u003C\u002Fh3\u003E\u003Cp data-pid=\"YPbx2YrK\"\u003E如果监控或者收集到上述问题的用户反馈，后续可以通过 prompt 优化或者 fine tune 的手段来持续改进。一般来说\u003Cb\u003E优先选择前者\u003C\u002Fb\u003E，尤其是当前开源模型，fine tune 技术都没有那么成熟的情况下。Slides 上有一些 fine tune 相关的内容介绍，不过作者认为当前应该多数情况下不需要，就跳过了  什么时候需要 fine tune 呢？\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"Km1mf2_y\"\u003E你需要节省成本，比如用更小的模型，不想每次都带一大段 prompt 之类。\u003C\u002Fli\u003E\u003Cli data-pid=\"Wbg4BL2s\"\u003E你有大量的数据，且 retrieval 的方法表现不够理想。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"0UD4vzbu\"\u003E大家如果有成功应用 fine tune 模式的例子，也欢迎交流分享。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-138f578cc5f3b7286456bd2cc7366257_b.jpg\" data-size=\"normal\" data-rawwidth=\"4224\" data-rawheight=\"2106\" class=\"origin_image zh-lightbox-thumb\" width=\"4224\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-138f578cc5f3b7286456bd2cc7366257_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;4224&#39; height=&#39;2106&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"4224\" data-rawheight=\"2106\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"4224\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-138f578cc5f3b7286456bd2cc7366257_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-138f578cc5f3b7286456bd2cc7366257_b.jpg\" data-original-token=\"v2-4511ae1b5bf41c63f10b455173a1b606\"\u002F\u003E\u003Cfigcaption\u003ELLM 应用迭代优化流程\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003EWhat&#39;s Next\u003C\u002Fh2\u003E\u003Cp data-pid=\"pyG0pDW5\"\u003E最后一个 session，展望一下未来，也是笑点最多的一集。\u003C\u002Fp\u003E\u003Ch3\u003E大模型的下一步发展方向\u003C\u002Fh3\u003E\u003Cp data-pid=\"FXgVnmuM\"\u003E作者认为一个很有希望的领域是多模态与机器人的结合。介绍了包括 ViT，PaLM-E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002FVision-CAIR\u002FMiniGPT-4\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMiniGPT-4\u003C\u002Fa\u003E，以及将 LLM 应用工具的思想拓展到机器人领域等工作。\u003C\u002Fp\u003E\u003Ch3\u003E大模型如何继续 scale\u003C\u002Fh3\u003E\u003Cp data-pid=\"9CCQ7hTi\"\u003E\u003Cb\u003ETransformer 就是终极架构吗？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"JEcIoEkG\"\u003E之前看 RNN 相对来说很容易达到性能瓶颈，而且不能有效利用并行计算资源。不过看起来 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002FBlinkDL\u002FRWKV-LM\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ERWKV\u003C\u002Fa\u003E 可能会是 RNN 的“逆袭”机会？\u003C\u002Fp\u003E\u003Cp data-pid=\"Q_HKjGmj\"\u003E\u003Cb\u003E钱，算力，数据哪个会成为大模型继续 scale 的瓶颈？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"bZIyeP2h\"\u003E总体来说最有可能成为瓶颈的是数据。比如 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2211.04325\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EWill we run out of data?\u003C\u002Fa\u003E 这篇文章认为我们在 2026 年之前就会碰到高质量数据增长跟不上算力提升的速度。而如果从 Chinchilla 论文中的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.lesswrong.com\u002Fposts\u002F6Fpvch8RR29qLEWNH\u002Fchinchilla-s-wild-implications\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Escaling law 公式\u003C\u002Fa\u003E 来推算，在特定数据量下即使是\u003Cb\u003E无限的参数量\u003C\u002Fb\u003E都没法打败拥有更多数据量训练出来的有限参数量的模型。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71ed6b62ee977ad4aca5f644b698af96_b.jpg\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb\" width=\"592\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71ed6b62ee977ad4aca5f644b698af96_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;592&#39; height=&#39;509&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"592\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71ed6b62ee977ad4aca5f644b698af96_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71ed6b62ee977ad4aca5f644b698af96_b.jpg\" data-original-token=\"v2-cf4733b034ec81e61923584c1301dda7\"\u002F\u003E\u003Cfigcaption\u003E通过 scaling law 推算无限参数\u002F数据情况下的模型性能\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"g52uoM_S\"\u003E\u003Cb\u003E小模型能够走多远？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"_c77pLtA\"\u003E因为 retrieval 模式非常有效，所以大家自然会有想法说是不是不需要那么大的模型来记住各种知识点，而只需要一个\u003Cb\u003E拥有推理能力的小模型\u003C\u002Fb\u003E就可以？另外像 Alpaca 这些从 ChatGPT“蒸馏”训练的方式目前看起来在简单场景上还挺有效的。小模型可以在手机端，机器人设备上直接部署使用，想象空间还是非常大的。\u003C\u002Fp\u003E\u003Ch3\u003EAGI 已经到来了吗？\u003C\u002Fh3\u003E\u003Cp data-pid=\"2qqh2CLo\"\u003E作者觉得有可能已经到了，只是我们还没有认识到。一些论点：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"7zqcJlQg\"\u003E现有模型能做什么，还需要我们花很多时间去挖掘。一个很有名的例子是一开始以为 LLM 不能做推理，但后来发现加一个 let&#39;s think step by step 就把准确率从 17.7%提升到了 78.7%。还有多少这样的现象是我们还没发现的？\u003C\u002Fli\u003E\u003Cli data-pid=\"ni0k7ihd\"\u003E模型已经可以自己探索和发现自己的能力了。比如在 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2211.01910\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELarge Language Models Are Human-Level Prompt Engineers\u003C\u002Fa\u003E 中，作者发现模型可以自己设计 prompt，甚至超过人类水平。\u003C\u002Fli\u003E\u003Cli data-pid=\"ccETsSU2\"\u003E模型可能已经可以做到自我提升了。比如 Anthropic 的 Constitutional AI，再比如让模型自己学会写代码和 debug，是不是未来也可能自己写 GPT-X 的训练优化代码自己提升？还有像 AutoGPT，BabyAGI 这些赋予 agent 使用工具和长期记忆能力的尝试，也是一个可能的方向。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"WwpTixv8\"\u003E作者认为可以把 GPT-4 理解为一种新的 CPU，它的 context 相当于内存。我们现在的 prompt 还处在一个很原始的应用这种新型计算机的阶段（接近机器码？），还远没有出现更高阶的智能计算编程语言与框架。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a652ac90357c3218cfb807a36cf7533e_b.jpg\" data-size=\"normal\" data-rawwidth=\"2798\" data-rawheight=\"1462\" class=\"origin_image zh-lightbox-thumb\" width=\"2798\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a652ac90357c3218cfb807a36cf7533e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2798&#39; height=&#39;1462&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2798\" data-rawheight=\"1462\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2798\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a652ac90357c3218cfb807a36cf7533e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a652ac90357c3218cfb807a36cf7533e_b.jpg\" data-original-token=\"v2-13656274cc02a4eb8463e5d380de53bc\"\u002F\u003E\u003Cfigcaption\u003EGPT 是认知计算机的 CPU\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E安全问题\u003C\u002Fh3\u003E\u003Cp data-pid=\"qpYQAHNn\"\u003E前面也看到了很多关于大模型应用的安全问题，包括 prompt 注入，“越狱”让模型做一些原本不应该做的事情，连接上工具之后影响与操控真实世界。这一节也举了非常多的例子。\u003C\u002Fp\u003E\u003Cp data-pid=\"kaLqugaj\"\u003E具体怎么做呢？这个应该也是各人都有不同的看法。或许 OpenAI 的逐渐发布更强大的模型让大家适应，同时密切关注安全，价值观对其等技术手段，并持续监控模型失控的信号算是目前看起来比较合理的方案。\u003C\u002Fp\u003E\u003Cp data-pid=\"OJiKgASG\"\u003E最后一页 PPT 也是非常幽默，作为整个系列讲座的结尾送给大家。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8ef97853d02ea3050cc568d11f6aea8e_b.jpg\" data-size=\"normal\" data-rawwidth=\"2372\" data-rawheight=\"1202\" class=\"origin_image zh-lightbox-thumb\" width=\"2372\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8ef97853d02ea3050cc568d11f6aea8e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2372&#39; height=&#39;1202&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2372\" data-rawheight=\"1202\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2372\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8ef97853d02ea3050cc568d11f6aea8e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8ef97853d02ea3050cc568d11f6aea8e_b.jpg\" data-original-token=\"v2-75e8ff5bc65a46ff5aeeb004c9e6f55e\"\u002F\u003E\u003Cfigcaption\u003E想起 Dr. Strangelove\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F26797383","type":"topic","id":"26797383","name":"LLM（大型语言模型）"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F27428077","type":"topic","id":"27428077","name":"Prompt工程"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20024008","type":"topic","id":"20024008","name":"UI\u002FUX"}],"voteupCount":460,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"},"commentCount":3,"contributions":[{"id":45255595,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":1,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":1629,"isNormal":true,"status":0,"activityToppingInfo":{"state":"untopped"},"shareText":"[必读] LLM 应用开发全栈指南 - 来自知乎专栏「RandomGenerator」，作者: 字节 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F629589593 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":156,"hasColumn":true,"republishers":[],"isNewLinkCard":true,"emojiReaction":{"cryFaceCount":0,"cryFaceHasSet":false,"hugCount":0,"hugHasSet":false,"likeCount":156,"likeHasSet":false,"onlookerCount":0,"onlookerHasSet":false},"abParam":{"qaHiddenVoteup":"1","rsInterest1":"1"},"attachedInfo":"kgIkCgkyMjgwNDAzNDISCTYyOTU4OTU5MxgHIgpJTUFHRV9URVhU","shareGuide":{"hasPositiveBubble":false,"hasTimeBubble":false,"hitShareGuideCluster":false},"settings":{"tableOfContents":{"enabled":true}},"canReference":false,"reactionInstruction":{},"entityWords":[{"name":"倒排索引","mention":"倒排索引","matchorder":1,"begin":16608,"end":16612,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJZCgzlgJLmjpLntKLlvJUSB1Vua25vd24Y4IEBIOSBASgBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"家族谱系","mention":"家族谱系","matchorder":1,"begin":7081,"end":7085,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzlrrbml4\u002FosLHns7sSB1Vua25vd24YqTcgrTcoATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"许可协议","mention":"许可协议","matchorder":1,"begin":29488,"end":29492,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJZCgzorrjlj6\u002FljY\u002Forq4SB1Vua25vd24YsOYBILTmASgBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"阿拉丁神灯","mention":"阿拉丁神灯","matchorder":1,"begin":9248,"end":9253,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJaCg\u002FpmL\u002Fmi4nkuIHnpZ7nga8SB1Vua25vd24YoEggpUgoATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"代码生成","mention":"代码生成","matchorder":1,"begin":27473,"end":27477,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJZCgzku6PnoIHnlJ\u002FmiJASB1Vua25vd24Y0dYBINXWASgBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"反向传播算法","mention":"反向传播算法","matchorder":1,"begin":3110,"end":3116,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJdChLlj43lkJHkvKDmkq3nrpfms5USB1Vua25vd24YphggrBgoATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"算法工程师","mention":"算法工程师","matchorder":1,"begin":24327,"end":24332,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJcCg\u002Fnrpfms5Xlt6XnqIvluIgSB1Vua25vd24Yh74BIIy+ASgBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"语义搜索","mention":"语义搜索","matchorder":1,"begin":16654,"end":16658,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJZCgzor63kuYnmkJzntKISB1Vua25vd24YjoIBIJKCASgBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"云服务","mention":"云服务","matchorder":1,"begin":1784,"end":1787,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJUCgnkupHmnI3liqESB1Vua25vd24Y+A0g+w0oATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"平行宇宙","mention":"平行宇宙","matchorder":1,"begin":9116,"end":9120,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzlubPooYzlroflrpkSB1Vua25vd24YnEcgoEcoATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"无损压缩","mention":"无损压缩","matchorder":1,"begin":5806,"end":5810,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzml6DmjZ\u002FljovnvKkSB1Vua25vd24Yri0gsi0oATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"用户留存率","mention":"用户留存率","matchorder":1,"begin":28154,"end":28159,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJcCg\u002FnlKjmiLfnlZnlrZjnjocSB1Vua25vd24Y+tsBIP\u002FbASgBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"并行计算","mention":"并行计算","matchorder":1,"begin":3180,"end":3184,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzlubbooYzorqHnrpcSB1Vua25vd24Y7Bgg8BgoATUAAAAAOgdhcnRpY2xlQABIAFIkNWJkNmE1YzUtNWI3NS00MTJkLWEzMTMtM2VjNTIzMjg5MjQ4","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"机器码","mention":"机器码","matchorder":1,"begin":37834,"end":37837,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJWCgnmnLrlmajnoIESB1Vua25vd24YyqcCIM2nAigBNQAAAAA6B2FydGljbGVAAEgAUiQ1YmQ2YTVjNS01Yjc1LTQxMmQtYTMxMy0zZWM1MjMyODkyNDg=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""}]}},"columns":{"zijie0":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"zvideos":{},"zvideoContributions":{},"briefs":{},"eduCourses":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"ab":{"config":{"params":[{"id":"ques_follow_con","type":"Int","value":"0","chainId":"_gene_","layerId":"ques_follow_con","key":3320}],"experiments":[],"chains":[],"encodedParams":"Cgo7ArcDiwUnB\u002FgMEgUAAAAAAA=="},"triggers":{}},"abV2":{"config":{"paramMap":{"ws_platform_new":{"value":"0"},"pm_new_task":{"value":"0"},"in_editor_title":{"value":"0"}},"abMap":{}},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":true,"Android":false,"iOS":true,"isAppleDevice":true,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (iPhone; CPU iPhone OS 16_4 like Mac OS X) AppleWebKit\u002F605.1.15 (KHTML, like Gecko) Mobile\u002F15E148"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F629589593","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F629589593","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"oppoSearch":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false,"huaweiSearch":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"","xUDId":"AFBXnGGr8BaPTq1NbGXn_ppp0RPq8BY0Jxo=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"武汉","countryName":"中国","regionName":"湖北","countryCode":"CN"},"logged":false,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0}},"recommend":{"recommendTimes":{}}},"explore":{},"levelUpperLimit":10,"mcn":{},"mcnManage":{},"tasks":{},"announcement":{},"creatorsRecommendInfo":{}},"creators":{"common":{"applyStatus":{},"rightsStatus":{}},"bayesDomains":{"status":{},"options":{"topDomains":null,"allDomains":null,"editable":0},"contents":null},"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"faq":{"tabs":[],"article":{}},"knowledgeIncome":{},"safeguardRights":{},"analytics":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"account":{"growthLevel":{}},"KMResource":{},"training":{},"ToolsQuestion":{"goodatTopics":[]},"ToolsHotspot":{"domains":[]},"ToolsRecommend":{},"ToolsCustomPromotion":{"itemLists":{},"baseInfo":{}},"ToolsSearchQuestion":{},"editorSetting":{},"MCNManage":{},"knowledgeTasks":{},"incomeAnalysis":{"income":{"aggregation":{}}},"creationManage":{"editModal":{"status":false}},"activity":{},"announcement":{},"home":{"currentCreatorUrlToken":null,"rights":[],"newRights":[],"scoreInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"bannerList":[],"recentlyCreated":[]},"videoSupport":{"textBenefit":{}},"videoDistribution":{}},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"concernedUpvoters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"zijie0",null]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false},"linkCardLimit":0},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]},"adPromotion":{"answer":{},"article":{}}},"fetchHost":"www.zhihu.com","subAppName":"column","spanName":"Post","canaryConfig":{"test_canary":"0","use_new_player":"1","player_vendor":"1","use_hevc":"1","upload_use_signature":"1","use_backdrop_blur":"1","article_title_imagex":"0","play_station":"1"}}</script><script crossorigin="" src="https://static.zhihu.com/heifetz/vendor.5f3e51e68d56265eb628.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react@17.0.2/umd/react.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom-server.browser.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/runtime.app.560046624f28621b8b9f.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-29107295.app.a7b6d98ed785438234bf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-79b5cf47.app.f16b5bf4c3cff85007a0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-330004dc.app.1a4905d34b3df3f09dff.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-0e5ce61e.app.121a4e979ab55ff600b2.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-83b0f42f.app.6f9779781d0af52a0ddf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-2ec050f6.app.c4cf2528b321f02e9fa0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/680.app.f3c9d9e614b550bbff65.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.app.b9bcd5e5f805cd0c6068.js"></script><script defer="" src="https://static.zhihu.com/event/wza/4613/aria.js?appid=c5ddb58ead4528987249d96fb27246ab" id="ariascripts" wapforceoldfixed="false" loaddata="false" callbackexit="RQ_HALW_QDPH" callback="RQ_VWDUW_QDPH"></script><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script crossorigin="" src="https://unpkg.zhimg.com/za-js-sdk@4.13.0/dist/zap.js"></script><div><div style="display: none;"><i>想来知乎工作？请发送邮件到 jobs@zhihu.com</i></div></div><script src="https://zz.bdstatic.com/linksubmit/push.js"></script><script crossorigin="" src="https://unpkg.zhimg.com/@cfe/emoticon@1.2.4/lib/emoticon.js"></script></body></html>