<html lang="zh" data-ios="true" class="itcauecng" data-theme="light" data-rh="data-theme"><head><meta charset="utf-8"><title>LLM 全栈开发指南补遗 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0,viewport-fit=cover"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=10,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-rh="true" name="keywords" content="LLM（大型语言模型）,Prompt工程,信息检索"><meta data-rh="true" name="description" content="在上一篇 LLM 应用开发全栈指南 中，我们介绍了 FSDL 的新课程 LLM Bootcamp 中的内容。本周他们又把几个 guest talk 的录像放了出来，看了下也挺有收获，在这里做个补遗。How to train your own LLM首先是来自 Re…"><meta data-rh="true" property="og:title" content="LLM 全栈开发指南补遗"><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/633033220"><meta data-rh="true" property="og:description" content="在上一篇 LLM 应用开发全栈指南 中，我们介绍了 FSDL 的新课程 LLM Bootcamp 中的内容。本周他们又把几个 guest talk 的录像放了出来，看了下也挺有收获，在这里做个补遗。How to train your own LLM首先是来自 Re…"><meta data-rh="true" property="og:image" content="https://picx.zhimg.com/v2-201fcd10c63fa9554176cc522a9f01f5_720w.jpg?source=172ae18b"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="og:site_name" content="知乎专栏"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png" sizes="152x152"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.d5793cac.png" sizes="120x120"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7abf3393.png" sizes="76x76"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.362a8eac.png" sizes="60x60"><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"><link rel="dns-prefetch" href="//static.zhimg.com"><link rel="dns-prefetch" href="//pica.zhimg.com"><link rel="dns-prefetch" href="//picx.zhimg.com"><link rel="dns-prefetch" href="//pic1.zhimg.com"><link rel="dns-prefetch" href="//pic2.zhimg.com"><link rel="dns-prefetch" href="//pic3.zhimg.com"><link rel="dns-prefetch" href="//pic4.zhimg.com"><link rel="dns-prefetch" href="//static.zhihu.com"><script nonce="12e21593-fd53-4570-b299-45d98b455765" data-web-reporter-config="{&quot;platform&quot;:&quot;web&quot;,&quot;project&quot;:&quot;heifetz&quot;}">!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports):"function"==typeof define&&define.amd?define(["exports"],t):t((e=e||self).webReporter={})}(this,function(e){"use strict";var t={},n=!1,o=function(){var e,o,r,a,i;return n||(e=document.querySelector("script[data-web-reporter-config]"),o=e&&e.dataset.webReporterConfig||"{}",r=JSON.parse(o),a=r.platform,i=r.project,t={platform:a,project:i},n=!0),t};function r(e){return a(function(){return localStorage.getItem(e)})()}function a(e){return function(){try{return e.apply(void 0,arguments)}catch(e){}}}var i=a(function(e,t){var n={platform:"web",project:o().project,clientTimestamp:+new Date};!function(e,t,n){"1"===r("weber:logenabled")&&console.log("[web-reporter]%o",{type:e,base:t,data:n})}(e,n,t),function(e,t){var n=btoa(JSON.stringify(t));if("undefined"!=typeof Blob&&window.navigator&&window.navigator.sendBeacon){var o=new Blob([n],{type:"text/plain"});navigator.sendBeacon(e,o)}else{var r=new XMLHttpRequest;r.open("POST",e),r.withCredentials=!1,r.setRequestHeader("Content-Type","text/plain;charset=UTF-8"),r.send(n)}}(r("weber:api")||"https://apm.zhihu.com/collector/web_json",{type:e,base:n,data:t})});e.report=i,Object.defineProperty(e,"__esModule",{value:!0})});
</script><link href="https://static.zhihu.com/heifetz/680.216a26f4.bc3dd4670546193a4781.css" crossorigin="" rel="stylesheet"><link href="https://static.zhihu.com/heifetz/column.216a26f4.3326da597f7431c1ea67.css" crossorigin="" rel="stylesheet"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/GoodsRecommendGoodsCardList.216a26f4.d95ce79191cdf8d7ac28.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/3280.216a26f4.8bfc371d6d7cfdc6aeec.css" crossorigin="anonymous"><script nonce="12e21593-fd53-4570-b299-45d98b455765">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"824-bcf32e16\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script><script crossorigin="anonymous" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;824-bcf32e16&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrorsPreset&quot;:&quot;ReactApp&quot;,&quot;tags&quot;:{&quot;app_name&quot;:&quot;heifetz&quot;}}" src="https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js"></script><style data-emotion-css="uzm3ri">.css-uzm3ri{position:fixed;top:0;right:0;left:0;z-index:101;display:none;height:2px;pointer-events:none;background:#056DE8;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}</style><style data-emotion-css="15ro776">.css-15ro776{margin-right:4px;}</style><style data-emotion-css="183aq3r">.css-183aq3r{border-radius:24px;padding:0 15px;font-size:13px;line-height:28px;-webkit-flex:none;-ms-flex:none;flex:none;}</style><style data-emotion-css="1ie3c6f">.css-1ie3c6f{fill:#999999;margin:0 10px;}</style><style data-emotion-css="78p1r9">.css-78p1r9{box-sizing:border-box;margin:0;min-width:0;margin-left:auto;margin-right:auto;max-width:690px;margin-top:0;}@media screen and (min-width:40em){.css-78p1r9{margin-top:1em;}}</style><style data-emotion-css="1rxlkd7">.css-1rxlkd7{position:relative;padding-bottom:57%;height:0;border-radius:inherit;}</style><style data-emotion-css="1nnyq1f">.css-1nnyq1f{box-sizing:border-box;margin:0;min-width:0;position:relative;padding-bottom:57%;height:0;border-radius:inherit;}</style><style data-emotion-css="1ld0bim">.css-1ld0bim{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;}</style><style data-emotion-css="1ujtx97">.css-1ujtx97{object-fit:cover;background-color:#F6F6F6;}</style><style data-emotion-css="uodor8">.css-uodor8{border-radius:50%;}</style><style data-emotion-css="kl6aur">.css-kl6aur{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:34px;height:34px;border-radius:50%;}</style><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1yuhvjn">.css-1yuhvjn{margin-top:16px;}</style><style data-emotion-css="376mun">.css-376mun{position:relative;display:inline;}</style><style data-emotion-css="1hhle02">.css-1hhle02 .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1hhle02 .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1hhle02 .FileLinkCard-info{margin-left:12px;}.css-1hhle02 .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1hhle02 .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1hhle02 .FileLinkCard-source{white-space:pre;}.css-1hhle02 img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1r0wf39">.css-1r0wf39 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1r0wf39 .LinkCard.new,.css-1r0wf39 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1r0wf39 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1r0wf39 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1r0wf39 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1r0wf39 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1r0wf39 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1r0wf39 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1r0wf39 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1r0wf39 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1r0wf39 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1r0wf39 .LinkCard.old,.css-1r0wf39 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="3np2dk">.css-3np2dk .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-3np2dk .LinkCard.old,.css-3np2dk .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-3np2dk .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-3np2dk .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-3np2dk .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-3np2dk .LinkCard.new,.css-3np2dk .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-3np2dk .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-3np2dk .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-3np2dk .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-3np2dk .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-3np2dk .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-3np2dk .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-3np2dk .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-3np2dk .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-3np2dk .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-3np2dk .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-3np2dk .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-3np2dk .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-3np2dk .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-3np2dk .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-3np2dk .FileLinkCard-info{margin-left:12px;}.css-3np2dk .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-3np2dk .FileLinkCard-source{white-space:pre;}.css-3np2dk img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1t538q animation-1yvu044">.css-1t538q{word-break:break-word;line-height:1.6;}.css-1t538q > [data-first-child]{margin-top:0;}.css-1t538q > :last-child{margin-bottom:0;}.css-1t538q h1,.css-1t538q h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:500;}.css-1t538q h3,.css-1t538q h4,.css-1t538q h5,.css-1t538q h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:500;}.css-1t538q u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #444444;}.css-1t538q b{font-weight:500;}.css-1t538q sup{font-size:0.8em;}.css-1t538q sup[data-draft-type='reference']{color:#175199;}.css-1t538q a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-1t538q a:focus{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(5,109,232,0.3);}.css-1t538q a.ztext-link,.css-1t538q a.internal,.css-1t538q a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #808080;}.css-1t538q a.ztext-link:hover,.css-1t538q a.internal:hover,.css-1t538q a.external:hover{color:#175199;border-bottom:1px solid #175199;}.css-1t538q a.ztext-link > .ellipsis::after,.css-1t538q a.internal > .ellipsis::after,.css-1t538q a.external > .ellipsis::after{content:'...';}.css-1t538q a.ztext-link > .invisible,.css-1t538q a.internal > .invisible,.css-1t538q a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-1t538q a.ztext-link u,.css-1t538q a.internal u,.css-1t538q a.external u{border:none;}.css-1t538q a.member_mention{color:#175199;}.css-1t538q a.member_mention:hover{border-bottom:1px solid #175199;}.css-1t538q a.UserLink-link{color:#175199;}.css-1t538q a.UserLink-link:hover{border-bottom:1px solid #175199;}.css-1t538q p{margin:1.4em 0;}.css-1t538q p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-1t538q p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-1t538q hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #D3D3D3;}.css-1t538q img[eeimg]{max-width:100%;vertical-align:middle;}.css-1t538q img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-1t538q img[eeimg="2"]{margin:1.4em auto;display:block;}.css-1t538q blockquote{margin:1.4em 0;padding-left:1em;color:#646464;border-left:3px solid #D3D3D3;}.css-1t538q ol,.css-1t538q ul{margin:1.4em 0;padding:0;width:100%;}.css-1t538q ol ol,.css-1t538q ul ol,.css-1t538q ol ul,.css-1t538q ul ul{margin:0;}.css-1t538q ol li::before,.css-1t538q ul li::before{width:1em;}.css-1t538q ol > ol,.css-1t538q ul > ol,.css-1t538q ol > ul,.css-1t538q ul > ul{display:table-row;}.css-1t538q ol > ol::before,.css-1t538q ul > ol::before,.css-1t538q ol > ul::before,.css-1t538q ul > ul::before{display:table-cell;content:'';}.css-1t538q ul{display:table;}.css-1t538q ul>li{display:table-row;list-style:none;}.css-1t538q ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-1t538q ol{display:table;counter-reset:ol;}.css-1t538q ol > li{display:table-row;list-style:none;}.css-1t538q ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-1t538q ol ol{counter-reset:ol2;}.css-1t538q ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-1t538q ol ol ol{counter-reset:ol3;}.css-1t538q ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-1t538q ol ol ol ol{counter-reset:ol4;}.css-1t538q ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-1t538q figure{margin:1.4em 0;}.css-1t538q figure .content_image,.css-1t538q figure .origin_image{margin:0 auto;}.css-1t538q figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#999999;}.css-1t538q figure + figure{margin-top:calc(1.4em * 1.6);}.css-1t538q figure[data-size='small'],.css-1t538q figure:not([data-size]) > [data-size='small']{clear:both;}.css-1t538q figure[data-size='left'],.css-1t538q figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-1t538q figure[data-size='right'],.css-1t538q figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-1t538q figure[data-size='collapse']{margin-bottom:0;}.css-1t538q figure[data-size='collapse'] + figure{margin-top:0;}.css-1t538q .content_image,.css-1t538q .origin_image{display:block;max-width:100%;height:auto;margin:1.4em auto;}.css-1t538q .content_image[data-size='small'],.css-1t538q .origin_image[data-size='small']{max-width:40%;}.css-1t538q .content_image.zh-lightbox-thumb,.css-1t538q .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-1t538q code{margin:0 2px;padding:3px 4px;border-radius:3px;font-family:Menlo,Monaco,Consolas,'Andale Mono','lucida console','Courier New',monospace;font-size:0.9em;background-color:#F6F6F6;}.css-1t538q pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#F6F6F6;border-radius:4px;}.css-1t538q pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-1t538q li pre{white-space:pre-wrap;}.css-1t538q table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-1t538q table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-1t538q table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#F6F6F6;}.css-1t538q table[data-draft-type='table'] td,.css-1t538q table[data-draft-type='table'] th{border:1px solid #D3D3D3;line-height:24px;height:24px;padding:3px 12px;}.css-1t538q table[data-draft-type='table'] th{background:#EBEBEB;color:#121212;font-weight:500;}.css-1t538q .video-box,.css-1t538q .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #EBEBEB;border-radius:4px;}.css-1t538q .lazy[data-lazy-status]{background-color:#F6F6F6;}.css-1t538q .lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1yvu044 0.5s ease-in;animation:animation-1yvu044 0.5s ease-in;}.css-1t538q .highlight{margin:1em 0;}.css-1t538q .highlight pre{margin:0;}.css-1t538q .highlight .hll{background-color:#FDFDFD;}.css-1t538q .highlight .c{font-style:italic;color:#999999;}.css-1t538q .highlight .err{color:#F1403C;}.css-1t538q .highlight .k{font-weight:500;}.css-1t538q .highlight .o{font-weight:500;}.css-1t538q .highlight .cm{font-style:italic;color:#999999;}.css-1t538q .highlight .cp{font-weight:500;color:#999999;}.css-1t538q .highlight .c1{font-style:italic;color:#999999;}.css-1t538q .highlight .cs{font-style:italic;font-weight:500;color:#999999;}.css-1t538q .highlight .gd{color:#FF3366;}.css-1t538q .highlight .ge{font-style:italic;}.css-1t538q .highlight .gr{color:#F1403C;}.css-1t538q .highlight .gh{color:#999999;}.css-1t538q .highlight .gi{color:#12b370;}.css-1t538q .highlight .go{color:#808080;}.css-1t538q .highlight .gp{color:#646464;}.css-1t538q .highlight .gs{font-weight:500;}.css-1t538q .highlight .gu{color:#999999;}.css-1t538q .highlight .gt{color:#F1403C;}.css-1t538q .highlight .kc{font-weight:500;}.css-1t538q .highlight .kd{font-weight:500;}.css-1t538q .highlight .kn{font-weight:500;}.css-1t538q .highlight .kp{font-weight:500;}.css-1t538q .highlight .kr{font-weight:500;}.css-1t538q .highlight .kt{font-weight:500;color:#175199;}.css-1t538q .highlight .m{color:#056DE8;}.css-1t538q .highlight .s{color:#F1403C;}.css-1t538q .highlight .na{color:#056DE8;}.css-1t538q .highlight .nb{color:#056DE8;}.css-1t538q .highlight .nc{font-weight:500;color:#175199;}.css-1t538q .highlight .no{color:#056DE8;}.css-1t538q .highlight .ni{color:#5555DD;}.css-1t538q .highlight .ne{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nf{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nn{color:#646464;}.css-1t538q .highlight .nt{color:#175199;}.css-1t538q .highlight .nv{color:#056DE8;}.css-1t538q .highlight .ow{font-weight:500;}.css-1t538q .highlight .w{color:#BFBFBF;}.css-1t538q .highlight .mf{color:#056DE8;}.css-1t538q .highlight .mh{color:#056DE8;}.css-1t538q .highlight .mi{color:#056DE8;}.css-1t538q .highlight .mo{color:#056DE8;}.css-1t538q .highlight .sb{color:#F1403C;}.css-1t538q .highlight .sc{color:#F1403C;}.css-1t538q .highlight .sd{color:#F1403C;}.css-1t538q .highlight .s2{color:#F1403C;}.css-1t538q .highlight .se{color:#F1403C;}.css-1t538q .highlight .sh{color:#F1403C;}.css-1t538q .highlight .si{color:#F1403C;}.css-1t538q .highlight .sx{color:#F1403C;}.css-1t538q .highlight .sr{color:#A5542F;}.css-1t538q .highlight .s1{color:#F1403C;}.css-1t538q .highlight .ss{color:#F1403C;}.css-1t538q .highlight .bp{color:#999999;}.css-1t538q .highlight .vc{color:#056DE8;}.css-1t538q .highlight .vg{color:#056DE8;}.css-1t538q .highlight .vi{color:#056DE8;}.css-1t538q .highlight .il{color:#056DE8;}.css-1t538q .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(18,18,18,0.5);border-radius:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(18,18,18,0.6);}.css-1t538q .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1t538q .LinkCard.old,.css-1t538q .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1t538q .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1t538q .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-1t538q .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1t538q .LinkCard.new,.css-1t538q .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1t538q .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1t538q .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1t538q .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1t538q .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1t538q .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1t538q .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1t538q .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1t538q .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1t538q .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1t538q .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1t538q .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1t538q .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1t538q .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1t538q .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1t538q .FileLinkCard-info{margin-left:12px;}.css-1t538q .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1t538q .FileLinkCard-source{white-space:pre;}.css-1t538q img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}@-webkit-keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}@keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}</style><style data-emotion-css="1k6fd7f">.css-1k6fd7f{margin:0;padding-top:15px;}</style><style data-emotion-css="1any501">.css-1any501{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:40px;height:40px;border-radius:50%;}</style><style data-emotion="css"></style></head><body class="WhiteBg-body PostIndex-body Body--Mobile Body--iOS Body--isAppleDevice" aria-basefontsize="16" data-rh="class"><a id="ariaTipText" role="pagedescription" aria-label="链接，无障碍模式读屏软件服务通道。" aria-atomic="true" href="javascript:void(0)" class="skipAutoFix" onclick="aria.wzaStart();" style="width: 1px; height: 1px;"><img src="" style="width:1px !important;height:1px !important;position:absolute;top:0;"></a><div id="root"><div class="App"><div class="LoadingBar  css-uzm3ri"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content Post-content-mobile" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;字节&quot;,&quot;itemId&quot;:633033220,&quot;title&quot;:&quot;LLM 全栈开发指南补遗&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;633033220&quot;}}}"><div><header class="Sticky MobileAppHeader" style="line-height:50px"><div class="MobileAppHeader-inner"><a class="MobileAppHeader-logo" href="//www.zhihu.com?utm_source=zhihu&amp;utm_campaign=guest_feed&amp;utm_content=guide&amp;utm_medium=zhuanlan&amp;utm_id=0" aria-label="知乎"><svg viewBox="0 0 64 30" fill="#056DE8" width="52" height="24.375"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><div class="MobileAppHeader-actions"><label class="MobileAppHeader-searchBox MobileAppHeader-searchBoxWithUnlogin Input-wrapper"><svg width="16" height="16" viewBox="0 0 24 24" fill="#999" class="ZDI ZDI--Search24 css-15ro776"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M11.5 18.389c3.875 0 7-3.118 7-6.945 0-3.826-3.125-6.944-7-6.944s-7 3.118-7 6.944 3.125 6.945 7 6.945Zm0 1.5c4.694 0 8.5-3.78 8.5-8.445C20 6.781 16.194 3 11.5 3S3 6.78 3 11.444c0 4.664 3.806 8.445 8.5 8.445Z"></path><path d="M16.47 16.97a.75.75 0 0 1 1.06 0l3.5 3.5a.75.75 0 1 1-1.06 1.06l-3.5-3.5a.75.75 0 0 1 0-1.06Z"></path></g></svg><input type="search" value="" class="Input" placeholder="搜索"></label><a class="MobileAppHeader-authLink" href="https://www.zhihu.com/signin?next=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F633033220" data-za-detail-view-name="注册或登录"><svg width="24" height="24" viewBox="0 0 24 24" style="vertical-align:middle;margin-bottom:1px" class="ZDI ZDI--User24" fill="currentColor"><path fill-rule="evenodd" d="M7.25 8A4.75 4.75 0 0 1 12 3.25 4.75 4.75 0 0 1 16.75 8 4.75 4.75 0 0 1 12 12.75 4.75 4.75 0 0 1 7.25 8ZM12 1.75A6.25 6.25 0 0 0 5.75 8a6.248 6.248 0 0 0 3.275 5.498c-2.993 1.03-5.222 3.572-5.521 6.681a.75.75 0 1 0 1.493.144c.31-3.209 3.277-5.819 7.006-5.819.025 0 .05-.001.075-.004 3.692.036 6.622 2.634 6.93 5.823a.75.75 0 1 0 1.492-.144c-.3-3.11-2.527-5.652-5.52-6.684A6.248 6.248 0 0 0 18.25 8 6.25 6.25 0 0 0 12 1.75Z" clip-rule="evenodd"></path></svg></a><button type="button" class="Button css-183aq3r Button--blue">打开App</button><svg width="22" height="22" viewBox="0 0 24 24" class="ZDI ZDI--Dots24 css-1ie3c6f" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></div></div><div></div></header></div><div class="css-78p1r9"><div class="css-1nnyq1f"><div class="css-1ld0bim"><img src="https://picx.zhimg.com/v2-201fcd10c63fa9554176cc522a9f01f5_720w.jpg?source=172ae18b" alt="LLM 全栈开发指南补遗" width="100%" height="100%" class="css-1phd9a0" srcset="https://picx.zhimg.com/v2-201fcd10c63fa9554176cc522a9f01f5_200x0.jpg?source=172ae18b 200w,https://picx.zhimg.com/v2-201fcd10c63fa9554176cc522a9f01f5_qhd.jpg?source=172ae18b 480w,https://picx.zhimg.com/v2-201fcd10c63fa9554176cc522a9f01f5_720w.jpg?source=172ae18b 720w,https://picx.zhimg.com/v2-201fcd10c63fa9554176cc522a9f01f5_1440w.jpg?source=172ae18b 1440w" loading="lazy"></div></div></div><article class="Post-Main Post-Main-Mobile" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">LLM 全栈开发指南补遗</h1></header><div class="Post-TimeExtra">17 天前<!-- --> · 来自专栏 <!-- -->RandomGenerator</div><div class="Post-Author Post-Author-Mobile"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><div class="AuthorInfo"><meta itemprop="name" content="字节"><meta itemprop="image" content="https://pic1.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/zijie0"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar AuthorInfo-avatar css-kl6aur" src="https://pic1.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b" srcset="https://pic1.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b 2x" alt="字节"></a></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">字节</a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText css-0">天地大观，志存高远</div></div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path fill-rule="evenodd" d="M13.25 3.25a1.25 1.25 0 1 0-2.5 0v7.5h-7.5a1.25 1.25 0 1 0 0 2.5h7.5v7.5a1.25 1.25 0 1 0 2.5 0v-7.5h7.5a1.25 1.25 0 0 0 0-2.5h-7.5v-7.5Z" clip-rule="evenodd"></path></svg></span>关注</button></div><div class="Post-RichTextContainer"><div class="css-1yuhvjn"><div class="css-376mun"><div class="RichText ztext Post-RichText css-1t538q" options="[object Object]"><p data-first-child="" data-pid="aw1KBN0Y">在上一篇 <a href="https://zhuanlan.zhihu.com/p/629589593" class="internal" data-za-detail-view-id="1043">LLM 应用开发全栈指南</a> 中，我们介绍了 FSDL 的新课程 LLM Bootcamp 中的内容。本周他们又把几个 guest talk 的录像放了出来，看了下也挺有收获，在这里做个补遗。</p><h2>How to train your own LLM</h2><p data-pid="OblrNWpl">首先是来自 Replit 的 Shabani 介绍他们自己训练一个代码生成的大语言模型的经验，非常有信息量，可以结合 WandB 的 <a href="https://link.zhihu.com/?target=https%3A//wandb.ai/site/llm-whitepaper" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">How to Train LLMs from Scratch</a> 来一起看。</p><h3>技术栈</h3><p data-pid="g3tLwKgj">Replit 用到的训练技术栈主要包括：</p><ul><li data-pid="D3i-Luoc">Databricks，用于做各种数据处理与分析，也是整个 stack 中最复杂最重要的一部分。</li><li data-pid="Tu3k7bXz">HuggingFace，用于获取数据集，模型，tokenizer，inference 工具等。AI 时代的 GitHub，也是人人必备了。</li><li data-pid="-av4wJhz"><a href="https://link.zhihu.com/?target=https%3A//www.mosaicml.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">MosaicML</a>，提供模型训练的基础设施，除了 GPU 这类硬件资源外，也能自动帮你做分布式训练，各种训练加速，并提供训练 LLM 的典型参数配置等，非常容易上手。</li></ul><p data-pid="xsgE8j0p">整体的架构图如下图所示：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-a8177b623b5a5df7531f8b9f76a9f4fe_b.jpg" data-size="normal" data-rawwidth="2100" data-rawheight="1082" class="origin_image zh-lightbox-thumb" width="2100" data-original="https://pic3.zhimg.com/v2-a8177b623b5a5df7531f8b9f76a9f4fe_r.jpg"/&gt;</noscript><div><img src="https://pic3.zhimg.com/80/v2-a8177b623b5a5df7531f8b9f76a9f4fe_1440w.jpg" data-size="normal" data-rawwidth="2100" data-rawheight="1082" class="origin_image zh-lightbox-thumb lazy" width="2100" data-original="https://pic3.zhimg.com/v2-a8177b623b5a5df7531f8b9f76a9f4fe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-a8177b623b5a5df7531f8b9f76a9f4fe_b.jpg" data-original-token="v2-18da7d5f21e5f06fb63cdfa007967752" height="1082" data-lazy-status="ok"></div><figcaption>训练 LLM 架构</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>数据集</h3><p data-pid="pZz8FUKl">他们因为是训练代码生成模型，所以训练数据集主要是跟代码相关的内容，包括 StackOverflow 中的问答，来自 BigCode 的 <a href="https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/bigcode/the-stack-dedup" class=" wrap external" target="_blank" rel="nofollow noreferrer">The-Stack-Dedup</a> 数据集，以及 Replit 自己的一些公开 repo。现在大家应该也都知道了，训练一个高质量大模型的主要秘诀都集中在数据清洗上，从这个分享中也可以学到很多他们的一些具体做法，例如：</p><ul><li data-pid="R5Nu-Ocm">通过一些正则表达式和人工规则判断并移除自动生成的代码。</li><li data-pid="eagO7xLW">将一些敏感信息移除，如邮箱，IP 地址，各种密码密钥等。</li><li data-pid="WlnES0VH">移除没法编译通过的代码，不过只能在部分语言做这个操作（例如 Python 就比较好做一些），而且还挺耗时的。</li><li data-pid="tSZZl5Cc">通过平均行长度，最大行长度，字母和数字类型的字符数占比等指标来进行一些过滤。比如典型的应该过滤掉一些 minified 或者混淆过的代码。</li><li data-pid="VeKHijJi">还可以通过 issue 数，star 数等指标来过滤一些质量不高的 repo。</li></ul><p data-pid="8ZXLoS3k">由于数据量非常大（原始代码数据这块就有 3TB 左右），加上处理和分析工作非常多，所以他们使用了 Databricks 作为框架来处理，有更好的 scalability 和性能，也能引入很多其它数据源，而不仅限于 HuggingFace 上的数据集。</p><h3>Tokenizer</h3><p data-pid="j7TIsZck">因为是代码生成任务，所以通用的 tokenizer 可能表现并不好或者性能不佳。很多在回答问题，日常交流或者写文章时用的 token 可能很少在 coding 中用到，所以他们也是自己根据代码数据使用 <a href="https://link.zhihu.com/?target=https%3A//github.com/google/sentencepiece" class=" wrap external" target="_blank" rel="nofollow noreferrer">SentencePiece</a> 自己训练了一个 BPE tokenizer 词表出来。这个 tokenizer 后续会在训练和 inference 中使用，提升训练推理效率，也能增加模型捕捉到的信息量。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-2108d2f4a5790c5802842051cb90d197_b.jpg" data-size="normal" data-rawwidth="2184" data-rawheight="1156" class="origin_image zh-lightbox-thumb" width="2184" data-original="https://pic4.zhimg.com/v2-2108d2f4a5790c5802842051cb90d197_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2184' height='1156'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2184" data-rawheight="1156" class="origin_image zh-lightbox-thumb lazy" width="2184" data-original="https://pic4.zhimg.com/v2-2108d2f4a5790c5802842051cb90d197_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-2108d2f4a5790c5802842051cb90d197_b.jpg" data-original-token="v2-22e9a47b165a8162cb332fb1778db0f6"></div><figcaption>跟 Codex 默认 tokenizer 比较</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>模型训练</h3><p data-pid="SPcnqw7a">训练部分看起来相对比较简单，一方面可能是用了比较成熟的云服务，另一方面也是模型参数量差不多在 30 亿以内，好像并没有提到训练过程中 babysitting 的问题。简单的 yaml 配置通过 CLI 触发就跑起来了。MosiacML 帮你精心挑选了合适的参数，各种自动重启等，非常省心（虽然我没用过）。作者也表示他们之前都是自己搞，后来切换到 MosiacML 提升了很多效率。</p><p data-pid="8hhm0VDu">同时他们也用了 WandB 来做训练的 logging 和监控，也是非常标准的做法。</p><h3>测试与评估</h3><p data-pid="WS7QB1KI">前面也提到大模型的测试评估是个很困难的事情。因为是代码相关任务，感觉可以评估的手段会更丰富一些。比如可以实际执行代码来查看结果是否正确，或者通过一些代码分析工具来评估生成的代码的质量等。</p><p data-pid="1plj8uP1">他们使用的评估数据集主要是 <a href="https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/openai_humaneval" class=" wrap external" target="_blank" rel="nofollow noreferrer">HumanEval</a>，使用 HuggingFace 的 code inference tool 来快速执行测试。像 Python 这类相对比较好搞定，但对于其它语言和场景，例如一些前端界面的代码就不是很容易做测试验证。</p><p data-pid="rDgpajst">另外也需要注意测试用例最好是模型训练时没有见过的，避免 overfitting/memorization。还有很重要的一点是这些用例要与真实的使用场景尽可能一致，比如是不是跟补全场景是类似的输入和输出形式，测试用例与真实用户的使用场景是否一致等。</p><h3>部署</h3><p data-pid="9-AxReSP">他们使用了 <a href="https://link.zhihu.com/?target=https%3A//github.com/NVIDIA/FasterTransformer" class=" wrap external" target="_blank" rel="nofollow noreferrer">FastTransformer</a> 和 <a href="https://link.zhihu.com/?target=https%3A//github.com/triton-inference-server/server" class=" wrap external" target="_blank" rel="nofollow noreferrer">Triton</a> 来做 inference 的部署，以提供更好的性能和吞吐。例如像 Triton 中支持部署多个模型 instance 的部署和并发执行，能够做请求动态 batching 等，看起来非常的方便。不过之前也听说当前训练框架跟 inference 框架还是有一些“隔阂”，如果在训练中用了一些特殊的操作，可能在 inference 框架中不一定支持，需要格外注意。</p><p data-pid="FPt8yKKD">在 auto-scaling 方面，他们复用了 Replit 现有的 k8s 基础设施。不过还是有很多特殊的挑战，例如模型的规模要大很多，对 GPU 也有特殊的要求，还要处理一些云上的区域出现 GPU“缺货”的问题等。</p><h3>经验教训</h3><p data-pid="mKCDxKYO">最最重要的还是“以数据为中心”，从前面架构图也可以看出，数据 pipeline 这块所占的内容也是最多的，需要有一个稳定的流程来支持快速迭代实验。另外过程中要尽可能深入去了解你的训练数据。看来 80%时间花在数据上仍然是个不变的真理。</p><p data-pid="PbY2S3s5">模型评估也是一个开放性的问题，作者认为目前更多是一门艺术而不是精确的科学。即使有 HumanEval 这样的评测数据集，也只是一种参考，还是需要真正把模型部署到实际使用场景中，让最终用户来测试体验模型的效果、延迟等，并尽可能全面地收集用户反馈、系统监控数据。这一点 GitHub Copilot 的 telemetry 就做得很好，值得参考学习。</p><p data-pid="42_nnPin">协作也是很重要的一点，像之前 OpenAI 也分享过他们的团队设置，不光是个软件系统工程，也是对组织设计的考验。作者举例说一些新的模型训练特性可能在 FastTransformer 中不支持，就会大大提升 inference 的延迟，所以需要各个团队中的同事一起协同来避免此类问题。</p><h3>招聘环节</h3><p data-pid="uO0nQ4DW">最后作者还聊了聊什么才是一个好的 LLM 工程师，感觉也是个各种交叉技能的“稀有物种”。既要懂 research，engineering 的 sense 也不能差；数据探索清洗要深入且有耐心，又擅长各种软件工程的实践……大概意思就是我们这里项目有趣，挑战又大，赶紧来一起做一番大事业吧 :)</p><h2>Agents</h2><p data-pid="2qOlPoQV">LangChain 的创始人 Chase 来聊了聊近期超火的 Agents。这部分提到几个工作正好跟之前我写的 <a href="https://zhuanlan.zhihu.com/p/622947810" class="internal">AutoGPT 与 LLM Agent 解析</a> 这篇文章完全重合，这里就简单介绍一下。</p><h3>概念</h3><p data-pid="gSLvcBFa">Agent 的核心是把 LLM 当作一个“推理引擎”，赋予其各类外部工具以及自身的长期记忆，能够让其自行生成灵活的决策步骤，完成复杂任务。而像 LangChain 里的 Chain 的概念则是由人工来定义一套确定的步骤来让 LLM 执行，更像是把 LLM 当成了一种强大的多任务工具。</p><p data-pid="-z_jxQ3q">典型的 agent 模式如 ReAct 中，一般的逻辑是：</p><ul><li data-pid="Y-gpfGjb">由 LLM 选择工具。</li><li data-pid="P1NLza2I">执行工具后再将输出返回给 LLM。</li><li data-pid="TohNt87D">不断重复上述过程，直到达到停止条件（一般也是 LLM 自己决定或者通过一些规则设定）。</li></ul><h3>挑战</h3><p data-pid="R4B7TtOC">作者列举了当前 agent 的一系列挑战，应该也是深入看过很多 agent 应用得出的结论。</p><p data-pid="EGurvUQ5"><b>如何让 agent 选择合适的工具</b></p><p data-pid="uTWhkuJt">常规的做法是通过指令，工具描述来引导。此外在复杂场景下：</p><ul><li data-pid="uZEVgLTg">当工具多了之后也可以针对工具做 retrieve。</li><li data-pid="a8irxebr">可以 retrieve 相关示例来做 few-shot prompt。</li><li data-pid="_iuORpS3">也可以进一步 fine tune 特定模型，例如之前的 Toolformer。</li></ul><p data-pid="FhczbQQt">近期正好有篇来自伯克利和微软的工作 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2305.15334.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Gorilla</a>，正好是结合了 retrieval，fine tune 等几种方法，在 LLaMA 模型的基础上做到了接近 GPT-4 的效果，值得借鉴。</p><p data-pid="URERbySk"><b>不必要的工具使用</b></p><p data-pid="ja7tIQH3">例如用户只是跟模型闲聊时，可能就没必要都使用工具了。除了在 prompt 里进行说明外，Chase 还给了个很有意思的想法，就是把“Human Input”也写成一种工具，让模型来主动发起对人类的提问。具体可以参考 <a href="https://link.zhihu.com/?target=https%3A//python.langchain.com/en/latest/modules/agents/tools/examples/human_tools.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">LangChain 文档中的例子</a>。</p><p data-pid="YDeJQcI8"><b>Agent 返回的格式不稳定</b></p><p data-pid="LoMvhku8">在程序使用工具时，需要 agent 按照特定格式返回内容，以便提取其中的工具操作信息。但 LLM 的随机性导致这部分可能会出现很多不稳定的情况。这里常见的做法是让 LLM 按照 json 这类常见的 schema 来返回，一般稳定性会高一些（相比“Action:”这种）。此外自动修复重试也很实用，可以利用 LangChain 里的 output parsers 来帮助完成。</p><p data-pid="i7pouPJc"><b>记住之前的操作，避免重复</b></p><p data-pid="c-ZPKHxT">如果没有长期记忆，agent 很容易“忘掉”之前做过的操作，导致不停在原地打转或者效率低下。常见的解决办法还是通过 retrieval 结合近期操作记录来克服，例如 AutoGPT 中就用了类似的手段。</p><p data-pid="HNWc0AMI"><b>处理超长的 observation</b></p><p data-pid="dQE7NJ1r">有些工具生成的 observation 很长，超出了 context length 的限制，这时候就需要用一些工具从中提取有用信息，或者放到外部存储中再借助 retrieval 来使用。</p><p data-pid="bOUu2EvB">这里引出很有趣的一点是我们未来在考虑 API 设计时也需要主动拥抱 LLM 的特性。除了有清晰的接口设计和说明，能让 LLM 更好地生成调用动作外，调用结果是否精简也很重要，可以避免上述 observation 过长的问题。</p><p data-pid="1r3bofoG"><b>专注于目标</b></p><p data-pid="89-KM-fy">像 AutoGPT 这类尝试中往往任务执行链路很长，agent 很容易做着做着就“迷失了目标”。简单的做法是在 prompt 结尾处再把目标加上，引起 agent 的注意。另外像 BabyAGI，HuggingGPT 这种把 planning 和 execution 分开的做法也是很有用。拆分的比较细的任务往往步骤比较短，也不容易丢失目标。</p><p data-pid="kmIU8F3v"><b>结果评估</b></p><p data-pid="lzLOZdB6">评估 agent 也是比较困难的。除了评估最终结果是否正确外，我们还可以做过程的细化评估，例如：</p><ul><li data-pid="wIgxH6ei">选择的中间步骤是否正确。</li><li data-pid="6WcgPG52">生成 action 的 input 是否正确。</li><li data-pid="qyB5H_yh">生成的步骤序列是否合理高效。</li></ul><h3>记忆系统</h3><p data-pid="YO4PFKo-">前面的挑战部分可以看到有很多都是跟 retrieval 相关，而且从 agent 的本质出发，其最大的优势之一也在于能够记住之前的操作，成为一个可以不断自我演进的智能体，或者实现不同用户的个性化应答，而不是固定的逻辑链路。所以 memory 这块的处理显得越来越重要。</p><p data-pid="DhcaG5Le">Agent 的记忆主要是跟用户的交互和跟工具的交互，当然一些项目中也基于这两类基础信息衍生出了很多复杂操作，例如 LangChain 中类似知识图谱的记忆模式；LlamaIndex 中复杂的外部记忆索引设计；Generative Agents 中的“自我反思”环节等等。</p><h3>Agent 项目速评</h3><ul><li data-pid="crNXhljU">AutoGPT：实现的任务比起 ReAct 中的例子来说会更发散更需要探索，因此步骤也更长。所以需要通过外部记忆系统来获取 agent 之前的操作步骤信息等。</li><li data-pid="4Zv3kcAy">BabyAGI：将计划和执行分开，在较长任务执行过程中保持 agent 的目标感。</li><li data-pid="o4oD_70w">Camel：给多个 agent 赋予不同的人格、记忆等，模拟 agent 之间的交互。</li><li data-pid="SfiIwIZM">Generative Agents：更复杂的 memory retrieval 机制。自我反思并更新系统状态。或许未来还可以自己触发 fine tune 更新模型参数？</li></ul><h2>Fireside Chat with OpenAI VP Product</h2><p data-pid="WlNWooXv">跟 Peter Welinder 的一个简短访谈。很多信息可能关注 OpenAI 的同学应该都比较了解了，例如他们早年在强化学习方面的探索，包括打游戏，玩魔方之类，后来大力押注了语言模型方向。从产品角度有几个故事还挺有意思：</p><ul><li data-pid="3XA2TOYa">他们在有了 GPT-3 之后也不知道有什么产品场景可以应用，一般来说拿着技术找场景并不是一个好主意，但对一家以 AGI 为目标的研究型公司来说也可以理解。后来他们干脆就开放 API，看看用户是不是能自己找到一些有趣的应用场景来。</li><li data-pid="K-UZNbN5">在 GPT-3 推出时他们就想过做个 Chatbot 推出来，但鉴于之前微软，谷歌等公司的失败尝试，他们觉得技术还不成熟就没有这么做。</li><li data-pid="axKUipw2">推出 ChatGPT 之前大家也很忐忑，不少人觉得也会跟以往的产品一样被发现一些严重的回复问题导致很快下线。而且他们当时找了 1000 来个用户内测，也没收到特别正面的反馈。但上线之后一方面模型表现的确可以，另外大家可能迅速挖掘出了很多实用场景，导致很快爆火全球。</li><li data-pid="VDiOEIgO">ChatGPT 的成功中是交互方式起到的因素更大还是模型因素更大？其实他们在之前开放 API 时就发现有很多人会在 playground 模拟交互来实现一些场景，聊天这个形式加上免费注册开放大大降低了大家的尝试门槛，所以起到了至关重要的作用。当然 instruct tuning，RLHF 对齐这些也是很重要的保障。</li></ul><h2>近期工作 highlight</h2><p data-pid="3XnIoq9o">最近还有不少激动人心的优秀工作，也一并在这里分享一下。</p><h3>Gorilla</h3><p data-pid="PmPgfgtv">前面讲 agent 的环节已经提到了这个工作，相比之前的 Toolformer，一大进步是 <a href="https://link.zhihu.com/?target=https%3A//github.com/ShishirPatil/gorilla" class=" wrap external" target="_blank" rel="nofollow noreferrer">开源了代码</a>，不过目前（2023.05.28）还没放出比较关键的训练这块的内容。Gorilla 主要实现的是可以通过用户提供的 API 文档，自己 fine tune 出一个模型，然后可以接受用户的任务指令，由这个模型生成一系列 API 调用代码实现任务。看了下论文，具体的做法是：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-5d97c085b3ac31861b11af14a86a0ea4_b.jpg" data-size="normal" data-rawwidth="2198" data-rawheight="1344" class="origin_image zh-lightbox-thumb" width="2198" data-original="https://pic1.zhimg.com/v2-5d97c085b3ac31861b11af14a86a0ea4_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2198' height='1344'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2198" data-rawheight="1344" class="origin_image zh-lightbox-thumb lazy" width="2198" data-original="https://pic1.zhimg.com/v2-5d97c085b3ac31861b11af14a86a0ea4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5d97c085b3ac31861b11af14a86a0ea4_b.jpg" data-original-token="v2-542a1f4c01789b684450f0dc83361e29"></div><figcaption>Gorilla 的 workflow</figcaption></figure><p class="ztext-empty-paragraph"><br></p><ul><li data-pid="y5RrwJiV">通过 API 文档，向 GPT-4 提问，让它针对每个 API 生成若干个任务指令来，而且还要求这些指令里不要显示的提到 API 的名字。这些 self-instruct 生成的指令与 API 调用对就形成了模型 fine tune 的数据集。</li><li data-pid="OKnlkcT_">在 fine tune 过程中，他们也“植入”了 retrieval 的信息，让模型明白后续在使用时可以结合相关文档信息来生成 API 调用的代码。不过他们发现这种增强方式并不一定总是有效，在当前 LlamaIndex 这类 retrieval 表现下很多反而会起到负面作用。</li><li data-pid="hE4wl9Uc">在 inference 时，模型可以按需要启用 retrieval。从文中的结果来看，他们测试的几个库不使用 retrieval 的 zero-shot 效果反而更好。当然 retrieval 在 API 文档持续变化的情况下可能会有优势。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-1fba5b5e0f1c6b2bd370784ac4f4eef1_b.jpg" data-size="normal" data-rawwidth="2672" data-rawheight="1432" class="origin_image zh-lightbox-thumb" width="2672" data-original="https://pic2.zhimg.com/v2-1fba5b5e0f1c6b2bd370784ac4f4eef1_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2672' height='1432'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2672" data-rawheight="1432" class="origin_image zh-lightbox-thumb lazy" width="2672" data-original="https://pic2.zhimg.com/v2-1fba5b5e0f1c6b2bd370784ac4f4eef1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1fba5b5e0f1c6b2bd370784ac4f4eef1_b.jpg" data-original-token="v2-60b3ccd29f8bb8c9ead95bcb18cbd229"></div><figcaption>Zero-shot 的表现更好</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="ISyOKPlF">总体来说还是非常有意思的一个工作，让 LLM 来写代码真的是一个拥有无限想象力的方向。</p><h3>Voyager</h3><p data-pid="pfJX5I8h">又是一篇探索 agent 方向的重磅文章。之前我们就介绍过他们团队推出的 <a href="https://link.zhihu.com/?target=https%3A//minedojo.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">MineDojo</a> 项目，当时还以为下一步应该会搞个多模态大模型出来，或者在 LLM 的基础上去更多使用 RL 方式来训练具有“世界知识”，能够做复杂推理玩游戏的 agent。没想到这次发的文章却是“无梯度更新”的路线，而且效果也是非常惊艳，有些出人意料。</p><p data-pid="mRC9JEIu">这篇工作总体实现的效果是让 GPT 在不需要任何传统 fine tune 更新参数的情况下，通过 in-context learning 的方式逐渐学会各种“技能”，探索 minecraft 这个虚拟世界。这个 agent 的形成玩游戏的动作主要就是“执行代码”，而其自我学习提升过程就是不断地去写代码，执行获取反馈，调试改进，以及 retrieve 之前写的代码。从整体实现效果来看，比之前的各种 agent 方法（ReAct，AutoGPT 等）强多了。更可贵的是项目代码也全公开了，非常值得深入研究学习。</p><p data-pid="Bf4763SZ">整体的项目结构如下：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-1d7c3395c32986b8e64fdbcbccff69fa_b.jpg" data-size="normal" data-rawwidth="2696" data-rawheight="1186" class="origin_image zh-lightbox-thumb" width="2696" data-original="https://pic3.zhimg.com/v2-1d7c3395c32986b8e64fdbcbccff69fa_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2696' height='1186'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2696" data-rawheight="1186" class="origin_image zh-lightbox-thumb lazy" width="2696" data-original="https://pic3.zhimg.com/v2-1d7c3395c32986b8e64fdbcbccff69fa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1d7c3395c32986b8e64fdbcbccff69fa_b.jpg" data-original-token="v2-283650e936522f1a8657270b49393d5f"></div><figcaption>Voyager 的架构</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="YsyIpz_i">几个模块的作用分别是：</p><ul><li data-pid="mIZbM_ki">中间的 iterative prompting 模块中，agent 会根据游戏环境状态，代码执行报错，当前任务等信息，输出模型的 reasoning，计划和具体的代码，并可以不断 refine 优化达到正确的代码。</li><li data-pid="67wxFP-0">执行成功的代码程序，会向量化后存到 skill library 中，后续在写代码过程中可以根据 context 来 retrieve。都会写 library 了有没有，离失业又近了一步。</li><li data-pid="ABpBhMll">最左边的模块也是把当前探索状态发给 agent，并让其以最大化探索空间为目标自己挖掘新的任务目标。我琢磨着让 GPT 做科研是不是也不远了。</li><li data-pid="O1XniXmC">除了全自动化执行，作者们也在 critic 和 curriculum 两个模块引入了可选的人工介入机制，帮助 agent 更好地处理程序错误，以及引导他们一步步做更复杂的任务。Human as a tool 可能也会成为一种流行模式。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-f0b779c2a4baa20156b1515cac3ba263_b.jpg" data-size="normal" data-rawwidth="2676" data-rawheight="1284" class="origin_image zh-lightbox-thumb" width="2676" data-original="https://pic4.zhimg.com/v2-f0b779c2a4baa20156b1515cac3ba263_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2676' height='1284'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2676" data-rawheight="1284" class="origin_image zh-lightbox-thumb lazy" width="2676" data-original="https://pic4.zhimg.com/v2-f0b779c2a4baa20156b1515cac3ba263_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-f0b779c2a4baa20156b1515cac3ba263_b.jpg" data-original-token="v2-484b503a14cb379e17e057ddac6c8ceb"></div><figcaption>Skill library 的实现</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="zDb7oMqs">这几个模块结合起来就达到了上面的效果，看起来都没有用 MineDojo 里收集的额外数据，也不用做任何训练，非常神奇。</p><p data-pid="rVxHlo-i">在 limitation 环节，作者提到了 agent 会出现无法实现正确的代码以及 hallucination 的问题，未来或许能通过 GPT 自身能力的提升或者通过微调开源 LLM 来克服。我的一个感觉是好像整个项目还没有把 minecraft 相关的文档以及其它用户经验分享利用起来，这些知识应该可以减少一些出错和 hallucination 的问题？</p><p data-pid="7aNUyMdQ">还有一个思考是，这类无梯度架构的能力边界会在哪里？有哪些效果是必须通过模型的参数训练更新才能达到的？目前看起来很多 fine tune 提供的优势好像主要是效率角度的提升。例如无梯度架构的模型每次都要从小本本里去翻找相关记忆，但训练过的模型可以直接从参数中找出 context；或者本来要用工具去跑一下代码才知道结果，训练过的模型可以直接给出结果；或者原先的任务做的不熟练，经常做错需要订正，训练过后就能一次做对了。是否有无梯度架构完全做不了的，而一定要用数据训练后才能做到的事情（例如扩展词表）？</p><p data-pid="pf8iXIPz">不过即使从提升效率，增加准确性的角度来看，这两者也是可以考虑结合起来的。比如 Generative Agents 里就有“自我反思”的步骤来沉淀重要的事件信息。我们是不是也可以延展一下，把“自我反思”改成调用自我 fine tune 的工具。其中的训练数据就可以根据上面提到的无梯度架构的局限性角度出发，将出错最多的代码，retrieve 频率最高的信息，调用最频繁的工具及其结果，人工介入最多的 workflow，以及模型自认为最重要的信息等等，都作为训练数据，来训练一个 fine tune 的模型。这样就可以在无梯度架构的基础上，通过 fine tune 来进一步提升 agent 的进化。</p><h3>Tree of Thought</h3><p data-pid="Int9JhcG">ReAct 作者“尧舜禹”大佬的新作，前两天又刷屏了。作者延展了 chain-of-thought 的思路，模拟人类在解决复杂问题时的提出多个可能方向，思考深挖，根据可行性选择路径，碰到问题时回溯到之前其它想法等思维过程，构建起了一棵自主探索生长的“思维树”。在算 24 点等一系列复杂的任务上，tree-of-thought 的表现都大大超过了之前的 chain-of-thought。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-0f2992e642e6433065b8c6263a0a7416_b.jpg" data-size="normal" data-rawwidth="2716" data-rawheight="1322" class="origin_image zh-lightbox-thumb" width="2716" data-original="https://pic3.zhimg.com/v2-0f2992e642e6433065b8c6263a0a7416_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2716' height='1322'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2716" data-rawheight="1322" class="origin_image zh-lightbox-thumb lazy" width="2716" data-original="https://pic3.zhimg.com/v2-0f2992e642e6433065b8c6263a0a7416_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0f2992e642e6433065b8c6263a0a7416_b.jpg" data-original-token="v2-e54cfa1db31cbfc5476b9f5ada42e6eb"></div><figcaption>直观理解 tree-of-thought</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="f3XzuI8x">作者也将代码公开在了 GitHub 上，感兴趣的同学可以深入学习研究。个人看下来感觉目前构建 tree 的 proposal/value prompt 需要针对具体任务来设计，需要比较深入的领域知识。不知是否有可能通过更加自动化的方式，结合 LLM 和相关外部工具来自动生成这些 prompt，那样或许会有更广的应用场景。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-eb1c8a1bb67df930ba5cb459bc29096d_b.jpg" data-size="normal" data-rawwidth="2200" data-rawheight="904" class="origin_image zh-lightbox-thumb" width="2200" data-original="https://pic2.zhimg.com/v2-eb1c8a1bb67df930ba5cb459bc29096d_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2200' height='904'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2200" data-rawheight="904" class="origin_image zh-lightbox-thumb lazy" width="2200" data-original="https://pic2.zhimg.com/v2-eb1c8a1bb67df930ba5cb459bc29096d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-eb1c8a1bb67df930ba5cb459bc29096d_b.jpg" data-original-token="v2-d318fb653d9832812746838b490eb766"></div><figcaption>BFS ToT 的核心逻辑</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="Nj7eXwYq">这个工作的设计思路还是挺有趣的，有种把 LLM 作为 CPU，在上面跑了更高级的树搜索算法的感觉。很多经典算法都是这类对人类系统性思考解决某类问题的高度抽象，或许未来会有更多这个方向上的探索，甚至真的把 <a href="https://link.zhihu.com/?target=https%3A//lmql.ai/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Prompt 设计成一种编程语言</a>。</p><h3>Status of GPT</h3><p data-pid="e9gvOBtc">最后再推荐一下推特第一人工智能网红 Karpathy 在微软 Build 大会上的演讲，如果你没怎么跟进 LLM 方面的进展，那么这个演讲绝对是最好的总结视频之一。表述非常清晰易懂，覆盖了各类主要进展，有细节也有 intuition，真是不可多得的佳作。个人感觉收获比较多的几个点包括：</p><ul><li data-pid="4OChEqma">为什么需要 RLHF，直观来看就是效果更好。一个可能的原因是要生成一个高质量的文本，比判别一下几个文本质量的好坏要难得多。“我虽然不会写，但点评下别人的作品还是容易的” :)</li><li data-pid="U__C9Q1m">模型 fine tune 会损失多样性，这个之前 Karpathy 也在推特上分享过。包括之前的“灾难性遗忘”感觉也没有很好的解决办法。</li><li data-pid="odFoFTxk">人工生成的文本跟 LLM 生成文本的比较非常精彩，一定要看。人类在产出最终文本前其实涉及了很多中间过程，可能包括问题拆解，资料查阅，反思，撰写，润色等等，而模型没有各种内在的心理活动，它的所有思考过程都需要一个一个 token 显示地生成出来。所以上面看到的很多工作也都是利用 prompting 和模型生成的交互来重建人类的 system 2 思考过程。</li><li data-pid="SNvMC-kd">LLM 只想模仿，不想成功。所以提醒一下模型模仿高智商的思考者很重要，让它记得需要完成的任务目标也很重要。举例：Let's work this out in a step by step way to be sure we have the right answer。</li><li data-pid="pu570Kg8">提到了微软的 <a href="https://link.zhihu.com/?target=https%3A//github.com/microsoft/guidance" class=" wrap external" target="_blank" rel="nofollow noreferrer">Guidance</a> 项目，实现了 constrained prompting，让模型能够更稳定地按照特定的格式进行输出。</li><li data-pid="yKnT1KB5">Fine tune 方面提到了各种 <a href="https://link.zhihu.com/?target=https%3A//github.com/huggingface/peft" class=" wrap external" target="_blank" rel="nofollow noreferrer">PEFT 技术</a>，这方面最近最火热的应该是这个 <a href="https://link.zhihu.com/?target=https%3A//github.com/artidoro/qlora" class=" wrap external" target="_blank" rel="nofollow noreferrer">QLoRA</a>，可以在 48GB 显存上 fine tune 一个 65B 的模型，着实惊人。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-8e01570b32feb57039900d3e7f708376_b.jpg" data-size="normal" data-rawwidth="3882" data-rawheight="2018" class="origin_image zh-lightbox-thumb" width="3882" data-original="https://pic3.zhimg.com/v2-8e01570b32feb57039900d3e7f708376_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='3882' height='2018'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="3882" data-rawheight="2018" class="origin_image zh-lightbox-thumb lazy" width="3882" data-original="https://pic3.zhimg.com/v2-8e01570b32feb57039900d3e7f708376_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-8e01570b32feb57039900d3e7f708376_b.jpg" data-original-token="v2-936dd933e1edfeaac8910bcfe1b4a1ae"></div><figcaption>第 23 分钟左右的精华部分</figcaption></figure><p></p></div></div></div></div><div class="Post-ReadMark"></div><div role="button" tabindex="0" class="ContentItem-time">发布于 2023-05-29 14:14<!-- -->・IP 属地日本</div></article><div class="KfeCollection-VipRecommendCard KfeCollection-VipRecommendCard-article Post-VipRecommendCard"><div class="KfeCollection-VipRecommendCard-title">如果你是替身文的替身，你会怎么做？</div><div class="KfeCollection-VipRecommendCard-author"><div class="KfeCollection-VipRecommendCard-author-avatar"><img src="https://pic3.zhimg.com/v2-d469c76e18bf1b073d7e3016e3334ecd.jpg"></div><div class="KfeCollection-VipRecommendCard-author-name">桥上小菩</div><div class="KfeCollection-VipRecommendCard-author-icon"><img src="https://pic1.zhimg.com/50/v2-5b7012c8c22fd520f5677305e1e551bf.webp"></div></div><div class="KfeCollection-VipRecommendCard-content">原来我只是仙界众仙君的白月光替身。但他们只知我可为替身，却不知我亦心狠手辣。1.「长羡，你的心能给莲毓，是你的福气。」  那柄弑仙刀插入我的胸脯时，我终于恍然大悟。眼泪是不知何时落下的，实则我并不想哭，但无奈这弑仙刀实在是痛极了，我很想抬手拔出这把刀，但我知道这只是个妄想罢了——身前，是淡淡垂着眼眸、面无表情的俊秀神君。他墨发高束，眼如横波，唇似樱红，一席如火的红衣，整个人清澈得却像是露珠。干干净净的面容，干干净净的红衣，唯独他的手上，沾染着血迹，那是我的血。地上真的很凉，弑仙刀又往我的心脏处深深入了几分。旁边，站着两位同样丰神如玉的仙君。两位皆是白衣，只不过一位面容清冷，一位面带不忍，两人皆容色出众。那面带不忍的仙君望着我，又看了眼红衣仙君，沉吟着开口道：「东君，还是速战速决罢……」面容清冷的仙君听了这话，微微皱了眉，看着身旁的人说：「宫吟，你心软了。」宫吟仙君无奈地说：「容华，她毕竟也做了三百年我们的小师妹。」「若不是因为莲毓，她也配么。」容华看着我，眼中似乎划过了什么，他冷冷说道。「好不容易遇上这颗与莲毓极配的心脏，自然不能容得一丝马虎。东君，取这心脏时务必小心。」莲毓，莲毓……这个名字其实我并没有听过多少次。但偶尔，我在仙界时也会听见几个仙婢窃窃私语过此仙君的风流韵事。而我曾经无意间闯入的仙境禁地中，无数珍贵的仙灵精华聚着的一片池中，就有一株静静沉睡的月白色莲花。那一次无意的闯入，也使得向来待我极温柔的师尊扶桑神君第一次大发雷霆。是了，早在那时，我就应该意识到，那株与我本体极为相近的莲花，将会在未来再次推我重入深渊。我不是什么天真单纯的仙君，从我有意识起，为了修为、为了强大起来，我就在三界中最危险的深渊之沼摸爬滚打。我杀过妖，我的手上沾染过血，我从来不像那些仙婢口中「温柔端重、钟灵毓秀」的莲毓仙君。但即便如此，当扶桑从天而降，白衣如月华、眉眼胜山河，一念便使想杀了我的大妖灰飞烟灭之时，我的心，竟然从未有过地滚烫起来。他会用神力抚去我的伤口，用那双修长的手拭去我面容上的血污，并用我从未听过的、轻柔好听的声音说：「从此以后，有我护着你，你不必再害怕了。」「往后，你便唤我师尊罢。」这句话，在此后多少次梦回，成为无数个噩梦中让我得以喘息的声音。后来，我成了仙界众人皆羡慕的扶桑神君的小徒弟，成了两个强大的仙君师兄万分包容呵护的长羡仙君。再后来，我下凡时捡到了一个被丢弃的婴儿，我为他取名长生，亲手将他带大。这个少年没有辜负我的期望，在两百多岁时便化成仙君，天生仙骨，气质不凡。却原来，此长生当真能够长生，他并不是什么被丢弃凡间的婴儿，而是自诞生以来便能享神君之位的东君。长羡长羡。我不仅本体与莲毓相似，就连容貌也是七成的相像，或许当初为我取此道名的扶桑神君，就觉得这是我之大幸，可以羡之。所以今日，在莲毓即将化身人形，重回仙位时，为了她的完美无缺，我，这个替身，是时候该牺牲了。我最信任的师尊封了下界之路，我的两位师兄亲自追杀于我，我从小养大的少年亲手用弑仙刀插入我的胸脯。为了莲毓。我的心脏，终于还是慢慢脱离了我的这副躯体。仙是不会死的，只是随着心脏的离去，我的一身仙力、一切感情，都将化为虚无。而这修为与情感，都将提供给莲毓，使刚化形的她修为更加精进，也使她能够在我这些强烈情感的刺激下，回忆过去，想起从前。所以，他们认为我只是没了四百多年的修为、没了正常的情感，却还能活着，这对我而言应该是一个多么大的恩赐。可是在那颗心离开后，我的痛苦并没有减少半分。我辛辛苦苦修炼了四百多年的修为，我游览这世间所有产生的爱恨……凭什么，凭什么为了一个莲毓，为了她再次化形的完美无缺，我就要全部牺牲？所以我用尽了仙力、用尽了我偷偷藏起来的所有杀手锏。我的感情还在。这是我最后剩下的东西。那颗心脏中，除了我四百多年的修为，再无其它。我躺在地上，感受着空空如也的心脏位置，艰难地扯出一抹笑容来。想必，在这些神君、仙君看到那化为人形却并无从前记忆的莲毓时，也能像我现在这般高兴吧。好在身前的红衣神君并没有检查那颗活生生的心脏，我送给他们的这个惊喜自然也不会在此时公布，虽然不知道为什么，但这样更好。他将那颗心脏交给我的大师兄容华仙君，容华低头看了我一眼，难得露出一丝笑意，他托着那颗心，对我说：「长羡，你的心能给莲毓，是你的福气。」旁边的宫吟本来面露不忍，此时见了那心，似乎是想起终于要化形的莲毓，也露出灿烂的笑容来，「长羡，莲毓将回来了，她是个极温柔、极善良的女子，所以你千万不要怪我们。以后……咱们还是好好相处，虽然你今日实在叛逆，师尊也很不高兴，但只要你乖乖的，到时候我托莲毓为你说上几句好话，师尊肯定也就消气了。」说完这话，他便头也不回地，与托着心十分着急的容华离开了这里。于是这里只剩下一位神君。我模糊的视线里，这红衣神君缓缓弯下腰来，他似乎是在看我，而我只觉得恶心，我尽量睁着双眼，好使眼中那极浓烈的厌恶之情能让他看得清清楚楚。东君也看清了。于是在那张面无表情的面容上，他缓缓垂下眸来，再抬起时，里面的颜色深沉浓郁，他伸出手指，似乎是想来触碰我的眼睛，我并没有躲开，只是静静地看着他。东君的手指缓缓触碰在我的眼上，他的手指很凉。像是叹息一般，他轻轻说道：「姐姐，你为何要逃呢？」我说不出话，现在的我空余仙骨而无仙力，虚弱得和下界刚刚出生的小妖无二。「姐姐，你不要这样看着我，我不喜欢。」见我这样，东君沉默片刻，将手掌覆在了我的眼上。于是钻心的痛苦再一次升起，可我明明没有心。——我的眼睛没了。2.「姐姐，我把你的记忆拿走，好不好？」在我修成仙骨下界的一日，我捡到了被丢弃的长生。也就是天生便是神君的东君。但我那时候并不知道。于是我心中难免升起怜悯，我其实不是一个心地多么善良的仙君，但或许是这百年来戒备心的逐渐消失，我轻轻戳了戳这婴儿的脸颊时，他不哭不闹地握住了我的手，软乎乎的。我决定将这孩子带上仙界。也是在上仙界之后，我发现这被丢弃的婴儿竟然有天生仙骨。彼时，我与二师兄宫吟仙君说起时，他眼神复杂，看了一眼我怀中的婴儿，笑着说：「不愧是我们长羡，这随手一捡，便是个天生仙骨的好苗子。」直到我被他们追杀，鲜血从脸颊滴落，沾染雪白的衣衫时，我才想通。哪有什么「随手一捡」，哪有什么「天生仙骨」，为了靠近我，靠近这个东君心心念念的「莲毓替身」，高高在上的小神君不惜返璞归真，伪装成弃婴。所以，一切的偶遇，一切的相伴，都是假的，都是这高高在上的小神君为了我这「莲毓替身」伪造出来的。那时候的大师兄容华仙君就不太喜欢还是长生的东君，他平日里便常与宫吟有些争风吃醋似的讨我的欢喜，见到一日日长大起来的长生时，他并没有什么好脸色，但也从来不像坑骗宫吟一般作弄长生，想必那时的他正是忌惮长生的真实身份。长生的第一次站起，第一次走路，我统统记得。他说话很早，第一句话便是「姐姐」。想想我当时是有多么欢喜。我从小的记忆，便是深不可测、危险万分的深渊之沼。故而当我捡到长生后，我只盼着他能够在干净、安全的环境下长大，我为他取名长生，含着彼时的我多少小心翼翼，就有多少我被剜心挖眼后的自嘲与痛楚。而找到我、发现我、将我带到仙界，并一手指导我修成仙骨化成仙君的扶桑神君，对长生的不喜却更加明显。如今想来，他不喜的不是长生对「长羡」的亲密，而是东君对「莲毓」怀揣的感情。扶桑。我是喜欢过他的。黑暗中如光一般耀眼的神君，将我一手拉起，百般温柔与呵护。我怎么会没有喜欢过他呢？-我被挖眼的不知道第多少日，或许是被东君带到了什么地方，他用仙君都挣不开的锁链将我囚禁住，每日会来几趟，但是来了之后，他也不说话，我只知道他静静地站在我面前。终于，他像是忍不住了，他的气息，如同风一般环绕在我的身边，声音低沉：「姐姐，你怎么还不愿开口？」我的手被锁链牵起，望不尽的黑暗中，我照旧没有说话。实则我并不知道该说些什么。我的心，我的眼睛，都已经被他拿去，我不知道东君将我囚禁在这里，对于他，或者说对于「莲毓」，还有什么好处。「姐姐，你的心就算离开了，也做了件坏事。」东君倒是也不管我有没有回应他，那轻柔的声音中，仿佛带着一丝怒气，又像是想要笑，「莲毓姐姐没有恢复记忆，是不是你做的？」我笑了笑，这对于现下的我而言是最简单不过的事情。「没有记忆，是个好事。」这是我这几日说的第一句话。黑暗的环境中，换来长久的寂静。如若不是我熟悉东君的气息，知道他还在我的身前，这寂静中，仿佛又只剩下我一人了。不知多久没有声音响起，那冰凉的手指触碰到我的脸颊时，我恶寒地往后缩了缩。但这双手的主人并不允许我这么做，他的声音再一次响起在我的耳畔，距离很近，气息扑在我的耳垂上，我只觉得恶心。「姐姐，我把你的记忆拿走，好不好。」不容我回答，他的手上似乎是出现了什么，而后捏开我的嘴，想要将那样东西塞进来。就在那丸药触碰到我的唇瓣时，我便知道这是什么——黄泉的孟婆汤与深渊之沼的唤灵草。这两者的确是能够让人前尘尽忘。我没有反抗，顺从地将这丸药咽下去了。东君因为我这顺从的行为愣了愣，他的手指触在我的唇上，声音似乎有些颤抖：「你怎么咽下去了。」闻言，我笑了笑：「神君，如你所愿。」「姐姐，你怎么能咽下去。」东君的手指用力地捏着我的喉咙，高声喊道，「姐姐，你把它吐出来，姐姐……」「姐姐，你怎么能想忘了我？姐姐？」「长生会害怕的，姐姐，你吐出来好不好？」「姐姐……」他甚至用了仙力。可这没什么用。隐隐约约，我似乎又听到熟悉的声音，温柔，却又冰冷——「东君，你给长羡喂了什么？」然而在这药的作用下，我已经逐渐听不到接下来的声音，恍惚之间，我仿佛又回到了东君第一次站起来摔倒的时候，他挣扎着爬起来，然后眼泪汪汪地扑在我的怀里，对我说，姐姐，长生害怕。又仿佛是第一次见到扶桑，他白衣不染纤尘，向黑暗中的我伸出手来，说，从此以后，有我护着你，你不必再害怕了。3.「他像是落荒而逃。」我是在一股强大的仙力催动下醒来的。是很舒服的力量，温柔、源源不断。在这种力量的支撑下，我微微睁开眼睛，却发现仍旧是黑暗一片，我不由动了动手指，却发现自己被锁链禁锢着。锁链很凉，而且我能感受到，这种锁链极其强大，不是我能够挣脱开的。而在这时，那股传入我身体的力量也停了下来。似乎还有一些无措。「……谁？」我张了张嘴，艰难地发出声音，声音很沙哑。没有人回应我。但我清清楚楚地能够感受到身前人的气息，那股与他的力量一样，温和如水却又不近人情的气息。于是我抬起头，用一种我认为能够看到身前人的角度，沙哑着声音，再次问道：「你是谁？」话音刚落，那股气息便在一刹那消失了。——以一种接近于落荒而逃的速度。-扶桑神君不知道为何要逃走，甚至是有一些狼狈的。等到离开东君的神殿，他才发现，他的手指竟然在微微颤抖。他沉默着站在东君的神殿前，远远看去，白衣如云，仿佛将这位眉眼如画的神君藏在雾中。也似乎什么人什么事都入不了那双淡如烟霭的眼中，在仙界所有人的眼中，作为三神君之一，扶桑神君永远是这么高不可攀的模样。但是，也就是在扶桑神君那鸦色的发中，却隐隐露出殷红的八股丝线。这丝线密密地缠绕在他的乌发间，就好像是黑夜中突然划过无数红色的星。他就这么站在东君的神殿前，一言未发。而来往的仙人们都不敢直视这位神君，只远远地行了礼，匆匆离开。这似乎凝固的氛围，直到一声悦耳动听的嗓音响起——「扶桑神君。」女子远山般的眉眼，仿佛温柔看待一切的事物，她那洁净的月白色长裙仿佛最圣洁的花，轻轻行走之间，有隐隐环绕的云纹。这一切，毫无疑问是美的，但超越了美的，还是她周身那让人感到无比舒适的气息。见到此人，扶桑神君本来微微皱起的眉，不由舒展开来，他的面容上，也同样展开一抹浅笑：「莲毓，你怎么来了。」莲毓向着他浅浅笑了，她微微抿着唇，道：「容华仙君与宫吟仙君打起来了……我想着，出来走一走也好。」周围有仙婢端着各类仙花仙果走过，总往两人身上似有若无地投来视线，似乎是觉得走了有段距离，也窃窃私语——「那位仙君是莲毓仙君么？」「肯定是了，你还见过扶桑神君向哪位仙子这么笑过？」「那、那长羡仙君……」一位仙婢忙打断她的话：「你怎么还敢提她？那日的阵仗，你是忘了么？」几位仙婢窃窃私语着，匆匆离开了。或许还是刚上来的仙婢，殊不知扶桑神君与莲毓已将这些对话听得一清二楚。莲毓的面容上浮现出一抹困惑，事实上，这不是她第一次听见「长羡」这个名字，在容华仙君与宫吟仙君打架的时候，她就偶然间听到过。而那位总缠着她的东君殿下，有时也会无意识地呢喃出这个名字。长羡……她是谁？莲毓觉得自己心里有些忐忑，她想抬起头问一问扶桑神君，却在那一刹那，她知道，扶桑神君也认识这个人。因为就在抬头的一瞬，莲毓看见扶桑神君正看着她。但不是在看她。而是通过她，看向另一个人。「扶桑神君？」莲毓不由皱起眉，她的心有些慌乱。扶桑神君终于回过神来，他抱歉地冲着莲毓笑了一笑：「抱歉，我在想……一些仙界政务的事情。你才刚刚修成仙君，境界不稳，我们还是先回去吧。」说罢，扶桑神君抬起手，似乎非常熟练地揉了揉莲毓的脑袋，而做出这个动作之后，他浅浅的笑却又突然僵住，意识到自己做了什么后，扶桑神君忙放下手：「对不起莲毓。」莲毓温柔地笑着：「没什么，这在从前……你是经常对我做的么？」闻言，扶桑神君沉默半晌，他看着莲毓，手指动了动，而后轻轻地说：「……是。」莲毓不是长羡，她比她温柔、善良、体贴……而且，她也没有那一双看似温和却暗藏桀骜的眼眸。-在又过了不知多久的黑暗与寂静后，我的身前，响起了一个人的脚步声。和醒来时那股温柔的力量不同，这人的气息灼热、滚烫，像是火、太阳。这气息，猛然间环绕住我。气息的主人紧紧地抱着我，抱得当真紧极了，仿佛要将我按入他的身体之中，我几乎有些喘不过气来。而后，在这一片寂静中，我听见耳边响起少年淡淡的声音：「姐姐，他来过，是不是？」4.「哪个弟弟会对姐姐做这种事？」我还没来得及开口，那人又在我耳旁呢喃道：「姐姐，你身上有他的味道，我不喜欢。」絮絮叨叨的声音，不断地在我的耳边响起，像是已经憋了许久没有说话，这下子统统发泄出来一般。「姐姐，你那日晕过去，吓坏长生了。」「那扶桑，他竟然还敢来。」说到这里，这声音微微压低，透着浓浓的不喜与忍耐。扶桑？我微微侧过头去，这人的呼吸全部喷在我的耳上，让我极其不耐，我张了张嘴重复了一遍这个名字：「扶桑？」这人的动作僵了僵。我下意识地觉得我好像说了什么不该提到的名字，不由微微皱了眉。下一秒，一股强大的仙力席卷四周，这力量的灼热与滚烫将周围的温度硬生生提高了许多，就像在火炉里一般，而这极其逼迫的气势还不仅仅如此，我整个人被狠狠推至身后的墙壁上。是冰玉一般的墙壁，使得我的脊骨都开始生凉，我被身前的人紧紧按住，一动也不能动，本来就被锁链囚住的双手早已被按在墙壁上，那人的手指紧紧地掐住我的手腕，灼热的气息几乎扑个满怀。我皱着眉，冷冷道：「放开。」那人按住我手腕的手指，慢慢地来回摩挲着，我能感受到他炽热的视线此刻就在将我上上下下地打量，我微微侧过头，那人却已经一把掐住我的喉咙，他的声音和力度一样，缓缓变大：「姐姐……」「刺啦——」几乎是没有想到的。在我将被他掐住呼吸困难之时，他突然松开了手，但也就是同时，我身上穿的衣服却被狠狠地撕开。而他冰凉的手指就摩挲着我露出的肌肤，一下一下地。越发靠近这滚烫的温度，我能够感觉到我脖子上不由自主沁出的汗。柔软的黑发碰触到我的脸颊，他几乎将整个人埋在我的怀中，那逐渐滚烫的唇瓣，轻轻地划过我的脖子、双肩。在这极度的愤怒与恶心之下，我只觉得我整个人都颤抖起来，我几乎是不受控制地喊出声——「你到底是谁，你为何要这样对我？……」那人的唇瓣，在我的肩上停住。他几乎是冷冷地开口：「姐姐，你在说什么？」「你声声唤我姐姐，却又做此等下作之事。」我感受到他动作的停止，冷冷笑了笑，「况且我孑然一身，何来的亲人？你是何人？」沉默。再次开口的时候，这人的声音却颤抖起来：「姐姐……你在骗我对不对？」我听见他站起来的声音，他来来回回地走着，身侧的气息大乱，那声音也断断续续的，「怎么会，我和扶桑都用了神力，你怎么还会忘记？孟婆汤和唤灵草，怎么会……」他冲过来，颤抖着抱住我：「姐姐，你是在骗我，是不是？你怎么会忘记长生呢？」我冷冷道：「孟婆汤和唤灵草？我自幼长于深渊之沼，这东西怎么会对我有效果？当真没想到，我不过小憩一会，一觉醒来……」我顿了顿，苦笑了一下：「心没了，眼睛也瞎了，还有这不知从何而来的一身仙骨。你到底是何人？将我囚于此地，你到底有何阴谋？」「深渊之沼……」他没有松开抱着我的手，「难道，难道，你只忘了这三百多年的事？」他的声音逐渐变得欢喜：「忘了，忘了……」但很快不知为何又痛苦地呜咽起来：「可是为什么，为什么你醒来见到的第一个人还是他！为什么你就这样痛痛快快地忘了？那我呢？姐姐，我怎么办？你怎么能忘了长生？」我沉默片刻：「我不认识你。」这自称为「长生」、似乎还是什么高高在上的神君，此刻紧紧地抱着我轻轻说道：「没事，没事姐姐，长生会陪着你的。姐姐，我是你亲手养大的呀，我们俩，是这个世上最亲的人了。」我抿了抿唇，不由一笑：「亲手养大？听你口气，你是神君，是仙界的人罢？我不过下界最最普通的莲花妖，我怎么将你亲手养大？况且……」我低头，「看了看」被撕破的衣服，嘲笑地拉长了声音：「哪个弟弟会对姐姐做这种事？」5.「容华，你算什么东西。」话音刚落，我便察觉到这位神君的身子立时僵硬起来。他缓缓站起身来，像是什么都没有发生一样，轻轻地对我说道：「姐姐，对不起，都是长生的错。」「是长生太着急了。长生害怕姐姐被那个人伤害到。」他轻轻地低语，「姐姐，我很珍惜姐姐的。」我皱着眉：「你在说些什么？」「姐姐，你不知道吧。你的心，就是扶桑挖掉的，你的眼，也是扶桑取走的。他把你囚禁在这里，用锁仙链将你的双手双脚锁住。」少年神君含着一丝悲伤的语调，在这小小的空间中响起，无边的黑暗中，他的声音，像是魔的低语，「姐姐，我好不容易找到你。你不知道，我有多害怕，害怕你会离开我。可是没想到扶桑竟然还给你服用了孟婆汤和唤灵草，我虽用了神力，但终究没有成功……你还是忘记了这些年的事情。」「你是说那个传了仙力给我的人，便是扶桑么？」我沉默片刻，说道，「你说的这些，我凭什么相信你？」「我知道姐姐会怀疑我。」少年神君轻轻地握住我的手，温温柔柔地笑了一声，「不过没关系，姐姐，过不了多久，我就为你将心和眼睛抢回来。」他说到这儿，突然咳嗽了一声，我的手背溅上了什么液体——应该是血。感受到这粘稠的液体，我不由微微皱了眉：「你怎么了？」我又听到他强作无恙、语调变得活泼的声音：「没事的，姐姐，就是一点血罢了。那日扶桑追杀你，我护你时受了一些伤，不过没有关系的，都是小伤。」「……」我轻轻抽出手来，「那你能告诉我，扶桑与我是什么关系么？他又为什么要挖去我的心、取走我的眼睛，还将我囚禁在这里？」一身红衣的东君淡淡垂着眼眸，他看向靠在墙上、发丝凌乱的白裙女子，微微勾起一抹笑，语调却逐渐变得低沉悲伤：「姐姐，扶桑是你的师尊。但是，他待你一点也不好，一开始，他还认真指导你，但当你晋升为仙君之后，不仅是扶桑，还有你曾经的两个师兄……都认为你不过只是花妖出身，却拥有如此出众的天资。所以，他们合起伙来，做出此等之事。」他弯下腰，手指轻点，那本来被他撕开的衣服便又完好如初。东君轻轻将那衣领合拢好，而后缓缓说道：「不过姐姐，你别担心，长生，会一直保护你的。」就在这时，一道声音轻轻响起，似乎是从什么传声器中传出来的——「神君，你在忙吗？」温柔轻缓的女声。东君下意识地看了眼对面的人。我自然也听到了这声音，我淡淡提醒他：「似乎有人找你。」「抱歉姐姐，有些事情，我不得不去处理一下。但你放心，我还会偷偷来看你的。」这少年神君，一丝慌乱也无，他将手从我合拢的衣领上移开，然后浅浅笑了一下。我感受到属于这位神君炙热的气息慢慢消失在这个空间中。空间重新变得冰冷起来。我闭着眼，动了动被链子牵住的手腕，不由笑了一下。-优美宁静的芳灵小境之中，花叶随着风轻轻摇曳，中心一片湖水，静静地荡起涟漪。而立在湖心亭中的女子与两位俊美仙君，本该是赏心悦目的场景，只是此刻，两种不同颜色的光芒不断地在这片空间中闪烁，也就是在这些光芒中，两道身影不断地穿梭、交织，几乎每一次碰撞，都会使得这片花叶纷纷坠落，甚至天都在变换着颜色。「容华，你为什么就非要霸占着莲毓不可？你没有觉得自己管得太多了吗？」「……宫吟，我都说过了，你不能偷偷来见莲儿。师兄的话，你也敢不听了是么？」「你这都是什么歪理！」这不是容华和宫吟第一次打起来，自从莲毓醒来，这样的争吵与打斗几乎每一日都要发生。穿着白衣的莲毓无奈地站在下面，她柔美的面容上眉头紧紧皱着：「容华，宫吟，你们不要再打了。」就在此时，一道火红的流光来势汹汹地撞入天上这两位正在打斗的仙君之间——「打够了就停下。」不远处缓缓走来的身影，墨发高竖，衣胜流火，行走之间自有一番风流。只是那眉眼清冷似青竹，虽还是少年模样，但却有着难言的威压。宫吟一见到此少年，忙收了手，他皱着眉躲开容华打来的一道法术：「容华，东君在此，你怎么还敢出手？」缓缓放下手的容华听到这话，冷冷一笑，他的目光瞥向那道火红的身影，眼中划过一丝憎恶，而后开口道：「东君既然来了，我小小仙君又怎么敢再出手？」他顿了顿，看着慌忙跑过来的莲毓，又用莲毓正好能够听到的声音，意味深长地说道：「只是东君来得匆匆，不知，是否从那处而来？」他是知道那日之后长羡的去处的。莲毓刚刚走到他们身边，此时听到容华这句话，不由皱了皱眉，刚想抬起头说些什么。「啪——」只听见重重一声，容华整个身躯都被拍起，而后坠落在了不远处的湖水之中。一片寂静，水花与涟漪之中，衣衫浸湿的容华慢慢地站起来。他慢慢看向负着手的神君。东君面无表情地看着他，突然笑了笑：「容华，你算什么东西。」6.「他可是……天生仙骨。」两百多年前，扶桑神君座下的小徒弟长羡仅仅用了一百年便修成仙骨化成了仙君。修成仙君那日，长羡盈盈而立，最简单的月白色长裙，周身萦绕着华光，漫天霞姿、仙兽齐鸣。一瞬间，容华几乎以为心心念念了几百年的莲毓就站在他的面前。但很快容华就反应过来。长羡的眼中，永远对他人带着一丝警惕，与莲毓七成像的面容上，本应该柔美温婉的五官，却像是生生浸了刺骨的冰水。和莲毓不同，长羡不太常笑，但是有一点是相似的——容华看着月白长裙的女子在看到缓缓行来的扶桑神君时，不由自主绽开来的浅浅的笑，心里这么想道。「面对扶桑时的笑。」容华的面容冷了下来，他闭了闭眼睛，看那霞光万千、仙兽齐鸣的景象，又看了看仙界禁地的方向，不由露出一抹笑来，「没事，既然长羡已经修成仙君，那么距离莲毓回来也不远了。」身前，月白长裙的长羡缓缓走来，向着他与宫吟，点了一点头：「容华师兄，宫吟师兄。」身旁是宫吟毫不遮掩的兴奋，他几乎要围着长羡打转：「长羡，师兄就说你可以，果不其然。」「谢谢师兄往日对我的指导。」长羡微微一笑。见此，容华忍住心中的暴戾，他柔和着眉，轻声问道：「长羡，你既已修成仙君，接下来有什么想做的么？若有什么喜欢的、想要的，也都说出来，师兄必然为你找来。」长羡微微皱了皱眉，她思忖片刻，道：「还是继续修炼吧，但或许我会下界一趟。仙界有些闷。」说到这里，她摇了摇头：「师兄往日送我的东西已经够多了，长羡受之有愧。」「怎么会，你可是我最疼爱的小师妹。」最疼爱的小师妹的替身、引子。容华笑了笑，抬起手来揉了揉长羡的脑袋：「那好，不若我陪你下界罢？」旁边的宫吟不满地拍下他触碰长羡的手，转头笑着说：「容华最近专管东海那儿的政务，忙得很。小师妹，不若我陪你去罢？我下界的次数多，也知道许多好玩、好吃的地方。」容华作为东海龙族的后裔，又拜在三神君之一的扶桑神君门下，未来不可限量，因此近日天帝便派他专管东海的事务。容华低头看了看手。长羡已淡淡笑着拒绝：「不必了，师兄。我一个人去就好。」正说着话，她身边缓缓站定一道身影，那人向着她的方向微微侧了侧头，声音如璧如玉：「长羡，你刚修为仙君，仙力并不稳，待会我为你巩固基本，你再下界也好。」说话的人正是他们的师尊扶桑神君。扶桑下意识地轻轻拍了拍长羡的头，长羡听到这话，微微抬了头，露出她自己或许都没发现的烂漫的笑容来：「知道了，师尊。」容华看着这副和乐融融的场景，冷冷一笑。-长羡回到仙界，还带上了一个婴儿时，是容华没有想到的。他在靠近那个婴儿，已经暗自凝聚仙力想要出手时，却感受到一股熟悉的力量——滚烫、灼热。不远处传来的阵阵龙车之声，仿佛是在警告。是东君。容华收起手，和身旁显然也已经意识到的宫吟对视一眼。长羡带着一丝欢喜的声音响起：「师兄，我在下界遇见他，觉得有些缘分，便带上来了。他还这么小……我为他取名长生，师兄们觉得可好？」容华抬起头时已面色如常，他上下打量了一番长羡怀中闭着眼的婴儿，换上了同样欣喜的表情：「小师妹，你是不是还没有看过他的天资？他可是……天生仙骨。」宫吟在旁边轻轻笑着，眼神复杂：「不愧是我们长羡，这随手一捡，便是个天生仙骨的好苗子。」闻言，长羡愣了愣，她低下头，轻轻摸了摸婴儿的面颊，缓缓说道：「我并没有在意这个。他若日后能够得升仙君，自然是好。若是没有，也无妨。这世间百态，我望他都能珍之看之，淡然待之。」于是，在接下来的两百年里，容华看着这婴儿逐渐长大成人。或许是因为东君强行返璞归真的原因，小小的身体里，藏起来的神君的巨大神力，使得他小时候便多病多灾。往往有几个日夜，他都能看到长羡抱着「长生」来往于药医殿，或是站在芳灵小境的湖心亭中，化萤火之光逗生病的「长生」开心。东君的记忆直到修成仙君后才回来。那时候长羡正轻轻拥抱着他：「长生，恭喜你。」容华亲眼见到，那本来清朗如竹的少年，身侧突然换了气息，他本来微微勾起的唇角此时已经放下，而抱住身前人的手却更紧了几分。「谢谢你……姐姐。」容华冷眼旁观。也是那日后不久，仙界禁地传来了震动，他欣喜若狂地奔去，看见池中悄然盛放的月白莲花——莲毓也要回来了。-一片静默之中，容华与不远处负着手的少年神君对视。在池中满身狼狈的容华，突然勾起唇笑了笑，他行了一个大礼，声音平和：「东君见谅，是容华一时失言。」7.「他明明是高高在上的三神君之一。」红衣的少年神君面无表情地看着容华。一时间气氛紧张起来。站在旁边的宫吟像是看戏一般，他一言不发，束手旁观。还是莲毓看了看湿漉漉的容华，又看了看面无表情的东君，担忧地开了口：「东君，想来容华师兄也不是故意冒犯你的，你切莫放在心上了。」听到莲毓开口，东君的面色微微缓了过来，眉眼也变得温柔起来，他向着莲毓露出一抹笑来：「莲毓姐姐既然开口了，我自然不会生气。但是……」他笑着继续说：「有些人还是要认清自己的身份，容华，你说是不是？」作为三神君之一，东君有这个资格也有这个底气这么说。容华微微一笑，也没用仙力弄干身上的衣服，仍湿漉漉的，他抬起脚跨过湖水站了上来，说道：「神君说的极是。」见此，莲毓仍旧有些担忧，就在她刚想要说些什么的时候，突然感到一阵头晕目眩，莲毓张了张嘴，竟突然合上眼晕了过去。站在旁边的东君忙接住了莲毓，容华刚冲过来，此时见得东君已将莲毓抱了起来，伸出的手又收了回去。宫吟在旁边着急道：「莲毓怎么了？怎么突然晕过去了？」东君抱着莲毓，紧紧皱了眉：「我送莲毓回景灵殿，宫吟你去药医殿。」景灵殿是扶桑神君的住处，这几日需要休养的莲毓都是住在那里。还未等宫吟接话，东君的身影已然消失不见。旁边的容华没多说什么，也跟了上去。宫吟长长叹了口气，也忙去了药医殿。-景灵殿内。请来的医药殿的清儒仙君摸了摸并不存在的胡子，看着躺在床上皱着眉显然极痛苦的莲毓，慢吞吞地说道：「这……莲毓仙君体内的力量，应该不是她的吧？虽然本体相近，但毕竟不是她自己的。」东君沉默着看了眼床上的莲毓，没有说话。容华已冷冷开口道：「那又如何？清儒，你把话说清楚。」「莲毓仙君本体为莲花，其莲子又被称为莲心。幻化人形之后，莲花花叶化作身体四肢，最重要的一颗莲心化作心脏，次之的两颗莲子便是双眼，剩下的莲子又各自形成不同的器官，最后的莲台便是本命仙器。而莲毓仙君在四百年前自毁本体，本就没了存活的机会，但是仰仗神君与各位仙君，又不知从哪儿取了这本体相似的莲心来，才使莲毓仙君能够再次化成仙身。」清儒仙君并没有被容华吓到，他摸着不存在的胡子，不紧不慢地继续说着，说到「又不知从哪儿取了……」的时候，竟忍不住笑出了声，「但这莲心并不是莲毓仙君自己的，虽在她体内，却会受到其它莲子的排斥，故而莲毓仙君此次便晕倒了。」说到这儿，殿外走进来了扶桑神君，他本在处理政务，之前放在莲毓身上的感应此时突然变动，便想到是莲毓出了事，忙就赶了来，他已经听到清儒仙君所说，本来还微微皱着的眉此时突然僵住了。「扶桑神君。」三位仙君见扶桑神君进来了，忙行了礼。扶桑看了眼床上面容痛苦的莲毓，转头问清儒仙君道：「照清儒你这么说，那该如何是好？」「老朽又不是莲花，老朽怎么给莲子和莲子劝架呢？」清儒收回手，不以为意地站了起来，而后摇头晃脑地说道：「哎呀，也不知道为什么，老朽一踏进这景灵殿呐，就感觉浑身不舒服，就感觉恶心，实在待不下去了……扶桑神君，东君，老朽这就回去了。」他一面说着，一面看了眼旁边沉默不语的东君，笑眯眯地说：「老朽还是回去看话本吧，话本里有句话，叫什么……养不熟的白眼狼云云，实在可叹、可笑，还挺有意思。」不等其他人说话，清儒行了一礼，拎着箱子便化云走了。东君本来面无表情的脸此时更阴沉了，他知道清儒是在指桑骂槐。小时候他常常生病，姐姐便会带他去药医殿，和清儒也算是老相识。扶桑神君自然也知道，但不知为何，他竟然觉得清儒那番话听得格外舒适。而一心想着莲毓的容华此时握紧了拳头，转头看向东君道：「东君，刚刚那番话你也听见了。既然莲儿体内一颗莲子不够，那么……」正听着的宫吟一下子便明白了他的言下之意，不由皱了皱眉：「你还想从长羡那儿……？」「长羡现在已经如此，怎么能再取她的莲子。」扶桑几乎是脱口而出。他似乎是反应过来自己在说什么，忍住心中的异样，缓缓道，「容华，长羡也是你的师妹。」容华看着这位师尊，心中冷冷笑了笑，他只转头看向沉默的东君，接着说：「东君，我知晓你取了长羡的一双眼。两颗莲子，莲儿肯定会没事的。」宫吟本来还不知道这件事，听见容华这么说，心下一惊，想到刚刚清儒仙君临走时说的话，实在不寒而栗。东君取出长羡的眼睛，无非是不想看见那双眼中的厌恶之情，他本没有想过将这双眼交予他人。他低头看着莲毓，莲毓此时满脸痛苦，昏迷不醒，汗珠从她的额头上滑落下来。就好像看见那一日的姐姐。东君闭了闭眼睛，可是在这一刹那，又是当年他渡劫时莲毓冲过来挡在他身前的样子。长羡的模样与莲毓的身影不断交叠，东君一时间心里跌宕起伏，他只觉得喉咙一腥，竟当众吐出一口血来。「神君……」宫吟忙上来扶住他。扶桑也不由皱了眉，但容华却继续道：「东君，恕我直言，当年莲儿为你挡劫，九死一生。难道，你就这么忘了？」他的声音如冰，寒冷而刺骨。扶桑看向容华，终于开口道：「容华，闭嘴。」扶桑毕竟是容华的师尊，容华只能不再开口，他心中不满，只痴痴地看着莲毓。东君缓缓站直身子，他神情淡淡地拭去嘴角的血迹。而就在他伸出的手掌之上，升腾起两颗如墨如玉的珠子。一时华光溢彩，温润流转。容华眼睛一亮：「东君你想……」话还未说完，他整个人又被一股强大的神力狠狠拍到了地上。烟尘之中，寂静无言。扶桑神君想要开口说些什么，他看着那两颗珠子，一时又想起那双漂亮的、流转的、却有些桀骜的眼眸，想起那时常安静、看见他便会展开一抹浅笑的小徒弟，心中突然一痛。这疼痛之感已经伴随了他两百多年。连他也不知道为什么会痛。他明明是高高在上的三神君之一，明明这世上几乎已经无人能够再伤他。「这是最后一次。」这满殿寂静中，响起少年神君淡淡的声音。-本来已经习惯的黑暗。却不知为何，我的身体，又或者是从灵魂深处，疼痛与撕裂感开始蔓延了全身。我想用手捂住疼痛的位置，但是手被锁链紧紧困住。在这寂静中，我的汗水不断地流出来，可以想象的狼狈，但我已经顾及不到了，我痛得想要起来，我身体内残余的一些灵力在不断乱窜，很快又消失不见。是什么消失了？我想睁开眼，但面对的仍旧是一片黑暗。以及铁链发出的冰冷的声音。8.「长生，你不会让姐姐失望的，是不是？」在这片急剧的痛苦中，我知道，我的眼睛可能回不来了。额角的汗水滴落到我的唇瓣上。很苦。在那股灼热的气息来到我的身前时，这自称为「长生」的神君沉默了许久。而后，我感受到他伸过来的手。我下意识地侧过了头，但仅仅只是这个小小的动作，就让我直喘了好几口气。「姐姐，我只是想帮你擦一擦汗。」他的声音在这时轻轻响起。我沉默半晌，开口道：「你曾说，你会帮我把我的心和眼睛抢回来。」长生没有说话。他似乎是弯下腰，用一方帕子轻缓地将我面容上的汗珠拭去。他呢喃一般地说:「姐姐，你会离开长生吗。」这一句话，他好像不是在问我，而是在问他自己一般。「我这样还能怎么离开你？」我自嘲地一笑，「你说我养你长大，是么？」长生的声音轻轻在这个空间中响起：「是。姐姐，整整两百多年。」我淡淡地笑了一下，被铁链牵制住的手向着他的方向挥了一下：「你过来。」半晌，脚步走得更近。我伸出手，循着刚刚声音的方向，摸索到一张温凉的面容上。他的唇瓣，在微微颤抖，声音亦是。「姐姐……」长生含糊地发出两个音节。一滴液体轻轻坠落在我的手背上。是泪。我突然凑近他，扯了扯唇角，想要露出一抹笑，却失败了。我在长生的面容前，以着几乎要贴近他唇角的距离，轻声低语：「长生，你怎么能喜欢上把你养大的姐姐。」「长生，你不会对不起养了你两百多年的姐姐，是不是？」「……」听到这句话，长生的身体剧烈地颤抖了一下，而后几乎是踉跄着往后退了一步。在我看不见的地方，东君用手指触碰了一下嘴角的鲜血，他低下头看着那修长手指上的血迹，而后又翻过手来，看了眼掌心。东君又想起剜长羡心的那一日，姐姐的鲜血就像是这样沾染上了他的手指。他颤抖着遮住自己的眼睛，好不让那眼泪得以流出来。从心的地方，有什么东西，像是雷劫一般，颤动着、跳动着，阵阵地逼入他酸涩的咽喉。可是……他不能让姐姐离开他，他决不能，决不能失去姐姐。他不允许姐姐喜欢上其他人。但他更不想姐姐厌恶他。在这片空间的长久的沉默中，我晃了晃手上的链子：「你说，是那位扶桑将我囚禁在这里的。现如今，我心也没了，眼睛……」说到这里，我轻轻笑一声：「眼睛应该也被拿去用了吧，既然如此，我一介废人，还有什么不放心的。你转告他，将我放出去转一转也好。我一个人待在这里，我不喜欢。」长生没有回答，但是他往这里走了几步，而后用手指轻轻触碰上冰冷的锁链以及那被锁链牵制住的我的手。我的手微微动了一下，然后轻轻地，反握住了那根手指。感受到那手指的颤抖，我再次柔声问道：「长生，好不好？」「我既照顾了你两百年，长生，你不会让姐姐失望的，是不是？」灼热的气息里，我听见少年沙哑的声音——「好。」9.「长羡……这个名字挺好的。」在那日之后，许是长生与那位扶桑说了，我的手脚终于不必被锁链锁住。并且，我似乎也被换到了另一个空间，像是就寝的地方，有适宜的温度与柔软的被褥。只是踩在地上，仍是冰凉。我的身体其实已很不好。失去了眼睛与心这三颗最为重要的莲子，我能察觉到如今的身体，就如同枯叶般摇摇欲坠。每至夜晚，当我合上眼休息时，都能察觉到一股滚烫的气息。那气息就近在咫尺。而后会有人的视线，贪婪地一遍又一遍描摹着我的面容。我知道是长生。-事实上，从我醒来的那一日之后，除了那位据说是我从前师尊的扶桑以及长生，我就再没有感觉到其他人的气息。长生似乎很不愿意我出去，他黏得我越发紧了。偶尔他会在我的要求下陪同我一起出门，虽说我也不知道是去哪里，但能够出门，就已让我本疲惫不堪的身体得到一丝放松。这日，我正倚在栏杆上，长生就站在旁边，将手上的像是鱼饵的东西交给我。「姐姐，你还记不记得？我小时候，最爱用这些东西来投给池中的鱼儿吃，你说这在下界叫做鱼饵。」他握着我的手，将那些鱼饵放在我的掌心。我收回手，用手指轻轻抓了点鱼饵，感受着那粗糙的质感，我淡淡道：「抱歉，我不记得。」「……」长生沉默了一会，又像是笑了起来，「没事姐姐，长生都记得，长生会一一告诉你的。」我可有可无地点了一点头，而后转过身，将那鱼饵一下一下地扔进池子里去。微微荡起的涟漪，是轻微的水声。而长生就静静地站在旁边，用那灼热的视线，似乎在一笔一划地勾勒我的五官。正在这时，长生身上又传来了上次一样的声音：「神君，是我，莲毓。若听到这些话，能否请你来见我一面？」莲毓。我挑了挑眉。还未等长生说话，那声音又再一次响起：「听师兄说，此次我醒过来，多亏了神君拿来的……」这句话还没有说完，便猛地被长生掐断了。「这声音有些耳熟。」我投着手上的鱼饵，笑了笑说，「莲毓。好名字。」长生笑得似乎有些勉强：「姐姐，是位故人，我们先回去吧。」我懒懒地摩挲着粗糙的鱼饵，漫不经心地说：「你先去吧，我就在这待一会。」「可是姐姐……」长生的声音里有一丝慌乱。「你若不放心，捏个结界便是。」长生沉默了一下，而后说：「姐姐，我不是这么想。」见我没有回答，他只能轻声道：「那姐姐，我先去一趟，你在这里……不要乱走。」在他消失的一瞬间，我便感受到了结界。我淡淡笑了笑，索性将手中的鱼饵全部扔在了池子里。「哗啦」一声。很安静的氛围。不知从哪里来的风，我微微闭上眼睛，却感到眼上像是落下了什么，颤颤巍巍的，很轻盈。我动了动眼睛，那东西就又轻轻飘起来落在了我的鼻尖上。我伸出手来，在鼻尖的位置轻轻触碰了一下——似乎是只蝴蝶。这蝴蝶并不畏惧我的触碰，它的蝶翼柔软而洁净，在我的手腹下微微地颤动着。是一种微小生命的颤动。「好痒。」那蝴蝶像是听懂了，又扑打着双翼停落在我伸出的手指上。我低下头，虽然仍旧是一片黑暗，但却像是能够看见这手指上的蝴蝶一般，盈盈的，应该很温柔。我愣了愣，也不管这蝴蝶是否能听懂，便低着头笑着说道：「从前在深渊之沼，灵物最不喜欢接近我，就算我化作本体也是。这里应当是仙界，难道仙界的灵物会格外喜欢我一些？」这蝴蝶便在我的手指上微微动了动。在那一瞬间，我仿佛能够看见它的模样。像一团光。可就在下一秒，我身旁传来了脚步声，与此同时我手上的重量也消失了。蝴蝶似乎飞走了。这气息与长生的不同，让我想起醒来的那一日，感受到的温柔与冰冷。或许在这个人的身上，温柔与不近人情，并不对立。「你是扶桑？」我将手收了起来，而后弹了弹袖子，转过了头看向那个方向。那人的脚步在离我还有一些距离的时候停下了。他浅淡的，宛若山涧流水的声音，轻轻响起：「东君说你失忆了。」这声音很耳熟，也很好听，但我并不喜欢。「东君？」我若有所思地开口，「你是说长生？他不是叫这个名字么？」「长生，是你给他取的名字。」他缓缓道，「长羡，你当真失忆了吗。」我不以为意地又转过头来，向着池水的方向看去：「我没有失忆。」</div><div class="KfeCollection-VipRecommendCard-footer"><div class="KfeCollection-VipRecommendCard-footer-number">3.6 万点赞 · 3496 评论 · 盐选推荐</div></div></div><div class="Post-Sub Post-Sub-Mobile"><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><img class="Avatar css-1any501" src="https://pic1.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b" srcset="https://pic1.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b 2x" alt="RandomGenerator"></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span>RandomGenerator</span></h2></div></div></div></ul></div><div role="complementary" aria-label="推荐阅读" class=""><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class=""><a href="https://zhuanlan.zhihu.com/p/19710173" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">LLM选课</div><div class="MobilePostItem-Summary u-ellipsis">专栏文章索引 - 敝帚集 - 知乎专栏 上次聊了LLM选专业，这次聊聊LL…</div><div class="MobilePostItem-Footer">蒋小诺 · 发表于律政留学</div></div><img src="https://picx.zhimg.com/6e607c0238f2b8c95daede0da940485a_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/6e607c0238f2b8c95daede0da940485a_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/6e607c0238f2b8c95daede0da940485a_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="LLM选课"></a><a href="https://zhuanlan.zhihu.com/p/125655125" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">LLM 有没有必要选具体方向？</div><div class="MobilePostItem-Summary u-ellipsis">作者简介William，上海交大凯原法学院本硕，康奈尔法学院LLM，参与牛津出版社《The Japanese Way of Justice-Prosecuting Crime in Japan》一书中文版的翻译工作，在上海市方达律师事务所工…</div><div class="MobilePostItem-Footer">将军 · 发表于律政留学</div></div></a><a href="https://zhuanlan.zhihu.com/p/30089981" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">如何在LLM的学习中生存并完成学业</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">作者 | 学律原创团队 首发 | 学律留学顾问中心（微信公众号ID：Top…</div><div class="MobilePostItem-Footer">学律留学... · 发表于学律申请中心</div></div><img src="https://picx.zhimg.com/v2-d402ece2be62edb571d0fe26b099b861_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-d402ece2be62edb571d0fe26b099b861_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/v2-d402ece2be62edb571d0fe26b099b861_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="如何在LLM的学习中生存并完成学业"></a><a href="https://zhuanlan.zhihu.com/p/22499113" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">LLM找工作的几点建议~ 真的 · 不是越俎代庖~</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">真的，我真的不是越俎代庖，虽然我读的是JD，但是女友找工作时，我全程参与，还是有一定发言权的。 来，我们不回避问题，也不夸大困难，并且分享“经验”。 问题： LLm的最大问题，无非是项…</div><div class="MobilePostItem-Footer">王夷骁 · 发表于法律圈很小</div></div></a></ul></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 390px; bottom: 0px; left: 16px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;633033220&quot;}}}"><span><button aria-label="赞同 194 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></span>赞同 194</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down VoteButton--mobileDown"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleDown" fill="currentColor"><path fill-rule="evenodd" d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023Z" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Comment Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span>6 条评论</button><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 0 0 .165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 0 0-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 0 0-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 0 0-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 0 0 .164-.12l2.378-4.122Z"></path></svg></span></button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover1-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover1-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Dots Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></span></button></div></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px; height: 54px;"></div></div></div></div></main></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fapi\u002F","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","allowSignUp":true,"refreshValidityPeriod":"30","release":"824-bcf32e16","currentEntry":"column","isMobileEntry":false,"apollo":{"env":"prod","globalSilence":"","ncgModeSign":"3f8e56febda4fb3bbea72e379d76de1e","topstory_rec_adp":"1","test_canary":"member|0-100,1-0","use_new_player":"member|0-0,1-100","player_vendor":"member|0-0,1-100,2-0","use_hevc":"member|0-0,1-100","upload_use_signature":"member|0-0,1-100","use_backdrop_blur":"member|0-0,1-100","article_title_imagex":"member|0-50,1-50","play_station":"member|0-0,1-100"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"entities":{"users":{"zijie0":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"633033220":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGJ-QhvjYHlDBQ==&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"entityWords":[{"name":"语言模型","mention":"语言模型","matchorder":1,"begin":292,"end":296,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzor63oqIDmqKHlnosSB1Vua25vd24YpAIgqAIoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"稀有物种","mention":"稀有物种","matchorder":1,"begin":5516,"end":5520,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgznqIDmnInniannp40SB1Vua25vd24YjCsgkCsoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"正则表达式","mention":"正则表达式","matchorder":1,"begin":1936,"end":1941,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJaCg\u002FmraPliJnooajovr7lvI8SB1Vua25vd24YkA8glQ8oATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"推理引擎","mention":"推理引擎","matchorder":1,"begin":5892,"end":5896,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzmjqjnkIblvJXmk44SB1Vua25vd24YhC4giC4oATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"代码生成","mention":"代码生成","matchorder":1,"begin":286,"end":290,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzku6PnoIHnlJ\u002FmiJASB1Vua25vd24YngIgogIoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"思维树","mention":"思维树","matchorder":1,"begin":15276,"end":15279,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJUCgnmgJ3nu7TmoJESB1Vua25vd24YrHcgr3coATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"组织设计","mention":"组织设计","matchorder":1,"begin":5345,"end":5349,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgznu4Tnu4forr7orqESB1Vua25vd24Y4Skg5SkoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"知识图谱","mention":"知识图谱","matchorder":1,"begin":8796,"end":8800,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgznn6Xor4blm77osLESB1Vua25vd24Y3EQg4EQoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"树搜索算法","mention":"树搜索算法","matchorder":1,"begin":16582,"end":16587,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJcCg\u002FmoJHmkJzntKLnrpfms5USB1Vua25vd24YxoEBIMuBASgBNQAAAAA6B2FydGljbGVAAEgAUiQxZGIxZTk0Yi0wYTllLTQzNzktOWM0MS0zMDFlMTkxYjE1ODM=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"测试用例","mention":"测试用例","matchorder":1,"begin":4095,"end":4099,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzmtYvor5XnlKjkvosSB1Vua25vd24Y\u002Fx8ggyAoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"云服务","mention":"云服务","matchorder":1,"begin":3385,"end":3388,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJUCgnkupHmnI3liqESB1Vua25vd24YuRogvBooATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"软件工程","mention":"软件工程","matchorder":1,"begin":5579,"end":5583,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzova\u002Fku7blt6XnqIsSB1Vua25vd24YyysgzysoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"数据清洗","mention":"数据清洗","matchorder":1,"begin":1868,"end":1872,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzmlbDmja7muIXmtJcSB1Vua25vd24YzA4g0A4oATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"尧舜禹","mention":"尧舜禹","matchorder":1,"begin":15160,"end":15163,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJUCgnlsKfoiJznprkSB1Vua25vd24YuHYgu3YoATUAAAAAOgdhcnRpY2xlQABIAFIkMWRiMWU5NGItMGE5ZS00Mzc5LTljNDEtMzAxZTE5MWIxNTgz","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""}],"id":633033220,"title":"LLM 全栈开发指南补遗","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F633033220","imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-201fcd10c63fa9554176cc522a9f01f5_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-201fcd10c63fa9554176cc522a9f01f5_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-18da7d5f21e5f06fb63cdfa007967752_200x112.png\" data-caption=\"训练 LLM 架构\" data-size=\"normal\" data-rawwidth=\"2100\" data-rawheight=\"1082\" data-watermark=\"watermark\" data-original-src=\"v2-18da7d5f21e5f06fb63cdfa007967752\" data-watermark-src=\"v2-a8177b623b5a5df7531f8b9f76a9f4fe\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-18da7d5f21e5f06fb63cdfa007967752_r.png\"\u002F\u003E在上一篇 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F629589593\" class=\"internal\"\u003ELLM 应用开发全栈指南\u003C\u002Fa\u003E 中，我们介绍了 FSDL 的新课程 LLM Bootcamp 中的内容。本周他们又把几个 guest talk 的录像放了出来，看了下也挺有收获，在这里做个补遗。How to train your own LLM首先是来自 Replit 的 Shabani 介绍他们自己训练一个代码…","created":1685340866,"updated":1685340866,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","ipInfo":"IP 属地日本","imageWidth":1792,"imageHeight":1024,"content":"\u003Cp data-pid=\"aw1KBN0Y\"\u003E在上一篇 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F629589593\" class=\"internal\"\u003ELLM 应用开发全栈指南\u003C\u002Fa\u003E 中，我们介绍了 FSDL 的新课程 LLM Bootcamp 中的内容。本周他们又把几个 guest talk 的录像放了出来，看了下也挺有收获，在这里做个补遗。\u003C\u002Fp\u003E\u003Ch2\u003EHow to train your own LLM\u003C\u002Fh2\u003E\u003Cp data-pid=\"OblrNWpl\"\u003E首先是来自 Replit 的 Shabani 介绍他们自己训练一个代码生成的大语言模型的经验，非常有信息量，可以结合 WandB 的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwandb.ai\u002Fsite\u002Fllm-whitepaper\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EHow to Train LLMs from Scratch\u003C\u002Fa\u003E 来一起看。\u003C\u002Fp\u003E\u003Ch3\u003E技术栈\u003C\u002Fh3\u003E\u003Cp data-pid=\"g3tLwKgj\"\u003EReplit 用到的训练技术栈主要包括：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"D3i-Luoc\"\u003EDatabricks，用于做各种数据处理与分析，也是整个 stack 中最复杂最重要的一部分。\u003C\u002Fli\u003E\u003Cli data-pid=\"Tu3k7bXz\"\u003EHuggingFace，用于获取数据集，模型，tokenizer，inference 工具等。AI 时代的 GitHub，也是人人必备了。\u003C\u002Fli\u003E\u003Cli data-pid=\"-av4wJhz\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.mosaicml.com\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMosaicML\u003C\u002Fa\u003E，提供模型训练的基础设施，除了 GPU 这类硬件资源外，也能自动帮你做分布式训练，各种训练加速，并提供训练 LLM 的典型参数配置等，非常容易上手。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"xsgE8j0p\"\u003E整体的架构图如下图所示：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8177b623b5a5df7531f8b9f76a9f4fe_b.jpg\" data-size=\"normal\" data-rawwidth=\"2100\" data-rawheight=\"1082\" class=\"origin_image zh-lightbox-thumb\" width=\"2100\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8177b623b5a5df7531f8b9f76a9f4fe_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2100&#39; height=&#39;1082&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2100\" data-rawheight=\"1082\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2100\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8177b623b5a5df7531f8b9f76a9f4fe_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8177b623b5a5df7531f8b9f76a9f4fe_b.jpg\" data-original-token=\"v2-18da7d5f21e5f06fb63cdfa007967752\"\u002F\u003E\u003Cfigcaption\u003E训练 LLM 架构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E数据集\u003C\u002Fh3\u003E\u003Cp data-pid=\"pZz8FUKl\"\u003E他们因为是训练代码生成模型，所以训练数据集主要是跟代码相关的内容，包括 StackOverflow 中的问答，来自 BigCode 的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fdatasets\u002Fbigcode\u002Fthe-stack-dedup\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EThe-Stack-Dedup\u003C\u002Fa\u003E 数据集，以及 Replit 自己的一些公开 repo。现在大家应该也都知道了，训练一个高质量大模型的主要秘诀都集中在数据清洗上，从这个分享中也可以学到很多他们的一些具体做法，例如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"R5Nu-Ocm\"\u003E通过一些正则表达式和人工规则判断并移除自动生成的代码。\u003C\u002Fli\u003E\u003Cli data-pid=\"eagO7xLW\"\u003E将一些敏感信息移除，如邮箱，IP 地址，各种密码密钥等。\u003C\u002Fli\u003E\u003Cli data-pid=\"WlnES0VH\"\u003E移除没法编译通过的代码，不过只能在部分语言做这个操作（例如 Python 就比较好做一些），而且还挺耗时的。\u003C\u002Fli\u003E\u003Cli data-pid=\"tSZZl5Cc\"\u003E通过平均行长度，最大行长度，字母和数字类型的字符数占比等指标来进行一些过滤。比如典型的应该过滤掉一些 minified 或者混淆过的代码。\u003C\u002Fli\u003E\u003Cli data-pid=\"VeKHijJi\"\u003E还可以通过 issue 数，star 数等指标来过滤一些质量不高的 repo。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"8ZXLoS3k\"\u003E由于数据量非常大（原始代码数据这块就有 3TB 左右），加上处理和分析工作非常多，所以他们使用了 Databricks 作为框架来处理，有更好的 scalability 和性能，也能引入很多其它数据源，而不仅限于 HuggingFace 上的数据集。\u003C\u002Fp\u003E\u003Ch3\u003ETokenizer\u003C\u002Fh3\u003E\u003Cp data-pid=\"j7TIsZck\"\u003E因为是代码生成任务，所以通用的 tokenizer 可能表现并不好或者性能不佳。很多在回答问题，日常交流或者写文章时用的 token 可能很少在 coding 中用到，所以他们也是自己根据代码数据使用 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fgoogle\u002Fsentencepiece\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ESentencePiece\u003C\u002Fa\u003E 自己训练了一个 BPE tokenizer 词表出来。这个 tokenizer 后续会在训练和 inference 中使用，提升训练推理效率，也能增加模型捕捉到的信息量。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2108d2f4a5790c5802842051cb90d197_b.jpg\" data-size=\"normal\" data-rawwidth=\"2184\" data-rawheight=\"1156\" class=\"origin_image zh-lightbox-thumb\" width=\"2184\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2108d2f4a5790c5802842051cb90d197_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2184&#39; height=&#39;1156&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2184\" data-rawheight=\"1156\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2184\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2108d2f4a5790c5802842051cb90d197_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2108d2f4a5790c5802842051cb90d197_b.jpg\" data-original-token=\"v2-22e9a47b165a8162cb332fb1778db0f6\"\u002F\u003E\u003Cfigcaption\u003E跟 Codex 默认 tokenizer 比较\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003E模型训练\u003C\u002Fh3\u003E\u003Cp data-pid=\"SPcnqw7a\"\u003E训练部分看起来相对比较简单，一方面可能是用了比较成熟的云服务，另一方面也是模型参数量差不多在 30 亿以内，好像并没有提到训练过程中 babysitting 的问题。简单的 yaml 配置通过 CLI 触发就跑起来了。MosiacML 帮你精心挑选了合适的参数，各种自动重启等，非常省心（虽然我没用过）。作者也表示他们之前都是自己搞，后来切换到 MosiacML 提升了很多效率。\u003C\u002Fp\u003E\u003Cp data-pid=\"8hhm0VDu\"\u003E同时他们也用了 WandB 来做训练的 logging 和监控，也是非常标准的做法。\u003C\u002Fp\u003E\u003Ch3\u003E测试与评估\u003C\u002Fh3\u003E\u003Cp data-pid=\"WS7QB1KI\"\u003E前面也提到大模型的测试评估是个很困难的事情。因为是代码相关任务，感觉可以评估的手段会更丰富一些。比如可以实际执行代码来查看结果是否正确，或者通过一些代码分析工具来评估生成的代码的质量等。\u003C\u002Fp\u003E\u003Cp data-pid=\"1plj8uP1\"\u003E他们使用的评估数据集主要是 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fdatasets\u002Fopenai_humaneval\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EHumanEval\u003C\u002Fa\u003E，使用 HuggingFace 的 code inference tool 来快速执行测试。像 Python 这类相对比较好搞定，但对于其它语言和场景，例如一些前端界面的代码就不是很容易做测试验证。\u003C\u002Fp\u003E\u003Cp data-pid=\"rDgpajst\"\u003E另外也需要注意测试用例最好是模型训练时没有见过的，避免 overfitting\u002Fmemorization。还有很重要的一点是这些用例要与真实的使用场景尽可能一致，比如是不是跟补全场景是类似的输入和输出形式，测试用例与真实用户的使用场景是否一致等。\u003C\u002Fp\u003E\u003Ch3\u003E部署\u003C\u002Fh3\u003E\u003Cp data-pid=\"9-AxReSP\"\u003E他们使用了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002FNVIDIA\u002FFasterTransformer\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EFastTransformer\u003C\u002Fa\u003E 和 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Ftriton-inference-server\u002Fserver\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ETriton\u003C\u002Fa\u003E 来做 inference 的部署，以提供更好的性能和吞吐。例如像 Triton 中支持部署多个模型 instance 的部署和并发执行，能够做请求动态 batching 等，看起来非常的方便。不过之前也听说当前训练框架跟 inference 框架还是有一些“隔阂”，如果在训练中用了一些特殊的操作，可能在 inference 框架中不一定支持，需要格外注意。\u003C\u002Fp\u003E\u003Cp data-pid=\"FPt8yKKD\"\u003E在 auto-scaling 方面，他们复用了 Replit 现有的 k8s 基础设施。不过还是有很多特殊的挑战，例如模型的规模要大很多，对 GPU 也有特殊的要求，还要处理一些云上的区域出现 GPU“缺货”的问题等。\u003C\u002Fp\u003E\u003Ch3\u003E经验教训\u003C\u002Fh3\u003E\u003Cp data-pid=\"mKCDxKYO\"\u003E最最重要的还是“以数据为中心”，从前面架构图也可以看出，数据 pipeline 这块所占的内容也是最多的，需要有一个稳定的流程来支持快速迭代实验。另外过程中要尽可能深入去了解你的训练数据。看来 80%时间花在数据上仍然是个不变的真理。\u003C\u002Fp\u003E\u003Cp data-pid=\"PbY2S3s5\"\u003E模型评估也是一个开放性的问题，作者认为目前更多是一门艺术而不是精确的科学。即使有 HumanEval 这样的评测数据集，也只是一种参考，还是需要真正把模型部署到实际使用场景中，让最终用户来测试体验模型的效果、延迟等，并尽可能全面地收集用户反馈、系统监控数据。这一点 GitHub Copilot 的 telemetry 就做得很好，值得参考学习。\u003C\u002Fp\u003E\u003Cp data-pid=\"42_nnPin\"\u003E协作也是很重要的一点，像之前 OpenAI 也分享过他们的团队设置，不光是个软件系统工程，也是对组织设计的考验。作者举例说一些新的模型训练特性可能在 FastTransformer 中不支持，就会大大提升 inference 的延迟，所以需要各个团队中的同事一起协同来避免此类问题。\u003C\u002Fp\u003E\u003Ch3\u003E招聘环节\u003C\u002Fh3\u003E\u003Cp data-pid=\"uO0nQ4DW\"\u003E最后作者还聊了聊什么才是一个好的 LLM 工程师，感觉也是个各种交叉技能的“稀有物种”。既要懂 research，engineering 的 sense 也不能差；数据探索清洗要深入且有耐心，又擅长各种软件工程的实践……大概意思就是我们这里项目有趣，挑战又大，赶紧来一起做一番大事业吧 :)\u003C\u002Fp\u003E\u003Ch2\u003EAgents\u003C\u002Fh2\u003E\u003Cp data-pid=\"2qOlPoQV\"\u003ELangChain 的创始人 Chase 来聊了聊近期超火的 Agents。这部分提到几个工作正好跟之前我写的 \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F622947810\" class=\"internal\"\u003EAutoGPT 与 LLM Agent 解析\u003C\u002Fa\u003E 这篇文章完全重合，这里就简单介绍一下。\u003C\u002Fp\u003E\u003Ch3\u003E概念\u003C\u002Fh3\u003E\u003Cp data-pid=\"gSLvcBFa\"\u003EAgent 的核心是把 LLM 当作一个“推理引擎”，赋予其各类外部工具以及自身的长期记忆，能够让其自行生成灵活的决策步骤，完成复杂任务。而像 LangChain 里的 Chain 的概念则是由人工来定义一套确定的步骤来让 LLM 执行，更像是把 LLM 当成了一种强大的多任务工具。\u003C\u002Fp\u003E\u003Cp data-pid=\"-z_jxQ3q\"\u003E典型的 agent 模式如 ReAct 中，一般的逻辑是：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"Y-gpfGjb\"\u003E由 LLM 选择工具。\u003C\u002Fli\u003E\u003Cli data-pid=\"P1NLza2I\"\u003E执行工具后再将输出返回给 LLM。\u003C\u002Fli\u003E\u003Cli data-pid=\"TohNt87D\"\u003E不断重复上述过程，直到达到停止条件（一般也是 LLM 自己决定或者通过一些规则设定）。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch3\u003E挑战\u003C\u002Fh3\u003E\u003Cp data-pid=\"R4B7TtOC\"\u003E作者列举了当前 agent 的一系列挑战，应该也是深入看过很多 agent 应用得出的结论。\u003C\u002Fp\u003E\u003Cp data-pid=\"EGurvUQ5\"\u003E\u003Cb\u003E如何让 agent 选择合适的工具\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"uTWhkuJt\"\u003E常规的做法是通过指令，工具描述来引导。此外在复杂场景下：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"uZEVgLTg\"\u003E当工具多了之后也可以针对工具做 retrieve。\u003C\u002Fli\u003E\u003Cli data-pid=\"a8irxebr\"\u003E可以 retrieve 相关示例来做 few-shot prompt。\u003C\u002Fli\u003E\u003Cli data-pid=\"_iuORpS3\"\u003E也可以进一步 fine tune 特定模型，例如之前的 Toolformer。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp data-pid=\"FhczbQQt\"\u003E近期正好有篇来自伯克利和微软的工作 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F2305.15334.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EGorilla\u003C\u002Fa\u003E，正好是结合了 retrieval，fine tune 等几种方法，在 LLaMA 模型的基础上做到了接近 GPT-4 的效果，值得借鉴。\u003C\u002Fp\u003E\u003Cp data-pid=\"URERbySk\"\u003E\u003Cb\u003E不必要的工具使用\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"ja7tIQH3\"\u003E例如用户只是跟模型闲聊时，可能就没必要都使用工具了。除了在 prompt 里进行说明外，Chase 还给了个很有意思的想法，就是把“Human Input”也写成一种工具，让模型来主动发起对人类的提问。具体可以参考 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fpython.langchain.com\u002Fen\u002Flatest\u002Fmodules\u002Fagents\u002Ftools\u002Fexamples\u002Fhuman_tools.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELangChain 文档中的例子\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp data-pid=\"YDeJQcI8\"\u003E\u003Cb\u003EAgent 返回的格式不稳定\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"LoMvhku8\"\u003E在程序使用工具时，需要 agent 按照特定格式返回内容，以便提取其中的工具操作信息。但 LLM 的随机性导致这部分可能会出现很多不稳定的情况。这里常见的做法是让 LLM 按照 json 这类常见的 schema 来返回，一般稳定性会高一些（相比“Action:”这种）。此外自动修复重试也很实用，可以利用 LangChain 里的 output parsers 来帮助完成。\u003C\u002Fp\u003E\u003Cp data-pid=\"i7pouPJc\"\u003E\u003Cb\u003E记住之前的操作，避免重复\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"c-ZPKHxT\"\u003E如果没有长期记忆，agent 很容易“忘掉”之前做过的操作，导致不停在原地打转或者效率低下。常见的解决办法还是通过 retrieval 结合近期操作记录来克服，例如 AutoGPT 中就用了类似的手段。\u003C\u002Fp\u003E\u003Cp data-pid=\"HNWc0AMI\"\u003E\u003Cb\u003E处理超长的 observation\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"dQE7NJ1r\"\u003E有些工具生成的 observation 很长，超出了 context length 的限制，这时候就需要用一些工具从中提取有用信息，或者放到外部存储中再借助 retrieval 来使用。\u003C\u002Fp\u003E\u003Cp data-pid=\"bOUu2EvB\"\u003E这里引出很有趣的一点是我们未来在考虑 API 设计时也需要主动拥抱 LLM 的特性。除了有清晰的接口设计和说明，能让 LLM 更好地生成调用动作外，调用结果是否精简也很重要，可以避免上述 observation 过长的问题。\u003C\u002Fp\u003E\u003Cp data-pid=\"1r3bofoG\"\u003E\u003Cb\u003E专注于目标\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"89-KM-fy\"\u003E像 AutoGPT 这类尝试中往往任务执行链路很长，agent 很容易做着做着就“迷失了目标”。简单的做法是在 prompt 结尾处再把目标加上，引起 agent 的注意。另外像 BabyAGI，HuggingGPT 这种把 planning 和 execution 分开的做法也是很有用。拆分的比较细的任务往往步骤比较短，也不容易丢失目标。\u003C\u002Fp\u003E\u003Cp data-pid=\"kmIU8F3v\"\u003E\u003Cb\u003E结果评估\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"lzLOZdB6\"\u003E评估 agent 也是比较困难的。除了评估最终结果是否正确外，我们还可以做过程的细化评估，例如：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"wIgxH6ei\"\u003E选择的中间步骤是否正确。\u003C\u002Fli\u003E\u003Cli data-pid=\"6WcgPG52\"\u003E生成 action 的 input 是否正确。\u003C\u002Fli\u003E\u003Cli data-pid=\"qyB5H_yh\"\u003E生成的步骤序列是否合理高效。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch3\u003E记忆系统\u003C\u002Fh3\u003E\u003Cp data-pid=\"YO4PFKo-\"\u003E前面的挑战部分可以看到有很多都是跟 retrieval 相关，而且从 agent 的本质出发，其最大的优势之一也在于能够记住之前的操作，成为一个可以不断自我演进的智能体，或者实现不同用户的个性化应答，而不是固定的逻辑链路。所以 memory 这块的处理显得越来越重要。\u003C\u002Fp\u003E\u003Cp data-pid=\"DhcaG5Le\"\u003EAgent 的记忆主要是跟用户的交互和跟工具的交互，当然一些项目中也基于这两类基础信息衍生出了很多复杂操作，例如 LangChain 中类似知识图谱的记忆模式；LlamaIndex 中复杂的外部记忆索引设计；Generative Agents 中的“自我反思”环节等等。\u003C\u002Fp\u003E\u003Ch3\u003EAgent 项目速评\u003C\u002Fh3\u003E\u003Cul\u003E\u003Cli data-pid=\"crNXhljU\"\u003EAutoGPT：实现的任务比起 ReAct 中的例子来说会更发散更需要探索，因此步骤也更长。所以需要通过外部记忆系统来获取 agent 之前的操作步骤信息等。\u003C\u002Fli\u003E\u003Cli data-pid=\"4Zv3kcAy\"\u003EBabyAGI：将计划和执行分开，在较长任务执行过程中保持 agent 的目标感。\u003C\u002Fli\u003E\u003Cli data-pid=\"o4oD_70w\"\u003ECamel：给多个 agent 赋予不同的人格、记忆等，模拟 agent 之间的交互。\u003C\u002Fli\u003E\u003Cli data-pid=\"SfiIwIZM\"\u003EGenerative Agents：更复杂的 memory retrieval 机制。自我反思并更新系统状态。或许未来还可以自己触发 fine tune 更新模型参数？\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch2\u003EFireside Chat with OpenAI VP Product\u003C\u002Fh2\u003E\u003Cp data-pid=\"WlNWooXv\"\u003E跟 Peter Welinder 的一个简短访谈。很多信息可能关注 OpenAI 的同学应该都比较了解了，例如他们早年在强化学习方面的探索，包括打游戏，玩魔方之类，后来大力押注了语言模型方向。从产品角度有几个故事还挺有意思：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"3XA2TOYa\"\u003E他们在有了 GPT-3 之后也不知道有什么产品场景可以应用，一般来说拿着技术找场景并不是一个好主意，但对一家以 AGI 为目标的研究型公司来说也可以理解。后来他们干脆就开放 API，看看用户是不是能自己找到一些有趣的应用场景来。\u003C\u002Fli\u003E\u003Cli data-pid=\"K-UZNbN5\"\u003E在 GPT-3 推出时他们就想过做个 Chatbot 推出来，但鉴于之前微软，谷歌等公司的失败尝试，他们觉得技术还不成熟就没有这么做。\u003C\u002Fli\u003E\u003Cli data-pid=\"axKUipw2\"\u003E推出 ChatGPT 之前大家也很忐忑，不少人觉得也会跟以往的产品一样被发现一些严重的回复问题导致很快下线。而且他们当时找了 1000 来个用户内测，也没收到特别正面的反馈。但上线之后一方面模型表现的确可以，另外大家可能迅速挖掘出了很多实用场景，导致很快爆火全球。\u003C\u002Fli\u003E\u003Cli data-pid=\"VDiOEIgO\"\u003EChatGPT 的成功中是交互方式起到的因素更大还是模型因素更大？其实他们在之前开放 API 时就发现有很多人会在 playground 模拟交互来实现一些场景，聊天这个形式加上免费注册开放大大降低了大家的尝试门槛，所以起到了至关重要的作用。当然 instruct tuning，RLHF 对齐这些也是很重要的保障。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch2\u003E近期工作 highlight\u003C\u002Fh2\u003E\u003Cp data-pid=\"3XnIoq9o\"\u003E最近还有不少激动人心的优秀工作，也一并在这里分享一下。\u003C\u002Fp\u003E\u003Ch3\u003EGorilla\u003C\u002Fh3\u003E\u003Cp data-pid=\"PmPgfgtv\"\u003E前面讲 agent 的环节已经提到了这个工作，相比之前的 Toolformer，一大进步是 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002FShishirPatil\u002Fgorilla\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E开源了代码\u003C\u002Fa\u003E，不过目前（2023.05.28）还没放出比较关键的训练这块的内容。Gorilla 主要实现的是可以通过用户提供的 API 文档，自己 fine tune 出一个模型，然后可以接受用户的任务指令，由这个模型生成一系列 API 调用代码实现任务。看了下论文，具体的做法是：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d97c085b3ac31861b11af14a86a0ea4_b.jpg\" data-size=\"normal\" data-rawwidth=\"2198\" data-rawheight=\"1344\" class=\"origin_image zh-lightbox-thumb\" width=\"2198\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d97c085b3ac31861b11af14a86a0ea4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2198&#39; height=&#39;1344&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2198\" data-rawheight=\"1344\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2198\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d97c085b3ac31861b11af14a86a0ea4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d97c085b3ac31861b11af14a86a0ea4_b.jpg\" data-original-token=\"v2-542a1f4c01789b684450f0dc83361e29\"\u002F\u003E\u003Cfigcaption\u003EGorilla 的 workflow\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"y5RrwJiV\"\u003E通过 API 文档，向 GPT-4 提问，让它针对每个 API 生成若干个任务指令来，而且还要求这些指令里不要显示的提到 API 的名字。这些 self-instruct 生成的指令与 API 调用对就形成了模型 fine tune 的数据集。\u003C\u002Fli\u003E\u003Cli data-pid=\"OKnlkcT_\"\u003E在 fine tune 过程中，他们也“植入”了 retrieval 的信息，让模型明白后续在使用时可以结合相关文档信息来生成 API 调用的代码。不过他们发现这种增强方式并不一定总是有效，在当前 LlamaIndex 这类 retrieval 表现下很多反而会起到负面作用。\u003C\u002Fli\u003E\u003Cli data-pid=\"hE4wl9Uc\"\u003E在 inference 时，模型可以按需要启用 retrieval。从文中的结果来看，他们测试的几个库不使用 retrieval 的 zero-shot 效果反而更好。当然 retrieval 在 API 文档持续变化的情况下可能会有优势。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1fba5b5e0f1c6b2bd370784ac4f4eef1_b.jpg\" data-size=\"normal\" data-rawwidth=\"2672\" data-rawheight=\"1432\" class=\"origin_image zh-lightbox-thumb\" width=\"2672\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1fba5b5e0f1c6b2bd370784ac4f4eef1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2672&#39; height=&#39;1432&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2672\" data-rawheight=\"1432\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2672\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1fba5b5e0f1c6b2bd370784ac4f4eef1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1fba5b5e0f1c6b2bd370784ac4f4eef1_b.jpg\" data-original-token=\"v2-60b3ccd29f8bb8c9ead95bcb18cbd229\"\u002F\u003E\u003Cfigcaption\u003EZero-shot 的表现更好\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"ISyOKPlF\"\u003E总体来说还是非常有意思的一个工作，让 LLM 来写代码真的是一个拥有无限想象力的方向。\u003C\u002Fp\u003E\u003Ch3\u003EVoyager\u003C\u002Fh3\u003E\u003Cp data-pid=\"pfJX5I8h\"\u003E又是一篇探索 agent 方向的重磅文章。之前我们就介绍过他们团队推出的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fminedojo.org\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMineDojo\u003C\u002Fa\u003E 项目，当时还以为下一步应该会搞个多模态大模型出来，或者在 LLM 的基础上去更多使用 RL 方式来训练具有“世界知识”，能够做复杂推理玩游戏的 agent。没想到这次发的文章却是“无梯度更新”的路线，而且效果也是非常惊艳，有些出人意料。\u003C\u002Fp\u003E\u003Cp data-pid=\"mRC9JEIu\"\u003E这篇工作总体实现的效果是让 GPT 在不需要任何传统 fine tune 更新参数的情况下，通过 in-context learning 的方式逐渐学会各种“技能”，探索 minecraft 这个虚拟世界。这个 agent 的形成玩游戏的动作主要就是“执行代码”，而其自我学习提升过程就是不断地去写代码，执行获取反馈，调试改进，以及 retrieve 之前写的代码。从整体实现效果来看，比之前的各种 agent 方法（ReAct，AutoGPT 等）强多了。更可贵的是项目代码也全公开了，非常值得深入研究学习。\u003C\u002Fp\u003E\u003Cp data-pid=\"Bf4763SZ\"\u003E整体的项目结构如下：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d7c3395c32986b8e64fdbcbccff69fa_b.jpg\" data-size=\"normal\" data-rawwidth=\"2696\" data-rawheight=\"1186\" class=\"origin_image zh-lightbox-thumb\" width=\"2696\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d7c3395c32986b8e64fdbcbccff69fa_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2696&#39; height=&#39;1186&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2696\" data-rawheight=\"1186\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2696\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d7c3395c32986b8e64fdbcbccff69fa_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d7c3395c32986b8e64fdbcbccff69fa_b.jpg\" data-original-token=\"v2-283650e936522f1a8657270b49393d5f\"\u002F\u003E\u003Cfigcaption\u003EVoyager 的架构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"YsyIpz_i\"\u003E几个模块的作用分别是：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"mIZbM_ki\"\u003E中间的 iterative prompting 模块中，agent 会根据游戏环境状态，代码执行报错，当前任务等信息，输出模型的 reasoning，计划和具体的代码，并可以不断 refine 优化达到正确的代码。\u003C\u002Fli\u003E\u003Cli data-pid=\"67wxFP-0\"\u003E执行成功的代码程序，会向量化后存到 skill library 中，后续在写代码过程中可以根据 context 来 retrieve。都会写 library 了有没有，离失业又近了一步。\u003C\u002Fli\u003E\u003Cli data-pid=\"ABpBhMll\"\u003E最左边的模块也是把当前探索状态发给 agent，并让其以最大化探索空间为目标自己挖掘新的任务目标。我琢磨着让 GPT 做科研是不是也不远了。\u003C\u002Fli\u003E\u003Cli data-pid=\"O1XniXmC\"\u003E除了全自动化执行，作者们也在 critic 和 curriculum 两个模块引入了可选的人工介入机制，帮助 agent 更好地处理程序错误，以及引导他们一步步做更复杂的任务。Human as a tool 可能也会成为一种流行模式。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f0b779c2a4baa20156b1515cac3ba263_b.jpg\" data-size=\"normal\" data-rawwidth=\"2676\" data-rawheight=\"1284\" class=\"origin_image zh-lightbox-thumb\" width=\"2676\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f0b779c2a4baa20156b1515cac3ba263_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2676&#39; height=&#39;1284&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2676\" data-rawheight=\"1284\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2676\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f0b779c2a4baa20156b1515cac3ba263_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f0b779c2a4baa20156b1515cac3ba263_b.jpg\" data-original-token=\"v2-484b503a14cb379e17e057ddac6c8ceb\"\u002F\u003E\u003Cfigcaption\u003ESkill library 的实现\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"zDb7oMqs\"\u003E这几个模块结合起来就达到了上面的效果，看起来都没有用 MineDojo 里收集的额外数据，也不用做任何训练，非常神奇。\u003C\u002Fp\u003E\u003Cp data-pid=\"rVxHlo-i\"\u003E在 limitation 环节，作者提到了 agent 会出现无法实现正确的代码以及 hallucination 的问题，未来或许能通过 GPT 自身能力的提升或者通过微调开源 LLM 来克服。我的一个感觉是好像整个项目还没有把 minecraft 相关的文档以及其它用户经验分享利用起来，这些知识应该可以减少一些出错和 hallucination 的问题？\u003C\u002Fp\u003E\u003Cp data-pid=\"7aNUyMdQ\"\u003E还有一个思考是，这类无梯度架构的能力边界会在哪里？有哪些效果是必须通过模型的参数训练更新才能达到的？目前看起来很多 fine tune 提供的优势好像主要是效率角度的提升。例如无梯度架构的模型每次都要从小本本里去翻找相关记忆，但训练过的模型可以直接从参数中找出 context；或者本来要用工具去跑一下代码才知道结果，训练过的模型可以直接给出结果；或者原先的任务做的不熟练，经常做错需要订正，训练过后就能一次做对了。是否有无梯度架构完全做不了的，而一定要用数据训练后才能做到的事情（例如扩展词表）？\u003C\u002Fp\u003E\u003Cp data-pid=\"pf8iXIPz\"\u003E不过即使从提升效率，增加准确性的角度来看，这两者也是可以考虑结合起来的。比如 Generative Agents 里就有“自我反思”的步骤来沉淀重要的事件信息。我们是不是也可以延展一下，把“自我反思”改成调用自我 fine tune 的工具。其中的训练数据就可以根据上面提到的无梯度架构的局限性角度出发，将出错最多的代码，retrieve 频率最高的信息，调用最频繁的工具及其结果，人工介入最多的 workflow，以及模型自认为最重要的信息等等，都作为训练数据，来训练一个 fine tune 的模型。这样就可以在无梯度架构的基础上，通过 fine tune 来进一步提升 agent 的进化。\u003C\u002Fp\u003E\u003Ch3\u003ETree of Thought\u003C\u002Fh3\u003E\u003Cp data-pid=\"Int9JhcG\"\u003EReAct 作者“尧舜禹”大佬的新作，前两天又刷屏了。作者延展了 chain-of-thought 的思路，模拟人类在解决复杂问题时的提出多个可能方向，思考深挖，根据可行性选择路径，碰到问题时回溯到之前其它想法等思维过程，构建起了一棵自主探索生长的“思维树”。在算 24 点等一系列复杂的任务上，tree-of-thought 的表现都大大超过了之前的 chain-of-thought。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f2992e642e6433065b8c6263a0a7416_b.jpg\" data-size=\"normal\" data-rawwidth=\"2716\" data-rawheight=\"1322\" class=\"origin_image zh-lightbox-thumb\" width=\"2716\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f2992e642e6433065b8c6263a0a7416_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2716&#39; height=&#39;1322&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2716\" data-rawheight=\"1322\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2716\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f2992e642e6433065b8c6263a0a7416_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f2992e642e6433065b8c6263a0a7416_b.jpg\" data-original-token=\"v2-e54cfa1db31cbfc5476b9f5ada42e6eb\"\u002F\u003E\u003Cfigcaption\u003E直观理解 tree-of-thought\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"f3XzuI8x\"\u003E作者也将代码公开在了 GitHub 上，感兴趣的同学可以深入学习研究。个人看下来感觉目前构建 tree 的 proposal\u002Fvalue prompt 需要针对具体任务来设计，需要比较深入的领域知识。不知是否有可能通过更加自动化的方式，结合 LLM 和相关外部工具来自动生成这些 prompt，那样或许会有更广的应用场景。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb1c8a1bb67df930ba5cb459bc29096d_b.jpg\" data-size=\"normal\" data-rawwidth=\"2200\" data-rawheight=\"904\" class=\"origin_image zh-lightbox-thumb\" width=\"2200\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb1c8a1bb67df930ba5cb459bc29096d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2200&#39; height=&#39;904&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2200\" data-rawheight=\"904\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2200\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb1c8a1bb67df930ba5cb459bc29096d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb1c8a1bb67df930ba5cb459bc29096d_b.jpg\" data-original-token=\"v2-d318fb653d9832812746838b490eb766\"\u002F\u003E\u003Cfigcaption\u003EBFS ToT 的核心逻辑\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"Nj7eXwYq\"\u003E这个工作的设计思路还是挺有趣的，有种把 LLM 作为 CPU，在上面跑了更高级的树搜索算法的感觉。很多经典算法都是这类对人类系统性思考解决某类问题的高度抽象，或许未来会有更多这个方向上的探索，甚至真的把 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Flmql.ai\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EPrompt 设计成一种编程语言\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Ch3\u003EStatus of GPT\u003C\u002Fh3\u003E\u003Cp data-pid=\"e9gvOBtc\"\u003E最后再推荐一下推特第一人工智能网红 Karpathy 在微软 Build 大会上的演讲，如果你没怎么跟进 LLM 方面的进展，那么这个演讲绝对是最好的总结视频之一。表述非常清晰易懂，覆盖了各类主要进展，有细节也有 intuition，真是不可多得的佳作。个人感觉收获比较多的几个点包括：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"4OChEqma\"\u003E为什么需要 RLHF，直观来看就是效果更好。一个可能的原因是要生成一个高质量的文本，比判别一下几个文本质量的好坏要难得多。“我虽然不会写，但点评下别人的作品还是容易的” :)\u003C\u002Fli\u003E\u003Cli data-pid=\"U__C9Q1m\"\u003E模型 fine tune 会损失多样性，这个之前 Karpathy 也在推特上分享过。包括之前的“灾难性遗忘”感觉也没有很好的解决办法。\u003C\u002Fli\u003E\u003Cli data-pid=\"odFoFTxk\"\u003E人工生成的文本跟 LLM 生成文本的比较非常精彩，一定要看。人类在产出最终文本前其实涉及了很多中间过程，可能包括问题拆解，资料查阅，反思，撰写，润色等等，而模型没有各种内在的心理活动，它的所有思考过程都需要一个一个 token 显示地生成出来。所以上面看到的很多工作也都是利用 prompting 和模型生成的交互来重建人类的 system 2 思考过程。\u003C\u002Fli\u003E\u003Cli data-pid=\"SNvMC-kd\"\u003ELLM 只想模仿，不想成功。所以提醒一下模型模仿高智商的思考者很重要，让它记得需要完成的任务目标也很重要。举例：Let&#39;s work this out in a step by step way to be sure we have the right answer。\u003C\u002Fli\u003E\u003Cli data-pid=\"pu570Kg8\"\u003E提到了微软的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fmicrosoft\u002Fguidance\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EGuidance\u003C\u002Fa\u003E 项目，实现了 constrained prompting，让模型能够更稳定地按照特定的格式进行输出。\u003C\u002Fli\u003E\u003Cli data-pid=\"yKnT1KB5\"\u003EFine tune 方面提到了各种 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fhuggingface\u002Fpeft\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EPEFT 技术\u003C\u002Fa\u003E，这方面最近最火热的应该是这个 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fartidoro\u002Fqlora\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EQLoRA\u003C\u002Fa\u003E，可以在 48GB 显存上 fine tune 一个 65B 的模型，着实惊人。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8e01570b32feb57039900d3e7f708376_b.jpg\" data-size=\"normal\" data-rawwidth=\"3882\" data-rawheight=\"2018\" class=\"origin_image zh-lightbox-thumb\" width=\"3882\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8e01570b32feb57039900d3e7f708376_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;3882&#39; height=&#39;2018&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"3882\" data-rawheight=\"2018\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3882\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8e01570b32feb57039900d3e7f708376_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8e01570b32feb57039900d3e7f708376_b.jpg\" data-original-token=\"v2-936dd933e1edfeaac8910bcfe1b4a1ae\"\u002F\u003E\u003Cfigcaption\u003E第 23 分钟左右的精华部分\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F26797383","type":"topic","id":"26797383","name":"LLM（大型语言模型）"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F27428077","type":"topic","id":"27428077","name":"Prompt工程"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19580199","type":"topic","id":"19580199","name":"信息检索"}],"voteupCount":194,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"},"commentCount":6,"contributions":[{"id":45413648,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":709,"isNormal":true,"status":0,"activityToppingInfo":{"state":"untopped"},"shareText":"LLM 全栈开发指南补遗 - 来自知乎专栏「RandomGenerator」，作者: 字节 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F633033220 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":56,"hasColumn":true,"republishers":[],"isNewLinkCard":true,"emojiReaction":{"cryFaceCount":0,"cryFaceHasSet":false,"hugCount":0,"hugHasSet":false,"likeCount":56,"likeHasSet":false,"onlookerCount":0,"onlookerHasSet":false},"abParam":{"qaHiddenVoteup":"1","rsInterest1":"1"},"attachedInfo":"kgIkCgkyMjg4MDU1NDUSCTYzMzAzMzIyMBgHIgpJTUFHRV9URVhU","shareGuide":{"hasPositiveBubble":false,"hasTimeBubble":false,"hitShareGuideCluster":false},"settings":{"tableOfContents":{"enabled":true}},"canReference":false,"reactionInstruction":{}}},"columns":{"zijie0":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"zvideos":{},"zvideoContributions":{},"briefs":{},"eduCourses":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"ab":{"config":{"params":[{"id":"ques_follow_con","type":"Int","value":"0","chainId":"_gene_","layerId":"ques_follow_con","key":3320}],"experiments":[],"chains":[],"encodedParams":"Cgo7ArcDiwUnB\u002FgMEgUAAAAAAA=="},"triggers":{}},"abV2":{"config":{"paramMap":{"pm_new_task":{"value":"0"},"in_editor_title":{"value":"0"},"ws_platform_new":{"value":"0"}},"abMap":{}},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":true,"Android":false,"iOS":true,"isAppleDevice":true,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (iPhone; CPU iPhone OS 16_4 like Mac OS X) AppleWebKit\u002F605.1.15 (KHTML, like Gecko) Mobile\u002F15E148"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F633033220","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F633033220","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"oppoSearch":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false,"huaweiSearch":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"","xUDId":"AFBXnGGr8BaPTq1NbGXn_ppp0RPq8BY0Jxo=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"武汉","countryName":"中国","regionName":"湖北","countryCode":"CN"},"logged":false,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0}},"recommend":{"recommendTimes":{}}},"explore":{},"levelUpperLimit":10,"mcn":{},"mcnManage":{},"tasks":{},"announcement":{},"creatorsRecommendInfo":{}},"creators":{"common":{"applyStatus":{},"rightsStatus":{}},"bayesDomains":{"status":{},"options":{"topDomains":null,"allDomains":null,"editable":0},"contents":null},"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"faq":{"tabs":[],"article":{}},"knowledgeIncome":{},"safeguardRights":{},"analytics":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"account":{"growthLevel":{}},"KMResource":{},"training":{},"ToolsQuestion":{"goodatTopics":[]},"ToolsHotspot":{"domains":[]},"ToolsRecommend":{},"ToolsCustomPromotion":{"itemLists":{},"baseInfo":{}},"ToolsSearchQuestion":{},"editorSetting":{},"MCNManage":{},"knowledgeTasks":{},"incomeAnalysis":{"income":{"aggregation":{}}},"creationManage":{"editModal":{"status":false}},"activity":{},"announcement":{},"home":{"currentCreatorUrlToken":null,"rights":[],"newRights":[],"scoreInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"bannerList":[],"recentlyCreated":[]},"videoSupport":{"textBenefit":{}},"videoDistribution":{}},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"concernedUpvoters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"zijie0"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false},"linkCardLimit":0},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]},"adPromotion":{"answer":{},"article":{}}},"fetchHost":"www.zhihu.com","subAppName":"column","spanName":"Post","canaryConfig":{"test_canary":"0","use_new_player":"1","player_vendor":"1","use_hevc":"1","upload_use_signature":"1","use_backdrop_blur":"1","article_title_imagex":"0","play_station":"1"}}</script><script crossorigin="" src="https://static.zhihu.com/heifetz/vendor.5f3e51e68d56265eb628.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react@17.0.2/umd/react.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom-server.browser.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/runtime.app.560046624f28621b8b9f.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-29107295.app.a7b6d98ed785438234bf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-79b5cf47.app.f16b5bf4c3cff85007a0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-330004dc.app.1a4905d34b3df3f09dff.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-0e5ce61e.app.121a4e979ab55ff600b2.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-83b0f42f.app.6f9779781d0af52a0ddf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-2ec050f6.app.c4cf2528b321f02e9fa0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/680.app.f3c9d9e614b550bbff65.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.app.b9bcd5e5f805cd0c6068.js"></script><script defer="" src="https://static.zhihu.com/event/wza/4613/aria.js?appid=c5ddb58ead4528987249d96fb27246ab" id="ariascripts" wapforceoldfixed="false" loaddata="false" callbackexit="RQ_HALW_QDPH" callback="RQ_VWDUW_QDPH"></script><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script crossorigin="" src="https://unpkg.zhimg.com/za-js-sdk@4.13.0/dist/zap.js"></script><div><div style="display: none;"><i>想来知乎工作？请发送邮件到 jobs@zhihu.com</i></div></div><script src="https://zz.bdstatic.com/linksubmit/push.js"></script><script crossorigin="" src="https://unpkg.zhimg.com/@cfe/emoticon@1.2.4/lib/emoticon.js"></script></body></html>