<html lang="zh" data-ios="true" class="itcauecng" data-theme="light" data-rh="data-theme"><head><meta charset="utf-8"><title>AutoGPT与LLM Agent解析 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0,viewport-fit=cover"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=10,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-rh="true" name="keywords" content="LLM,Prompt Engineer,强化学习 (Reinforcement Learning)"><meta data-rh="true" name="description" content="前两周 AutoGPT，BabyAGI 等项目异常火爆，周末也正好花了点时间来看了下这些 AI agent 类项目的代码，写篇文章来总结一下对于当前这类项目进展的技术角度认识和思考，与大家一同交流。 从语言理解到任务执行之前…"><meta data-rh="true" property="og:title" content="AutoGPT与LLM Agent解析"><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/622947810"><meta data-rh="true" property="og:description" content="前两周 AutoGPT，BabyAGI 等项目异常火爆，周末也正好花了点时间来看了下这些 AI agent 类项目的代码，写篇文章来总结一下对于当前这类项目进展的技术角度认识和思考，与大家一同交流。 从语言理解到任务执行之前…"><meta data-rh="true" property="og:image" content="https://pica.zhimg.com/v2-1e36a1bfc750cd1b5acd76cb211b95e7_720w.jpg?source=172ae18b"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="og:site_name" content="知乎专栏"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png" sizes="152x152"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.d5793cac.png" sizes="120x120"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7abf3393.png" sizes="76x76"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.362a8eac.png" sizes="60x60"><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"><link rel="dns-prefetch" href="//static.zhimg.com"><link rel="dns-prefetch" href="//pica.zhimg.com"><link rel="dns-prefetch" href="//picx.zhimg.com"><link rel="dns-prefetch" href="//pic1.zhimg.com"><link rel="dns-prefetch" href="//pic2.zhimg.com"><link rel="dns-prefetch" href="//pic3.zhimg.com"><link rel="dns-prefetch" href="//pic4.zhimg.com"><link rel="dns-prefetch" href="//static.zhihu.com"><script nonce="10aa7cd2-0587-48c5-9dbd-fe9a92fdd4d2" data-web-reporter-config="{&quot;platform&quot;:&quot;web&quot;,&quot;project&quot;:&quot;heifetz&quot;}">!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports):"function"==typeof define&&define.amd?define(["exports"],t):t((e=e||self).webReporter={})}(this,function(e){"use strict";var t={},n=!1,o=function(){var e,o,r,a,i;return n||(e=document.querySelector("script[data-web-reporter-config]"),o=e&&e.dataset.webReporterConfig||"{}",r=JSON.parse(o),a=r.platform,i=r.project,t={platform:a,project:i},n=!0),t};function r(e){return a(function(){return localStorage.getItem(e)})()}function a(e){return function(){try{return e.apply(void 0,arguments)}catch(e){}}}var i=a(function(e,t){var n={platform:"web",project:o().project,clientTimestamp:+new Date};!function(e,t,n){"1"===r("weber:logenabled")&&console.log("[web-reporter]%o",{type:e,base:t,data:n})}(e,n,t),function(e,t){var n=btoa(JSON.stringify(t));if("undefined"!=typeof Blob&&window.navigator&&window.navigator.sendBeacon){var o=new Blob([n],{type:"text/plain"});navigator.sendBeacon(e,o)}else{var r=new XMLHttpRequest;r.open("POST",e),r.withCredentials=!1,r.setRequestHeader("Content-Type","text/plain;charset=UTF-8"),r.send(n)}}(r("weber:api")||"https://apm.zhihu.com/collector/web_json",{type:e,base:n,data:t})});e.report=i,Object.defineProperty(e,"__esModule",{value:!0})});
</script><link href="https://static.zhihu.com/heifetz/680.216a26f4.bc3dd4670546193a4781.css" crossorigin="" rel="stylesheet"><link href="https://static.zhihu.com/heifetz/column.216a26f4.3326da597f7431c1ea67.css" crossorigin="" rel="stylesheet"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/GoodsRecommendGoodsCardList.216a26f4.d95ce79191cdf8d7ac28.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="https://static.zhihu.com/heifetz/3280.216a26f4.8bfc371d6d7cfdc6aeec.css" crossorigin="anonymous"><script nonce="10aa7cd2-0587-48c5-9dbd-fe9a92fdd4d2">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"824-bcf32e16\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script><script crossorigin="anonymous" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;824-bcf32e16&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrorsPreset&quot;:&quot;ReactApp&quot;,&quot;tags&quot;:{&quot;app_name&quot;:&quot;heifetz&quot;}}" src="https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js"></script><style data-emotion-css="uzm3ri">.css-uzm3ri{position:fixed;top:0;right:0;left:0;z-index:101;display:none;height:2px;pointer-events:none;background:#056DE8;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}</style><style data-emotion-css="15ro776">.css-15ro776{margin-right:4px;}</style><style data-emotion-css="183aq3r">.css-183aq3r{border-radius:24px;padding:0 15px;font-size:13px;line-height:28px;-webkit-flex:none;-ms-flex:none;flex:none;}</style><style data-emotion-css="1ie3c6f">.css-1ie3c6f{fill:#999999;margin:0 10px;}</style><style data-emotion-css="78p1r9">.css-78p1r9{box-sizing:border-box;margin:0;min-width:0;margin-left:auto;margin-right:auto;max-width:690px;margin-top:0;}@media screen and (min-width:40em){.css-78p1r9{margin-top:1em;}}</style><style data-emotion-css="w59ah2">.css-w59ah2{position:relative;padding-bottom:66.5%;height:0;border-radius:inherit;}</style><style data-emotion-css="1b198zr">.css-1b198zr{box-sizing:border-box;margin:0;min-width:0;position:relative;padding-bottom:66.5%;height:0;border-radius:inherit;}</style><style data-emotion-css="1ld0bim">.css-1ld0bim{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;}</style><style data-emotion-css="1ujtx97">.css-1ujtx97{object-fit:cover;background-color:#F6F6F6;}</style><style data-emotion-css="uodor8">.css-uodor8{border-radius:50%;}</style><style data-emotion-css="kl6aur">.css-kl6aur{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:34px;height:34px;border-radius:50%;}</style><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1yuhvjn">.css-1yuhvjn{margin-top:16px;}</style><style data-emotion-css="376mun">.css-376mun{position:relative;display:inline;}</style><style data-emotion-css="1hhle02">.css-1hhle02 .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1hhle02 .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1hhle02 .FileLinkCard-info{margin-left:12px;}.css-1hhle02 .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1hhle02 .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1hhle02 .FileLinkCard-source{white-space:pre;}.css-1hhle02 img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1r0wf39">.css-1r0wf39 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1r0wf39 .LinkCard.new,.css-1r0wf39 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1r0wf39 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1r0wf39 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1r0wf39 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1r0wf39 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1r0wf39 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1r0wf39 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1r0wf39 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1r0wf39 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1r0wf39 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1r0wf39 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1r0wf39 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1r0wf39 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1r0wf39 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1r0wf39 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1r0wf39 .LinkCard.old,.css-1r0wf39 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1r0wf39 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1r0wf39 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="3np2dk">.css-3np2dk .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-3np2dk .LinkCard.old,.css-3np2dk .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-3np2dk .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-3np2dk .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-3np2dk .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-3np2dk .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-3np2dk .LinkCard.new,.css-3np2dk .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-3np2dk .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-3np2dk .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-3np2dk .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-3np2dk .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-3np2dk .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-3np2dk .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-3np2dk .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-3np2dk .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-3np2dk .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-3np2dk .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-3np2dk .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-3np2dk .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-3np2dk .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-3np2dk .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-3np2dk .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-3np2dk .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-3np2dk .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-3np2dk .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-3np2dk .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-3np2dk .FileLinkCard-info{margin-left:12px;}.css-3np2dk .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3np2dk .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-3np2dk .FileLinkCard-source{white-space:pre;}.css-3np2dk img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}</style><style data-emotion-css="1t538q animation-1yvu044">.css-1t538q{word-break:break-word;line-height:1.6;}.css-1t538q > [data-first-child]{margin-top:0;}.css-1t538q > :last-child{margin-bottom:0;}.css-1t538q h1,.css-1t538q h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:500;}.css-1t538q h3,.css-1t538q h4,.css-1t538q h5,.css-1t538q h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:500;}.css-1t538q u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #444444;}.css-1t538q b{font-weight:500;}.css-1t538q sup{font-size:0.8em;}.css-1t538q sup[data-draft-type='reference']{color:#175199;}.css-1t538q a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-1t538q a:focus{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(5,109,232,0.3);}.css-1t538q a.ztext-link,.css-1t538q a.internal,.css-1t538q a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #808080;}.css-1t538q a.ztext-link:hover,.css-1t538q a.internal:hover,.css-1t538q a.external:hover{color:#175199;border-bottom:1px solid #175199;}.css-1t538q a.ztext-link > .ellipsis::after,.css-1t538q a.internal > .ellipsis::after,.css-1t538q a.external > .ellipsis::after{content:'...';}.css-1t538q a.ztext-link > .invisible,.css-1t538q a.internal > .invisible,.css-1t538q a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-1t538q a.ztext-link u,.css-1t538q a.internal u,.css-1t538q a.external u{border:none;}.css-1t538q a.member_mention{color:#175199;}.css-1t538q a.member_mention:hover{border-bottom:1px solid #175199;}.css-1t538q a.UserLink-link{color:#175199;}.css-1t538q a.UserLink-link:hover{border-bottom:1px solid #175199;}.css-1t538q p{margin:1.4em 0;}.css-1t538q p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-1t538q p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-1t538q hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #D3D3D3;}.css-1t538q img[eeimg]{max-width:100%;vertical-align:middle;}.css-1t538q img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-1t538q img[eeimg="2"]{margin:1.4em auto;display:block;}.css-1t538q blockquote{margin:1.4em 0;padding-left:1em;color:#646464;border-left:3px solid #D3D3D3;}.css-1t538q ol,.css-1t538q ul{margin:1.4em 0;padding:0;width:100%;}.css-1t538q ol ol,.css-1t538q ul ol,.css-1t538q ol ul,.css-1t538q ul ul{margin:0;}.css-1t538q ol li::before,.css-1t538q ul li::before{width:1em;}.css-1t538q ol > ol,.css-1t538q ul > ol,.css-1t538q ol > ul,.css-1t538q ul > ul{display:table-row;}.css-1t538q ol > ol::before,.css-1t538q ul > ol::before,.css-1t538q ol > ul::before,.css-1t538q ul > ul::before{display:table-cell;content:'';}.css-1t538q ul{display:table;}.css-1t538q ul>li{display:table-row;list-style:none;}.css-1t538q ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-1t538q ol{display:table;counter-reset:ol;}.css-1t538q ol > li{display:table-row;list-style:none;}.css-1t538q ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-1t538q ol ol{counter-reset:ol2;}.css-1t538q ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-1t538q ol ol ol{counter-reset:ol3;}.css-1t538q ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-1t538q ol ol ol ol{counter-reset:ol4;}.css-1t538q ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-1t538q figure{margin:1.4em 0;}.css-1t538q figure .content_image,.css-1t538q figure .origin_image{margin:0 auto;}.css-1t538q figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#999999;}.css-1t538q figure + figure{margin-top:calc(1.4em * 1.6);}.css-1t538q figure[data-size='small'],.css-1t538q figure:not([data-size]) > [data-size='small']{clear:both;}.css-1t538q figure[data-size='left'],.css-1t538q figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-1t538q figure[data-size='right'],.css-1t538q figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-1t538q figure[data-size='collapse']{margin-bottom:0;}.css-1t538q figure[data-size='collapse'] + figure{margin-top:0;}.css-1t538q .content_image,.css-1t538q .origin_image{display:block;max-width:100%;height:auto;margin:1.4em auto;}.css-1t538q .content_image[data-size='small'],.css-1t538q .origin_image[data-size='small']{max-width:40%;}.css-1t538q .content_image.zh-lightbox-thumb,.css-1t538q .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-1t538q code{margin:0 2px;padding:3px 4px;border-radius:3px;font-family:Menlo,Monaco,Consolas,'Andale Mono','lucida console','Courier New',monospace;font-size:0.9em;background-color:#F6F6F6;}.css-1t538q pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#F6F6F6;border-radius:4px;}.css-1t538q pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-1t538q li pre{white-space:pre-wrap;}.css-1t538q table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-1t538q table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-1t538q table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#F6F6F6;}.css-1t538q table[data-draft-type='table'] td,.css-1t538q table[data-draft-type='table'] th{border:1px solid #D3D3D3;line-height:24px;height:24px;padding:3px 12px;}.css-1t538q table[data-draft-type='table'] th{background:#EBEBEB;color:#121212;font-weight:500;}.css-1t538q .video-box,.css-1t538q .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #EBEBEB;border-radius:4px;}.css-1t538q .lazy[data-lazy-status]{background-color:#F6F6F6;}.css-1t538q .lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1yvu044 0.5s ease-in;animation:animation-1yvu044 0.5s ease-in;}.css-1t538q .highlight{margin:1em 0;}.css-1t538q .highlight pre{margin:0;}.css-1t538q .highlight .hll{background-color:#FDFDFD;}.css-1t538q .highlight .c{font-style:italic;color:#999999;}.css-1t538q .highlight .err{color:#F1403C;}.css-1t538q .highlight .k{font-weight:500;}.css-1t538q .highlight .o{font-weight:500;}.css-1t538q .highlight .cm{font-style:italic;color:#999999;}.css-1t538q .highlight .cp{font-weight:500;color:#999999;}.css-1t538q .highlight .c1{font-style:italic;color:#999999;}.css-1t538q .highlight .cs{font-style:italic;font-weight:500;color:#999999;}.css-1t538q .highlight .gd{color:#FF3366;}.css-1t538q .highlight .ge{font-style:italic;}.css-1t538q .highlight .gr{color:#F1403C;}.css-1t538q .highlight .gh{color:#999999;}.css-1t538q .highlight .gi{color:#12b370;}.css-1t538q .highlight .go{color:#808080;}.css-1t538q .highlight .gp{color:#646464;}.css-1t538q .highlight .gs{font-weight:500;}.css-1t538q .highlight .gu{color:#999999;}.css-1t538q .highlight .gt{color:#F1403C;}.css-1t538q .highlight .kc{font-weight:500;}.css-1t538q .highlight .kd{font-weight:500;}.css-1t538q .highlight .kn{font-weight:500;}.css-1t538q .highlight .kp{font-weight:500;}.css-1t538q .highlight .kr{font-weight:500;}.css-1t538q .highlight .kt{font-weight:500;color:#175199;}.css-1t538q .highlight .m{color:#056DE8;}.css-1t538q .highlight .s{color:#F1403C;}.css-1t538q .highlight .na{color:#056DE8;}.css-1t538q .highlight .nb{color:#056DE8;}.css-1t538q .highlight .nc{font-weight:500;color:#175199;}.css-1t538q .highlight .no{color:#056DE8;}.css-1t538q .highlight .ni{color:#5555DD;}.css-1t538q .highlight .ne{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nf{font-weight:500;color:#F1403C;}.css-1t538q .highlight .nn{color:#646464;}.css-1t538q .highlight .nt{color:#175199;}.css-1t538q .highlight .nv{color:#056DE8;}.css-1t538q .highlight .ow{font-weight:500;}.css-1t538q .highlight .w{color:#BFBFBF;}.css-1t538q .highlight .mf{color:#056DE8;}.css-1t538q .highlight .mh{color:#056DE8;}.css-1t538q .highlight .mi{color:#056DE8;}.css-1t538q .highlight .mo{color:#056DE8;}.css-1t538q .highlight .sb{color:#F1403C;}.css-1t538q .highlight .sc{color:#F1403C;}.css-1t538q .highlight .sd{color:#F1403C;}.css-1t538q .highlight .s2{color:#F1403C;}.css-1t538q .highlight .se{color:#F1403C;}.css-1t538q .highlight .sh{color:#F1403C;}.css-1t538q .highlight .si{color:#F1403C;}.css-1t538q .highlight .sx{color:#F1403C;}.css-1t538q .highlight .sr{color:#A5542F;}.css-1t538q .highlight .s1{color:#F1403C;}.css-1t538q .highlight .ss{color:#F1403C;}.css-1t538q .highlight .bp{color:#999999;}.css-1t538q .highlight .vc{color:#056DE8;}.css-1t538q .highlight .vg{color:#056DE8;}.css-1t538q .highlight .vi{color:#056DE8;}.css-1t538q .highlight .il{color:#056DE8;}.css-1t538q .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(18,18,18,0.5);border-radius:6px;}.css-1t538q .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(18,18,18,0.6);}.css-1t538q .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1t538q .LinkCard.old,.css-1t538q .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1t538q .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1t538q .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1t538q .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-1t538q .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1t538q .LinkCard.new,.css-1t538q .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1t538q .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1t538q .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1t538q .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1t538q .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1t538q .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1t538q .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1t538q .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1t538q .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1t538q .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1t538q .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1t538q .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1t538q .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1t538q .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1t538q .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1t538q .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1t538q .LinkCard.new .LinkCard-richText .bold{font-weight:500;}.css-1t538q .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1t538q .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1t538q .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1t538q .FileLinkCard-info{margin-left:12px;}.css-1t538q .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1t538q .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1t538q .FileLinkCard-source{white-space:pre;}.css-1t538q img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}@-webkit-keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}@keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}</style><style data-emotion-css="1k6fd7f">.css-1k6fd7f{margin:0;padding-top:15px;}</style><style data-emotion-css="1any501">.css-1any501{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#FFFFFF;width:40px;height:40px;border-radius:50%;}</style><style data-emotion="css"></style></head><body class="WhiteBg-body PostIndex-body Body--Mobile Body--iOS Body--isAppleDevice" aria-basefontsize="16" data-rh="class"><a id="ariaTipText" role="pagedescription" aria-label="链接，无障碍模式读屏软件服务通道。" aria-atomic="true" href="javascript:void(0)" class="skipAutoFix" onclick="aria.wzaStart();" style="width: 1px; height: 1px;"><img src="" style="width:1px !important;height:1px !important;position:absolute;top:0;"></a><div id="root"><div class="App"><div class="LoadingBar  css-uzm3ri"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content Post-content-mobile" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;字节&quot;,&quot;itemId&quot;:622947810,&quot;title&quot;:&quot;AutoGPT与LLM Agent解析&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;622947810&quot;}}}"><div><header class="Sticky MobileAppHeader" style="line-height:50px"><div class="MobileAppHeader-inner"><a class="MobileAppHeader-logo" href="//www.zhihu.com?utm_source=zhihu&amp;utm_campaign=guest_feed&amp;utm_content=guide&amp;utm_medium=zhuanlan&amp;utm_id=0" aria-label="知乎"><svg viewBox="0 0 64 30" fill="#056DE8" width="52" height="24.375"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><div class="MobileAppHeader-actions"><label class="MobileAppHeader-searchBox MobileAppHeader-searchBoxWithUnlogin Input-wrapper"><svg width="16" height="16" viewBox="0 0 24 24" fill="#999" class="ZDI ZDI--Search24 css-15ro776"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M11.5 18.389c3.875 0 7-3.118 7-6.945 0-3.826-3.125-6.944-7-6.944s-7 3.118-7 6.944 3.125 6.945 7 6.945Zm0 1.5c4.694 0 8.5-3.78 8.5-8.445C20 6.781 16.194 3 11.5 3S3 6.78 3 11.444c0 4.664 3.806 8.445 8.5 8.445Z"></path><path d="M16.47 16.97a.75.75 0 0 1 1.06 0l3.5 3.5a.75.75 0 1 1-1.06 1.06l-3.5-3.5a.75.75 0 0 1 0-1.06Z"></path></g></svg><input type="search" value="" class="Input" placeholder="搜索"></label><a class="MobileAppHeader-authLink" href="https://www.zhihu.com/signin?next=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F622947810" data-za-detail-view-name="注册或登录"><svg width="24" height="24" viewBox="0 0 24 24" style="vertical-align:middle;margin-bottom:1px" class="ZDI ZDI--User24" fill="currentColor"><path fill-rule="evenodd" d="M7.25 8A4.75 4.75 0 0 1 12 3.25 4.75 4.75 0 0 1 16.75 8 4.75 4.75 0 0 1 12 12.75 4.75 4.75 0 0 1 7.25 8ZM12 1.75A6.25 6.25 0 0 0 5.75 8a6.248 6.248 0 0 0 3.275 5.498c-2.993 1.03-5.222 3.572-5.521 6.681a.75.75 0 1 0 1.493.144c.31-3.209 3.277-5.819 7.006-5.819.025 0 .05-.001.075-.004 3.692.036 6.622 2.634 6.93 5.823a.75.75 0 1 0 1.492-.144c-.3-3.11-2.527-5.652-5.52-6.684A6.248 6.248 0 0 0 18.25 8 6.25 6.25 0 0 0 12 1.75Z" clip-rule="evenodd"></path></svg></a><button type="button" class="Button css-183aq3r Button--blue">打开App</button><svg width="22" height="22" viewBox="0 0 24 24" class="ZDI ZDI--Dots24 css-1ie3c6f" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></div></div><div></div></header></div><div class="css-78p1r9"><div class="css-1b198zr"><div class="css-1ld0bim"><img src="https://pica.zhimg.com/v2-1e36a1bfc750cd1b5acd76cb211b95e7_720w.jpg?source=172ae18b" alt="AutoGPT与LLM Agent解析" width="100%" height="100%" class="css-1phd9a0" srcset="https://pica.zhimg.com/v2-1e36a1bfc750cd1b5acd76cb211b95e7_200x0.jpg?source=172ae18b 200w,https://pica.zhimg.com/v2-1e36a1bfc750cd1b5acd76cb211b95e7_qhd.jpg?source=172ae18b 480w,https://pica.zhimg.com/v2-1e36a1bfc750cd1b5acd76cb211b95e7_720w.jpg?source=172ae18b 720w,https://pica.zhimg.com/v2-1e36a1bfc750cd1b5acd76cb211b95e7_1440w.jpg?source=172ae18b 1440w" loading="lazy"></div></div></div><article class="Post-Main Post-Main-Mobile" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">AutoGPT与LLM Agent解析</h1></header><div class="Post-TimeExtra">1 个月前<!-- --> · 来自专栏 <!-- -->RandomGenerator</div><div class="Post-Author Post-Author-Mobile"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><div class="AuthorInfo"><meta itemprop="name" content="字节"><meta itemprop="image" content="https://picx.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/zijie0"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar AuthorInfo-avatar css-kl6aur" src="https://picx.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b 2x" alt="字节"></a></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><a href="//www.zhihu.com/people/zijie0" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">字节</a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText css-0">天地大观，志存高远</div></div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path fill-rule="evenodd" d="M13.25 3.25a1.25 1.25 0 1 0-2.5 0v7.5h-7.5a1.25 1.25 0 1 0 0 2.5h7.5v7.5a1.25 1.25 0 1 0 2.5 0v-7.5h7.5a1.25 1.25 0 0 0 0-2.5h-7.5v-7.5Z" clip-rule="evenodd"></path></svg></span>关注</button></div><div class="Post-RichTextContainer"><div class="css-1yuhvjn"><div class="css-376mun"><div class="RichText ztext Post-RichText css-1t538q" options="[object Object]"><p data-first-child="" data-pid="v7BW6Vwt">前两周 AutoGPT，BabyAGI 等项目异常火爆，周末也正好花了点时间来看了下这些 AI agent 类项目的代码，写篇文章来总结一下对于当前这类项目进展的技术角度认识和思考，与大家一同交流。</p><h2>从语言理解到任务执行</h2><p data-pid="WF7iTVA_">之前大多相关项目和产品都主要利用了 GPT 模型的语言理解方面的能力，例如生成文案的 Jasper，Notion AI，帮忙做网页、文档总结的 Glarity，Bearly.ai，做问答的 New Bing，ChatPDF 等。后续想要拓展 GPT 的应用范围，一个很自然的方向就是让 GPT 能够学会自己使用各种外部工具，来进行更广泛的任务类型的执行，做到“知行合一” 。除了上面提到的 AutoGPT 和 BabyAGI，还有很多有意思的项目如 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2302.04761" class=" wrap external" target="_blank" rel="nofollow noreferrer">Toolformer</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/microsoft/JARVIS" class=" wrap external" target="_blank" rel="nofollow noreferrer">HuggingGPT</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/microsoft/visual-chatgpt" class=" wrap external" target="_blank" rel="nofollow noreferrer">Visual ChatGPT</a> 等都在尝试这个方向。</p><p data-pid="z8dvO_UQ">这个任务执行说起来原理也不复杂，基本的套路还是让 GPT 去做生成，只不过我们会在 Prompt 中告诉 GPT，如果你需要调用一些外部工具，那么就按照特定的格式来生成一些指令/代码，程序接收到之后，再根据 GPT 生成的内容去调用外部工具并获得相应结果，这个结果再作为输入可以由 GPT 去做进一步的理解和生成，循环往复。以 LangChain 里最常见的 ReAct prompt 为例，输入给模型的内容如下：</p><div class="highlight"><pre><code class="language-text">...
你可以使用如下工具来完成任务：

1. 计算器，用来执行各种数学计算获取精确结果，输入表达式，例如 1 + 1，得到结果
...

问题：123 乘以 456 的结果是多少？
...</code></pre></div><p data-pid="DBmRy4Hz">模型生成的内容如下：</p><div class="highlight"><pre><code class="language-text">思考：我需要使用计算器来计算 123 乘以 456 的结果
动作：调用计算器
动作输入：123 * 456
观测结果：</code></pre></div><p data-pid="gxGETQWi">然后我们可以处理这段返回，调用计算器程序，拿到 123 * 456 的结果，然后将结果填写到观测结果后面，再让模型继续生成下一段内容。</p><p data-pid="YNnKTqxG">这就是基本的任务执行的方法。更多内容也可以参考我之前对于 LangChain 的一些分享：<a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1DY4y1Q7Te/" class=" wrap external" target="_blank" rel="nofollow noreferrer">微软 365 Copilot 是如何实现的？揭秘 LLM 如何生成指令</a>。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-a5d133b8902cbe430ddf8f117871b635_b.jpg" data-size="normal" data-rawwidth="2530" data-rawheight="2488" class="origin_image zh-lightbox-thumb" width="2530" data-original="https://pic2.zhimg.com/v2-a5d133b8902cbe430ddf8f117871b635_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2530' height='2488'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2530" data-rawheight="2488" class="origin_image zh-lightbox-thumb lazy" width="2530" data-original="https://pic2.zhimg.com/v2-a5d133b8902cbe430ddf8f117871b635_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a5d133b8902cbe430ddf8f117871b635_b.jpg" data-original-token="v2-e8959c5e758a693db12e9e81a947f9c4"></div><figcaption>典型的 ReAct prompt</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h2>模型记忆</h2><p data-pid="MHFsKRaz">另外一类非常常见的模式是通过外部存储来增强模型记忆。其中一个典型场景是长 session 的聊天过程，由于 GPT API 本身的输入信息有 4000 个 token 的限制，所以当聊天进行比较久之后，用户经常会发现 ChatGPT 已经“忘了”之前讲过的内容。另外一个典型场景是给 LLM 提供更多的新信息，像一些产品里能够对一整篇 PDF 甚至一整个知识库里的内容做理解和问答，那么自然不可能直接把所有这些额外信息都直接在 prompt 里扔给 GPT 去处理。</p><p data-pid="Y-04tgmn">这时候就需要通过外部存储来帮助 GPT 拓展记忆。最简单的方法就是直接把这些对话记录，外部信息等以文本形式保存到文件或者数据库系统里，后续在与模型进行交互时，可以按需去获取这些外部存储中的信息。我们可以把 prompt 里的内容当成模型的“短期记忆”，那么这些外部存储自然就成为了“长期记忆”。除了前面提到的好处外，这种记忆系统模式还能一定程度上起到降低模型 hallucinations 的作用，避免纯粹依靠“生成”来实现任务目标。</p><p data-pid="pqnWFL9q">获取长期记忆的方法，目前最常见的方式是通过“语义搜索”。大概意思就是利用一个 embedding 模型，将所有的记忆文本都转化为一个向量。而后续跟模型的交互信息也可以通过同样的 embedding 模型转化为向量，然后通过计算相似度来找到最相似的记忆文本。最后再将这些记忆文本拼接到 prompt 里，作为模型的输入。这类方法最热门的开源项目可以参考 OpenAI 官方的 <a href="https://link.zhihu.com/?target=https%3A//github.com/openai/chatgpt-retrieval-plugin" class=" wrap external" target="_blank" rel="nofollow noreferrer">ChatGPT Retrieval Plugin</a> 和 Jerry Liu 的 <a href="https://link.zhihu.com/?target=https%3A//github.com/jerryjliu/llama_index" class=" wrap external" target="_blank" rel="nofollow noreferrer">LlamaIndex</a>。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-3742a095fdd75d3c3a66faecbb690575_b.jpg" data-size="normal" data-rawwidth="4062" data-rawheight="1828" class="origin_image zh-lightbox-thumb" width="4062" data-original="https://pic2.zhimg.com/v2-3742a095fdd75d3c3a66faecbb690575_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='4062' height='1828'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="4062" data-rawheight="1828" class="origin_image zh-lightbox-thumb lazy" width="4062" data-original="https://pic2.zhimg.com/v2-3742a095fdd75d3c3a66faecbb690575_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-3742a095fdd75d3c3a66faecbb690575_b.jpg" data-original-token="v2-2de22c9b5ca4ae995c091cc49a59c9bd"></div><figcaption>Retrieval Pattern</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="-hNG5WRk">这种拓展模型记忆的模式相比人类大脑的运作方式来说感觉还有些“粗糙”，所谓的长期与短期记忆（包括 LangChain 与 LlamaIndex 中一些更复杂的实现），仍然是比较“hard coded”的感觉。如果未来在模型 context size 上有突破性的研究进展，那么当前的这类模式或许就不再需要了。</p><p data-pid="reXEJqKB">从整体的交互流程来看，这类模型记忆实现模式也可以看作是一种“任务执行”的方式，只不过这里的任务是“写入/获取记忆”，而不是“执行某个外部工具”。我们可以把两者统一来看，也就是当前大语言模型最常用的应用开发模式。后面我们也会看到，各种所谓的智能 agent 也都是在这个思路下进行拓展实现的。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-670e38abdbd8e6686adcc2c35aea66c2_b.jpg" data-size="normal" data-rawwidth="2110" data-rawheight="1612" class="origin_image zh-lightbox-thumb" width="2110" data-original="https://pic3.zhimg.com/v2-670e38abdbd8e6686adcc2c35aea66c2_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2110' height='1612'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2110" data-rawheight="1612" class="origin_image zh-lightbox-thumb lazy" width="2110" data-original="https://pic3.zhimg.com/v2-670e38abdbd8e6686adcc2c35aea66c2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-670e38abdbd8e6686adcc2c35aea66c2_b.jpg" data-original-token="v2-3129260d55eeb003642fa296a099649c"></div><figcaption>LLM 调用外部工具的应用模式</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="4IZPJwNy">有意思的是，OpenAI 的 Jack Rae 和 Ilya Sutskever 在之前的分享中也分别提到了 <a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DdO4TPJkeaaU" class=" wrap external" target="_blank" rel="nofollow noreferrer">压缩即智慧</a> 的理念。对于模型的“压缩率”来说，如果能更有效地使用这些“外部工具”，就能大幅提升很多特定任务 next token 预测的准确率。个人感觉这个方向的发展还有非常大的空间，例如从“有效数据”角度看，人类执行各类任务使用工具，甚至思维过程等数据会有非常高的价值。而从模型训练角度来看，如何能在过程中把模型利用工具的能力也体现在 loss function 里，可能也是个很有趣的方向。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-06fe12da5124690ef0bcba8b8531d618_b.jpg" data-size="normal" data-rawwidth="4062" data-rawheight="1900" class="origin_image zh-lightbox-thumb" width="4062" data-original="https://pic1.zhimg.com/v2-06fe12da5124690ef0bcba8b8531d618_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='4062' height='1900'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="4062" data-rawheight="1900" class="origin_image zh-lightbox-thumb lazy" width="4062" data-original="https://pic1.zhimg.com/v2-06fe12da5124690ef0bcba8b8531d618_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-06fe12da5124690ef0bcba8b8531d618_b.jpg" data-original-token="v2-832efe1eca0848dc9cc3d516aaedf91d"></div><figcaption>提升“压缩率”的手段</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h2>AutoGPT</h2><p data-pid="Y9gBzrPW">有了前面的铺垫信息，我们来理解 AutoGPT 这类 AI agent 工作的内部结构与核心逻辑就会比较容易了。这类项目绝大多数的主要创新还是在 prompt 层面，通过更好的提示词来激发模型的能力，把更多原先需要通过代码来实现的流程“硬逻辑”转化为模型自动生成的“动态逻辑”。以 AutoGPT 为例，它的核心 prompt 如下：</p><div class="highlight"><pre><code class="language-text">You are Guandata-GPT, 'an AI assistant designed to help data analysts do their daily work.'
Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.

GOALS:

1. 'Process data sets'
2. 'Generate data reports and visualizations'
3. 'Analyze reports to gain business insights'

Constraints:
1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.
2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.
3. No user assistance
4. Exclusively use the commands listed in double quotes e.g. "command name"

Commands:
1. Google Search: "google", args: "input": "&lt;search&gt;"
2. Browse Website: "browse_website", args: "url": "&lt;url&gt;", "question": "&lt;what_you_want_to_find_on_website&gt;"
3. Start GPT Agent: "start_agent", args: "name": "&lt;name&gt;", "task": "&lt;short_task_desc&gt;", "prompt": "&lt;prompt&gt;"
4. Message GPT Agent: "message_agent", args: "key": "&lt;key&gt;", "message": "&lt;message&gt;"
5. List GPT Agents: "list_agents", args: 
6. Delete GPT Agent: "delete_agent", args: "key": "&lt;key&gt;"
7. Clone Repository: "clone_repository", args: "repository_url": "&lt;url&gt;", "clone_path": "&lt;directory&gt;"
8. Write to file: "write_to_file", args: "file": "&lt;file&gt;", "text": "&lt;text&gt;"
9. Read file: "read_file", args: "file": "&lt;file&gt;"
10. Append to file: "append_to_file", args: "file": "&lt;file&gt;", "text": "&lt;text&gt;"
11. Delete file: "delete_file", args: "file": "&lt;file&gt;"
12. Search Files: "search_files", args: "directory": "&lt;directory&gt;"
13. Evaluate Code: "evaluate_code", args: "code": "&lt;full_code_string&gt;"
14. Get Improved Code: "improve_code", args: "suggestions": "&lt;list_of_suggestions&gt;", "code": "&lt;full_code_string&gt;"
15. Write Tests: "write_tests", args: "code": "&lt;full_code_string&gt;", "focus": "&lt;list_of_focus_areas&gt;"
16. Execute Python File: "execute_python_file", args: "file": "&lt;file&gt;"
17. Generate Image: "generate_image", args: "prompt": "&lt;prompt&gt;"
18. Send Tweet: "send_tweet", args: "text": "&lt;text&gt;"
19. Do Nothing: "do_nothing", args: 
20. Task Complete (Shutdown): "task_complete", args: "reason": "&lt;reason&gt;"

Resources:
1. Internet access for searches and information gathering.
2. Long Term memory management.
3. GPT-3.5 powered Agents for delegation of simple tasks.
4. File output.

Performance Evaluation:
1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.
2. Constructively self-criticize your big-picture behavior constantly.
3. Reflect on past decisions and strategies to refine your approach.
4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.

You should only respond in JSON format as described below 
Response Format: 
{
    "thoughts": {
        "text": "thought",
        "reasoning": "reasoning",
        "plan": "- short bulleted\n- list that conveys\n- long-term plan",
        "criticism": "constructive self-criticism",
        "speak": "thoughts summary to say to user"
    },
    "command": {
        "name": "command name",
        "args": {
            "arg name": "value"
        }
    }
} 
Ensure the response can be parsed by Python json.loads</code></pre></div><p data-pid="qadTZNUu">从这大段的 prompt 可以看出来，AutoGPT 的确算得上是提示词应用模式当前比较先进的“集大成者”了，有很多可以学习的地方。相比经典的 reason + act 模式，我们可以分别来看看它都做了哪些进一步的发展改进。</p><h3>Constraints &amp; Resources</h3><p data-pid="2Jb8BGEH">在这里告诉了模型你自己的各种局限性，也是很有喜感。例如模型的输入 context size 有限制，所以你需要把重要的信息保存到文件里。尤其在代码生成场景中这个动作非常重要，否则无法实现长代码的生成和执行。另外 AutoGPT 里也给模型提供了长期记忆的管理功能，当前这类复杂 prompt 生成的解决任务的流程往往比较冗长，没有这类长期记忆的管理很容易就会导致模型的输出变得不连贯协调。</p><p data-pid="sX737LGu">另外像默认的模型是“没有联网”的，所有的知识只更新到训练数据的截止日期。所以也明确告诉模型可以通过网络搜索来获取更多时效性的外部信息。</p><h3>Commands</h3><p data-pid="U-9J01LS">在 commands 也就是各类工具的选择上，这里给出的选项非常丰富。这也是为何很多文章宣传里提到 AutoGPT 能够完成多种不同任务的原因之一，灵活性与通用性很高。</p><p data-pid="83AG-xZ0">具体的 commands 中，可以分为几大类，包括搜索、浏览网页相关，启动其它的 GPT agent，文件读写操作，代码生成与执行等。使用其它的 agent 的想法跟 HuggingGPT 有些类似，因为目前 GPT 模型对于越具体，细致的任务，生成的表现就越精确和稳定。所以这种“分而治之”的思路，是很有必要的。</p><h3>Performance Evaluation</h3><p data-pid="BJCc_t9B">这里给出了模型整体思考流程的指导原则，分为了几个具体维度，包括对自己的能力与行为的匹配进行 review，大局观与自我反思，结合长期记忆对决策动作进行优化，以及尽可能高效率地用较少的动作来完成任务。这个思考逻辑也非常符合人类的思考，决策与反馈迭代的过程。</p><h3>Response</h3><p data-pid="nBiIG2l2">从 response 格式上来看，也是综合了几种模式，包括需要把自己的想法写出来，做一些 reasoning 获取相关背景知识，生成有具体步骤的 plan，以及对自己的思考过程进行 criticism 等。这些格式的限定也是对前面思维指导原则的具体操作规范说明。</p><p data-pid="ojsrh11r">具体 command 的生成与前面提到的 ReAct 方式基本一致。这里的 command 也是可以嵌套的，比如可以在一个 command 中启动另一个 GPT agent，然后再对这个 agent 发送 message，这样就可以实现更复杂的任务了。而在 LangChain 里，子 agent 与主流程之间应该只有一次调用和返回，相对来说比较受局限。</p><p data-pid="DKZ1-EpS">值得注意的是这么一大段 response 是模型一次交互生成的，而不像一些其它框架中会把计划，审视，动作生成等通过多轮模型交互来生成。个人感觉是因为 AutoGPT 生成的解决流程往往会非常冗长，如果每一个动作的生成都需要与 LLM 做多轮交互，耗费的时间和 token 量都会非常大。但如果某个具体决策动作的开销非常大，例如需要调用一个比较贵的 API 做图片生成，那么可能把这个动作做多次审视优化，最后做一次决策，可能整体成本会更低一些。</p><h3>人工介入</h3><p data-pid="660nhDmd">如果大家自己跑过 AutoGPT，会发现模型很容易会把问题复杂化或者在执行计划层面“跑偏”。所以在具体执行过程中，AutoGPT 也允许用户来介入，对于每一个具体执行步骤提供额外的输入来指导模型行为。经过人工反馈输入后，模型会重新生成上述的 response，以此往复。大家可以访问这个 <a href="https://link.zhihu.com/?target=https%3A//godmode.space/" class=" wrap external" target="_blank" rel="nofollow noreferrer">带界面的 AutoGPT 产品</a>，实际体验一下这个流程。虽然从实际完成任务角度来看还在比较早期的阶段，但这个 prompt 的设计和交互方式还是挺有启发性的。</p><h2>BabyAGI</h2><p data-pid="5b1Extdt">相比 AutoGPT 来说，BabyAGI 是一个相对更聚焦在“思维流程”方面尝试的项目，并没有添加对各种外部工具利用的支持。其核心逻辑非常简单：</p><ol><li data-pid="hp3oKfIZ">从任务列表中获取排在第一位的任务。</li><li data-pid="aVrH89wS">获取任务相关的“记忆”信息，由任务执行 agent 来执行这个任务，获取结果。目前这个执行就是一个简单的 LLM 调用，不涉及外部工具。</li><li data-pid="MHgDBaiC">将返回结果再存放到记忆存储中。</li><li data-pid="DcGpqfdF">基于当前的信息，如整体目标，最近一次执行结果，任务描述，还未执行的任务列表等，生成所需要的新任务。</li><li data-pid="RaI_PqD_">将新任务添加到任务列表中，再判断所有任务的优先级，重新排序。</li></ol><p data-pid="VDVytWML">作者表示这个过程就是在模拟他一天真实的工作流程。早上起来看下有哪些任务要做，白天做任务拿反馈，晚上再看下基于反馈有没有新的任务要加进来，然后重新排下优先级。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic1.zhimg.com/v2-fc665ce2bae6d064e16ae444a5096ff0_b.jpg" data-size="normal" data-rawwidth="1970" data-rawheight="1618" class="origin_image zh-lightbox-thumb" width="1970" data-original="https://pic1.zhimg.com/v2-fc665ce2bae6d064e16ae444a5096ff0_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1970' height='1618'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1970" data-rawheight="1618" class="origin_image zh-lightbox-thumb lazy" width="1970" data-original="https://pic1.zhimg.com/v2-fc665ce2bae6d064e16ae444a5096ff0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-fc665ce2bae6d064e16ae444a5096ff0_b.jpg" data-original-token="v2-629620a3d4cd0f0b292c0e29098b6f93"></div><figcaption>BabyAGI 运作流程</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="yi2e-lXE">整个项目的代码量很少，相关的 prompts 也比较简单易懂，有兴趣的同学可以自行阅读。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-a6a493784c7c41d553390551e64f9f4d_b.jpg" data-size="normal" data-rawwidth="2210" data-rawheight="1538" class="origin_image zh-lightbox-thumb" width="2210" data-original="https://pic2.zhimg.com/v2-a6a493784c7c41d553390551e64f9f4d_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2210' height='1538'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2210" data-rawheight="1538" class="origin_image zh-lightbox-thumb lazy" width="2210" data-original="https://pic2.zhimg.com/v2-a6a493784c7c41d553390551e64f9f4d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a6a493784c7c41d553390551e64f9f4d_b.jpg" data-original-token="v2-93ae48ddb742777dd8f9f7dfb5e22741"></div><figcaption>BabyAGI prompts 示例</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="6vvbYHbA">后续也出现了一些在这个项目上的进化版本，例如这个 <a href="https://link.zhihu.com/?target=https%3A//github.com/oliveirabruno01/babyagi-asi" class=" wrap external" target="_blank" rel="nofollow noreferrer">BabyASI</a>，借鉴了 AutoGPT 添加了对 search，代码执行等工具的支持。理论上来说，如果这个 ASI（Artificial Super Intelligence）真的足够聪明，甚至可以产生代码给自己做 prompt 优化，流程改造，甚至持续的模型训练等，让 GPT 自己开发未来的 GPT，想想是不是很带感 。</p><h2>HuggingGPT</h2><p data-pid="LUVs331-">如果说 BabyAGI 更多的是探索了 plan &amp; execution 这个应用 LLM 的模式，那么 HuggingGPT 这个相对早一些的工作更多地展示了在“外部工具”这个层面的想象空间。其核心运作逻辑也是计划加上执行，只不过在执行工具层面，可以利用丰富的“领域专业模型”来协助 LLM 更好地完成复杂任务，如下图所示：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-512ef42cf0d983c518d3d47d2638dbbe_b.jpg" data-size="normal" data-rawwidth="1246" data-rawheight="1240" class="origin_image zh-lightbox-thumb" width="1246" data-original="https://pic3.zhimg.com/v2-512ef42cf0d983c518d3d47d2638dbbe_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1246' height='1240'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1246" data-rawheight="1240" class="origin_image zh-lightbox-thumb lazy" width="1246" data-original="https://pic3.zhimg.com/v2-512ef42cf0d983c518d3d47d2638dbbe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-512ef42cf0d983c518d3d47d2638dbbe_b.jpg" data-original-token="v2-1bd0fee0a05d861d146c08595d3332dc"></div><figcaption>HuggingGPT 流程</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="6WdYVRY-">通过作者给出的各种例子，可以看出 LLM 能够很好地理解任务并调用相应模型来解决。虽然很多例子可能会被后来多模态的 GPT 系列通过端到端的方式直接完成，但这个想法还是挺有意思的。外部工具不仅仅局限于搜索，API 调用这些，也可以调用其他复杂的模型。未来或许不光能调用模型，还能触发数据收集，模型训练/微调等动作，完成更加复杂的任务流程。</p><p data-pid="9Zk60Fzt">从另一个角度看，对于一些目标明确，专业化且高频的场景，往往具有丰富的数据，可以通过构建一个更小的专有模型来很好地以较低成本来完成相关诉求。而像一些更加模糊，需求多变的“胖尾”诉求，就可以更好地利用大模型强大的理解，推理，生成能力来满足，未来或许会替换到很多当基于启发式规则驱动的业务流程。这或许是未来大模型与小模型的一种常见组合应用形态。</p><h2>Camel / Generative Agents</h2><p data-pid="8JBCFjbx">在前面 AutoGPT 里，我们看到了一些给模型 agent 加上长期记忆，以及调用其它 agent 进行交互的玩法。另外在前面的 prompt 模式中也发现，让模型进行自我审视，或者先计划再执行的方式往往能达到非常好的效果提升。如果沿着这个方向进一步推演，是否可以将多个 agent 组成一个团队，分别扮演不同的角色，是否能更好地解决一些复杂问题，甚至让这个小的“社群”演化出一些更复杂的行为模式甚至新知识的发现？最近就有两篇很火的工作跟 agent“社群”的方向相关。</p><h3>Camel</h3><p data-pid="xqaZwiwl">在 <a href="https://link.zhihu.com/?target=https%3A//www.camel-ai.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Camel</a> 这篇工作中，作者的思路是通过 LLM 来模拟用户和 AI 助手，让两个 agent 进行角色扮演（例如一个是业务专家，一个是程序员），然后让他们自主沟通协作来完成一项具体的任务。这个想法还是比较直接的，不过作者也提到 prompt 的设计还是蛮重要的，否则很容易出现角色转换，重复指令，消息无限循环，有瑕疵的回复，何时终止对话等等问题。有兴趣的同学可以具体看项目代码中给出的 prompt 设定，添加了非常多的明确指令来让 agent 按照预想的设定来沟通协作。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic4.zhimg.com/v2-0f871ff3f5b1af49a74d56caa39a785b_b.jpg" data-size="normal" data-rawwidth="2184" data-rawheight="2494" class="origin_image zh-lightbox-thumb" width="2184" data-original="https://pic4.zhimg.com/v2-0f871ff3f5b1af49a74d56caa39a785b_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2184' height='2494'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2184" data-rawheight="2494" class="origin_image zh-lightbox-thumb lazy" width="2184" data-original="https://pic4.zhimg.com/v2-0f871ff3f5b1af49a74d56caa39a785b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0f871ff3f5b1af49a74d56caa39a785b_b.jpg" data-original-token="v2-d8817269dd5e48957ca03c8794e5ec3e"></div><figcaption>AI 用户与 AI 代码助手 prompt</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="PdQV7b8h">除了 agent prompt 和运作模式的设计优化外，作者还设计了 prompt 来自动生成各种角色，场景诉求等内容。这些内容在自动组成各种角色扮演的场景，就能收集到各个场景下 agent 的交互情况，便于后续做进一步的挖掘分析。感兴趣的同学可以在 <a href="https://link.zhihu.com/?target=http%3A//data.camel-ai.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">这个网站</a> 来探索他们已经生成的各种 agent 组合之间的对话记录。这个项目代码也做了开源，会是一个非常好的研究 AI agent 社群研究方向的起点。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-3dbb028cb33164d20aaff5ba6b0c1a65_b.jpg" data-size="normal" data-rawwidth="2210" data-rawheight="1660" class="origin_image zh-lightbox-thumb" width="2210" data-original="https://pic2.zhimg.com/v2-3dbb028cb33164d20aaff5ba6b0c1a65_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2210' height='1660'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2210" data-rawheight="1660" class="origin_image zh-lightbox-thumb lazy" width="2210" data-original="https://pic2.zhimg.com/v2-3dbb028cb33164d20aaff5ba6b0c1a65_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-3dbb028cb33164d20aaff5ba6b0c1a65_b.jpg" data-original-token="v2-f78f362ea18d9620921b46047b2e2148"></div><figcaption>数据生成 prompt</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h3>Generative Agents</h3><p data-pid="l6l-0Arj">而在 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2304.03442" class=" wrap external" target="_blank" rel="nofollow noreferrer">Generative Agents</a> 这篇工作中，作者将 25 个拥有身份设定的模型 agent 组成了一个虚拟小镇社群，每个 agent 都具有记忆系统，并通过做计划，行动应答，自我反思等机制来让他们自由活动，真正来模拟一个社群的运作。从模拟过程来看这个社群也“涌现”了不少真实社会中的现象，非常有意思。</p><p data-pid="Ysk6Ru4Z">从技术角度来说，这篇文章中有几个 agent 行为的设定值得学习：</p><ul><li data-pid="s2s_VyhC">每个 agent 的记忆获取做得更加细致，会结合时效性，重要度和相关度来做相关记忆的召回。相比简单的向量相似度搜索来说效果会好很多。</li><li data-pid="xBFqK_ZT">记忆的存储方面也添加了 reflection 步骤，定期对记忆进行反思总结，保持 agent 的“目标感”。</li><li data-pid="yiTnXVrn">在 plan 生成方面也做了多层级的递归，由粗到细生成接下来的行动计划，跟我们的日常思考模式也更接近。</li><li data-pid="hFxNu2fN">通过“人物采访”的方式来评估这些行为设定的效果，消融实验中都能发现明显的提升。</li></ul><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic3.zhimg.com/v2-4d785241de1d097d8c5ba10b2666fba2_b.jpg" data-size="normal" data-rawwidth="2872" data-rawheight="1062" class="origin_image zh-lightbox-thumb" width="2872" data-original="https://pic3.zhimg.com/v2-4d785241de1d097d8c5ba10b2666fba2_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='2872' height='1062'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2872" data-rawheight="1062" class="origin_image zh-lightbox-thumb lazy" width="2872" data-original="https://pic3.zhimg.com/v2-4d785241de1d097d8c5ba10b2666fba2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4d785241de1d097d8c5ba10b2666fba2_b.jpg" data-original-token="v2-abe6e96570170ffe7481926024083f68"></div><figcaption>Agent 架构</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="5hCLcOCI">这一整套 identity，plan， act/react，reflect，memory stream 的逻辑看起来也挺合理的，与 AutoGPT 的做法可以进行一些互补。当然局限性应该也有不少，比如模拟过程中 agent 之间都是一对一的谈话，而没有会议/广播这种设定。目前模拟运行的时长也有限，比较难确保长时间的运行下 agent 的记忆、行为模式的演化，社群整体目标的探索与推进等方面的效果。</p><p data-pid="oqYUtQtO">从应用角度来看，目前好像也主要集中在社会活动模拟，游戏应用等。是否能拓展到任务处理，知识探索等更广阔的领域，还有待进一步探索。</p><h2>Prompt Patterns</h2><p data-pid="KEKd-n8g">最后我们来总结一下前面这些项目中体现的 prompt 设计模式。</p><ol><li data-pid="uIasu9dx">CoT prompt，在给出指令的过程中，同时也给出执行任务过程的拆解或者样例。这个应该很多人都用过，“let's think step by step”  </li><li data-pid="CWB6JYLC">“自我审视”，提醒模型在产出结果之前，先自我审视一下，看看是否有更好的方案。也可以拿到结果后再调用一下模型强制审视一下。比如 AutoGPT 里的“Constructively self-criticize your big-picture behavior constantly”。</li><li data-pid="z7luH5Dl">分而治之，大家在写 prompt 的时候也发现，越是具体的 context 和目标，模型往往完成得越好。所以把任务拆细再来应用模型，往往比让它一次性把整个任务做完效果要好。利用外部工具，嵌套 agent 等也都是这个角度，也是 CoT 的自然延伸。</li><li data-pid="9_vRbTM0">先计划，后执行。BabyAGI，HuggingGPT 和 Generative Agents 都应用了这个模式。也可以扩展这个模式，例如在计划阶段让模型主动来提出问题，澄清目标，或者给出一些可能的方案，再由人工 review 来进行确认或者给出反馈，减少目标偏离的可能。</li><li data-pid="tWjx0nuQ">记忆系统，包括短期记忆的 scratchpad，长期记忆的 memory stream 的存储、加工和提取等。这个模式同样在几乎所有的 agent 项目里都有应用，也是目前能体现一些模型的实时学习能力的方案。</li></ol><p data-pid="KdjmAbaP">可以看出这些模式都与人类的认知和思考模式有很大的相似性，历史上也有专门做 <a href="https://link.zhihu.com/?target=https%3A//cogarch.ict.usc.edu/" class=" wrap external" target="_blank" rel="nofollow noreferrer">cognitive architecture 相关的研究</a>，从记忆，世界认知，问题解决（行动），感知，注意力，奖励机制，学习等维度来系统性思考智能体的设计。个人感觉目前的 LLM agent 尝中，在奖励机制（是否有比较好的目标指引）和学习进化（是否能持续提升能力）这两方面还有很大的提升空间。或许未来 RL 在模型 agent 这方的应用会有很大的想象空间，而不仅仅是现在主要用来做“价值观对齐”。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript>&lt;img src="https://pic2.zhimg.com/v2-8fd3707e43ddc4afa367ce855ab84205_b.jpg" data-size="normal" data-rawwidth="1259" data-rawheight="1280" class="origin_image zh-lightbox-thumb" width="1259" data-original="https://pic2.zhimg.com/v2-8fd3707e43ddc4afa367ce855ab84205_r.jpg"/&gt;</noscript><div><img src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1259' height='1280'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1259" data-rawheight="1280" class="origin_image zh-lightbox-thumb lazy" width="1259" data-original="https://pic2.zhimg.com/v2-8fd3707e43ddc4afa367ce855ab84205_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-8fd3707e43ddc4afa367ce855ab84205_b.jpg" data-original-token="v2-d180c7da0828c96231f8aa308c9443d2"></div><figcaption>认知架构研究</figcaption></figure><p class="ztext-empty-paragraph"><br></p><h2>常见问题</h2><p data-pid="5x82KwMa">如果大家有实际上手玩过这些项目，应该能切实感受到一些当前模型 agent 的问题和局限性。例如：</p><ol><li data-pid="YW7LXwZV">记忆召回问题。如果只是做简单的 embedding 相似性召回，很容易发现召回的结果不是很好。这里应该也有不少可以改进的空间，例如前面提到的 Generative Agents 里对于记忆的更细致的处理，LlamaIndex 中对于 index 结构的设计也有很多可以选择与调优的地方。</li><li data-pid="VTUg4SP8">错误累积问题。网上给出的很多例子应该都是做了 cherry-picking 的，实际上模型总体表现并没有那么惊艳，反而经常在前面一些步骤就出现了偏差，然后逐渐越跑越远……这里一个很重要的问题可能还是任务拆解执行，外部工具利用等方面的高质量训练数据相对匮乏。这应该也是 OpenAI 为啥要自己来做 plugin 体系的原因之一。</li><li data-pid="2i0haGCv">探索效率问题。对于很多简单的场景，目前通过模型 agent 来自行探索并完成整个解决过程还是比较繁琐耗时，agent 也很容易把问题复杂化。考虑到 LLM 调用的成本，要在实际场景落地使用也还需要在这方面做不少优化。一种方式可能是像 AutoGPT 那样可以中途引入人工的判断干预和反馈输入。</li><li data-pid="JqdmiiB1">任务终止与结果验证。在一些开放性问题或者无法通过明确的评估方式来判断结果的场景下，模型 agent 的工作如何终止也是一个挑战。这也回到了前面提到的，执行 task 相关的数据收集与模型训练以及强化学习的应用或许可以帮助解决这个问题。</li></ol><p data-pid="n0kQi3_g">你在使用这些模型 agent 过程中有碰到过什么样棘手的问题，有什么好的解决方法？或者有没有发现什么场景已经可以由现有的 agent 很好地满足？欢迎在评论区分享交流。</p></div></div></div></div><div class="Post-ReadMark"></div><div role="button" tabindex="0" class="ContentItem-time">编辑于 2023-04-18 20:38<!-- -->・IP 属地浙江</div></article><div class="Post-Sub Post-Sub-Mobile"><div class="css-3rj67r" data-za-detail-view-path-module="CommentList" data-za-extra-module="{}"><div class="css-n51fzv">评论 10 </div><div class="css-5nsq0q"><div class="css-1w5k7wg"><img src="https://pic1.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_s.jpeg" class="css-rdccu8"></div><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true" class="css-entir"><div role="link" tabindex="0" class="css-eh6tr1"><div class="css-1n5v8m5">写评论</div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/fbf7f151797b8a7f1f7aa911c7995d68" class="css-134a7ny"><img src="https://picx.zhimg.com/v2-04fa74a5363eacf3198f8bd11fa02a36_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/fbf7f151797b8a7f1f7aa911c7995d68" class="css-prp5c">王燕飞</div></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10534751222" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">关于模型记忆可以起一个专题讲讲，有些是技术手段，有些是应用背景，可以都讲讲，比如对于搜索检索场景，如果能对现在的gpt插件架构和传统的检索架构做一些survey和讨论，也很有意思</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-19 · </span><span class="css-1vvbddw">IP 属地上海</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10534751222&amp;reply_author_name=%E7%8E%8B%E7%87%95%E9%A3%9E&amp;resource_type=article&amp;reply_comment_id=10534751222"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">1 </span></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/942fe009b1998bfdf02891f1f7c380fc" class="css-134a7ny"><img src="https://pica.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/942fe009b1998bfdf02891f1f7c380fc" class="css-prp5c">码农祺的经世致用</div><a href="https://www.zhihu.com/vip?entry_privileges_type=member_id" class="css-12gckqk"><img src="https://pica.zhimg.com/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg?source=88ceefae" class="css-pjaw30"></a></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10589173710" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">最近又看到一个，data-copilot ，不仅仅使用工具，还自己创造工具来管理数据<a href="https://zhuanlan.zhihu.com/p/636906119" class="internal css-134a7ny"><span class="invisible">https://</span>zhuanlan.zhihu.com/p/636906119</a></div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>昨天 11:10 · </span><span class="css-1vvbddw">IP 属地浙江</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10589173710&amp;reply_author_name=%E7%A0%81%E5%86%9C%E7%A5%BA%E7%9A%84%E7%BB%8F%E4%B8%96%E8%87%B4%E7%94%A8&amp;resource_type=article&amp;reply_comment_id=10589173710"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/96b4303ee4d9f581a9980f9d3a3fb97b" class="css-134a7ny"><img src="https://pic1.zhimg.com/v2-f77e469f6347304a9004ea2f91ad4d66_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/96b4303ee4d9f581a9980f9d3a3fb97b" class="css-prp5c">随意任性</div></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10541641705" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">很赞的一篇总结，强烈推荐</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-27 · </span><span class="css-1vvbddw">IP 属地美国</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10541641705&amp;reply_author_name=%E9%9A%8F%E6%84%8F%E4%BB%BB%E6%80%A7&amp;resource_type=article&amp;reply_comment_id=10541641705"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/7dedf85c6b4b4c1adab1aab05ded5963" class="css-134a7ny"><img src="https://pic1.zhimg.com/v2-da9d3d979b3596369889fa084a684700_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/7dedf85c6b4b4c1adab1aab05ded5963" class="css-prp5c">少女变成猫</div></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10538132200" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">你这个名字让人想到公司...觉得很晦气</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-23 · </span><span class="css-1vvbddw">IP 属地浙江</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10538132200&amp;reply_author_name=%E5%B0%91%E5%A5%B3%E5%8F%98%E6%88%90%E7%8C%AB&amp;resource_type=article&amp;reply_comment_id=10538132200"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/a8c98474680a2a34f274a5a87dd9066b" class="css-134a7ny"><img src="https://picx.zhimg.com/2740a18b7_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/a8c98474680a2a34f274a5a87dd9066b" class="css-prp5c">nklwsy</div><a href="https://www.zhihu.com/vip?entry_privileges_type=member_id" class="css-12gckqk"><img src="https://picx.zhimg.com/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg?source=88ceefae" class="css-pjaw30"></a></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10536973316" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">你申请到gpt4的api了么，用gpt3.5跑这玩意可不太行，输出经常不按照json格式来输出</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-22 · </span><span class="css-1vvbddw">IP 属地陕西</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10536973316&amp;reply_author_name=nklwsy&amp;resource_type=article&amp;reply_comment_id=10536973316"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div><div class="css-v714e6"><div class="css-uliqdc"><div class="css-12uxdu1"><div class="css-i6e8l9"><a href="https://www.zhihu.com/people/489cdc47497cd9db361bcdde600088db" class="css-134a7ny"><img src="https://pic1.zhimg.com/01a4b7296_l.jpg?source=06d4cd63" class="css-1ddviz3"></a></div><div class="css-utmabs"><div class="css-i6a6te"><span class="css-6su6fj">Gong Lei</span></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10536973316" class="css-1d6gsgn"><div role="link" tabindex="0" class="css-e4e808">一直没有申请到 4 的 api，3.5 的结果惨不忍睹</div></div><div class="css-1e8s6ex"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-23 · </span><span class="css-1vvbddw">IP 属地北京</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10536973316&amp;reply_author_name=Gong%20Lei&amp;resource_type=article&amp;reply_comment_id=10538096886&amp;reply_root_comment_id=10536973316"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/c31590adeb22c3637e94d6f7d9643d7e" class="css-134a7ny"><img src="https://picx.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/c31590adeb22c3637e94d6f7d9643d7e" class="css-prp5c">王peter</div><a href="https://www.zhihu.com/vip?entry_privileges_type=member_id" class="css-12gckqk"><img src="https://pica.zhimg.com/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg?source=88ceefae" class="css-pjaw30"></a></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10536361803" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">这么有深度的文章太难得了。作为编程小白，也用2天时间跑通了Auto GPT，包括各种API接口。最让我印象深刻的是那个Pinocone的记忆存储接口。这种接口很像是搜索引擎的逻辑。把每一个网页变成N维向量，然后与你进行搜索的向量进行匹配。感觉下一步的发展应该是这个“记忆GPT”。即把世界上的知识文字，转化成一个超大数据库，真正赋予GPT以“智慧”。</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-20 · </span><span class="css-1vvbddw">IP 属地上海</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10536361803&amp;reply_author_name=%E7%8E%8Bpeter&amp;resource_type=article&amp;reply_comment_id=10536361803"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div><div class="css-v714e6"><div class="css-uliqdc"><div class="css-12uxdu1"><div class="css-i6e8l9"><a href="https://www.zhihu.com/people/a8c98474680a2a34f274a5a87dd9066b" class="css-134a7ny"><img src="https://picx.zhimg.com/2740a18b7_l.jpg?source=06d4cd63" class="css-1ddviz3"></a></div><div class="css-utmabs"><div class="css-i6a6te"><span class="css-6su6fj">nklwsy</span></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10536361803" class="css-1d6gsgn"><div role="link" tabindex="0" class="css-e4e808">你说的是内嵌Embeddings吧，这是openai提供的，可以把一段文字转化为1536维的向量，Pinocone接口只是用来存储和提取数据的</div></div><div class="css-1e8s6ex"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-22 · </span><span class="css-1vvbddw">IP 属地陕西</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10536361803&amp;reply_author_name=nklwsy&amp;resource_type=article&amp;reply_comment_id=10537934853&amp;reply_root_comment_id=10536361803"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">1 </span></div></div></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/c7644dc45cc534235f88d78dc75d43b3" class="css-134a7ny"><img src="https://picx.zhimg.com/f21f8187b_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/c7644dc45cc534235f88d78dc75d43b3" class="css-prp5c">姬契希</div></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10534800646" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">很不错的总结</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-20 · </span><span class="css-1vvbddw">IP 属地美国</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10534800646&amp;reply_author_name=%E5%A7%AC%E5%A5%91%E5%B8%8C&amp;resource_type=article&amp;reply_comment_id=10534800646"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div></div><div class="css-uliqdc"><div class="css-1dnnrwx"><div class="css-15cewoq"><a href="https://www.zhihu.com/people/e7dbb2ce49f1a2a7e14362b903d1f453" class="css-134a7ny"><img src="https://pica.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63" class="css-rdccu8"></a></div><div class="css-1ve1vnk"><div class="css-c4je66"><div href="https://www.zhihu.com/people/e7dbb2ce49f1a2a7e14362b903d1f453" class="css-prp5c">问问和哈哈</div></div><div href="https://www.zhihu.com/comment/list/article/622947810?anchor_comment_id=10534445692" class="css-vjs2sl"><div role="link" tabindex="0" class="css-e4e808">硬核硬核</div></div><div class="css-uliqdc"><div class="css-1kw0tju"></div><div class="css-x8tehl"><div class="css-15psb2p"><span>04-18 · </span><span class="css-1vvbddw">IP 属地广东</span></div><div class="css-n0jssl"><div href="https://www.zhihu.com/comment/list/article/622947810?open_editor=true&amp;anchor_comment_id=10534445692&amp;reply_author_name=%E9%97%AE%E9%97%AE%E5%92%8C%E5%93%88%E5%93%88&amp;resource_type=article&amp;reply_comment_id=10534445692"><div role="link" tabindex="0" class="css-e4e808"><span style="display: inline-flex; align-items: center;">​<svg width="17" height="17" viewBox="0 0 24 24" class="Zi Zi--Comment" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span><span class="css-15fzge">回复</span></div></div><button class="css-q8r6rg" style="transform: none;"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--Like" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 0 1 2.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 0 1-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 0 1 2.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 0 0 3.19-2.191c.115-.296.173-.611.173-.928v-.553Z"></path></svg></button><span class="css-1ejfdqt">赞</span></div></div></div></div></div></div><div href="https://www.zhihu.com/comment/list/article/622947810?" class="css-10ti98u"><div role="link" tabindex="0" class="css-e4e808"></div></div></div><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><img class="Avatar css-1any501" src="https://picx.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-b7a5731b9b518c13c4a82a90453ebaf6_l.jpg?source=172ae18b 2x" alt="RandomGenerator"></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span>RandomGenerator</span></h2></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><img class="Avatar css-1any501" src="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b" srcset="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b 2x" alt="我的ai之路"></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span>我的ai之路</span></h2><div class="ContentItem-meta">作为一名算法工程师正在不断成长！</div></div></div></div></ul></div><div role="complementary" aria-label="推荐阅读" class=""><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class=""><a href="https://zhuanlan.zhihu.com/p/270558067" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">AutoRigPro初探</div><div class="MobilePostItem-Summary u-ellipsis">之前找过一些3dsmax下自动绑骨骼的插件，都不怎么好用，Mixamo要联网没试过。最近才发现Blender的插件AutoRigPro，看了视频演示直呼相见恨晚。初步试用后，觉得效果非常好。操作简单，自动…</div><div class="MobilePostItem-Footer">莫晓天</div></div></a><a href="https://zhuanlan.zhihu.com/p/105609772" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">BGP/MPLS VPN option 方案A B C对比</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">BGP/MPLS VPN option 方案A B C对比 option 方案A B C对比表option…</div><div class="MobilePostItem-Footer">挨踢FA... · 发表于攻城狮小站</div></div><img src="https://picx.zhimg.com/v2-1cfb6d19345fbd8b88111f40b94289af_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-1cfb6d19345fbd8b88111f40b94289af_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/v2-1cfb6d19345fbd8b88111f40b94289af_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="BGP/MPLS VPN option 方案A B C对比"></a><a href="https://zhuanlan.zhihu.com/p/349427371" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">从DIP到DGP，预训练的GAN如何用于底层视觉任务？</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">最近在写ICCV，所以文章好久没有更新了，今天跟大家讨论一个专题，…</div><div class="MobilePostItem-Footer">lam ... · 发表于底层视觉论文笔记</div></div><img src="https://picx.zhimg.com/v2-7f5c043ca49121c93880e34e280e2eee_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-7f5c043ca49121c93880e34e280e2eee_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/v2-7f5c043ca49121c93880e34e280e2eee_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="从DIP到DGP，预训练的GAN如何用于底层视觉任务？"></a><a href="https://zhuanlan.zhihu.com/p/375817564" class="MobilePostItem"><div class="MobilePostItem-Description"><div class="MobilePostItem-Title">【目录序言翻译】GPGPU的性能分析及其调优《Performance Analysis and Turning for GPGPU》</div><div class="MobilePostItem-Summary u-ellipsis" style="display: none;">摘要通用图形处理单元（GPGPU）已成为了一类重要的共享存储并行处…</div><div class="MobilePostItem-Footer">VN V... · 发表于一些计算机科学书的目录与序言翻译</div></div><img src="https://picx.zhimg.com/v2-9f5b8c1a1e4bc33a6e4b2268a96e9943_ipico.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-9f5b8c1a1e4bc33a6e4b2268a96e9943_250x250.jpg?source=172ae18b 2x, https://picx.zhimg.com/v2-9f5b8c1a1e4bc33a6e4b2268a96e9943_ms.jpg?source=172ae18b 3x" class="MobilePostItem-TitleImage" alt="【目录序言翻译】GPGPU的性能分析及其调优《Performance Analysis and Turning for GPGPU》"></a></ul></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 390px; bottom: 0px; left: 16px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;622947810&quot;}}}"><span><button aria-label="赞同 305 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></span>赞同 305</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down VoteButton--mobileDown"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleDown" fill="currentColor"><path fill-rule="evenodd" d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023Z" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Comment Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span>10 条评论</button><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 0 0 .165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 0 0-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 0 0-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 0 0-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 0 0 .164-.12l2.378-4.122Z"></path></svg></span></button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover1-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover1-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Dots Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M5.83 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm7.835 0a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0Zm6.17 1.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z" clip-rule="evenodd"></path></svg></span></button></div></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px; height: 54px;"></div></div></div></div></main></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fapi\u002F","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","allowSignUp":true,"refreshValidityPeriod":"30","release":"824-bcf32e16","currentEntry":"column","isMobileEntry":false,"apollo":{"env":"prod","globalSilence":"","ncgModeSign":"3f8e56febda4fb3bbea72e379d76de1e","topstory_rec_adp":"1","test_canary":"member|0-100,1-0","use_new_player":"member|0-0,1-100","player_vendor":"member|0-0,1-100,2-0","use_hevc":"member|0-0,1-100","upload_use_signature":"member|0-0,1-100","use_backdrop_blur":"member|0-0,1-100","article_title_imagex":"member|0-50,1-50","play_station":"member|0-0,1-100"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"entities":{"users":{"zijie0":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"622947810":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGJ-QhvjYHlDBQ==&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"entityWords":[{"name":"行动计划","mention":"行动计划","matchorder":1,"begin":18008,"end":18012,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJZCgzooYzliqjorqHliJISB1Vua25vd24Y2IwBINyMASgBNQAAAAA6B2FydGljbGVAAEgAUiQxODE3Y2UyMi00MTUyLTQ0ZTEtODdhMC02ODQ0NGZkYjNkYjI=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"语言模型","mention":"语言模型","matchorder":1,"begin":4200,"end":4204,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzor63oqIDmqKHlnosSB1Vua25vd24Y6CAg7CAoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"设计模式","mention":"设计模式","matchorder":1,"begin":18979,"end":18983,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJZCgzorr7orqHmqKHlvI8SB1Vua25vd24Yo5QBIKeUASgBNQAAAAA6B2FydGljbGVAAEgAUiQxODE3Y2UyMi00MTUyLTQ0ZTEtODdhMC02ODQ0NGZkYjNkYjI=","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"启发式规则","mention":"启发式规则","matchorder":1,"begin":15252,"end":15257,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJaCg\u002FlkK\u002Flj5HlvI\u002Fop4TliJkSB1Vua25vd24YlHcgmXcoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"数据库系统","mention":"数据库系统","matchorder":1,"begin":2674,"end":2679,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJaCg\u002FmlbDmja7lupPns7vnu58SB1Vua25vd24Y8hQg9xQoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"开源项目","mention":"开源项目","matchorder":1,"begin":3025,"end":3029,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzlvIDmupDpobnnm64SB1Vua25vd24Y0Rcg1RcoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"业务流程","mention":"业务流程","matchorder":1,"begin":15260,"end":15264,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzkuJrliqHmtYHnqIsSB1Vua25vd24YnHcgoHcoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"程序员","mention":"程序员","matchorder":1,"begin":15836,"end":15839,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJUCgnnqIvluo\u002FlkZgSB1Vua25vd24Y3Hsg33soATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"知行合一","mention":"知行合一","matchorder":1,"begin":348,"end":352,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgznn6XooYzlkIjkuIASB1Vua25vd24Y3AIg4AIoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"代码生成","mention":"代码生成","matchorder":1,"begin":10481,"end":10485,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzku6PnoIHnlJ\u002FmiJASB1Vua25vd24Y8VEg9VEoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"行为模式","mention":"行为模式","matchorder":1,"begin":15546,"end":15550,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzooYzkuLrmqKHlvI8SB1Vua25vd24YunkgvnkoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"语义搜索","mention":"语义搜索","matchorder":1,"begin":2880,"end":2884,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzor63kuYnmkJzntKISB1Vua25vd24YwBYgxBYoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"数学计算","mention":"数学计算","matchorder":1,"begin":1217,"end":1221,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJXCgzmlbDlraborqHnrpcSB1Vua25vd24YwQkgxQkoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""},{"name":"大局观","mention":"大局观","matchorder":1,"begin":11121,"end":11124,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Unknown","score":0,"attachedInfoBytes":"sgJUCgnlpKflsYDop4ISB1Vua25vd24Y8VYg9FYoATUAAAAAOgdhcnRpY2xlQABIAFIkMTgxN2NlMjItNDE1Mi00NGUxLTg3YTAtNjg0NDRmZGIzZGIy","isOnAB":false,"isNatural":1,"isDelete":false,"contentType":"","contentId":"","contentToken":""}],"id":622947810,"title":"AutoGPT与LLM Agent解析","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F622947810","imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-1e36a1bfc750cd1b5acd76cb211b95e7_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-1e36a1bfc750cd1b5acd76cb211b95e7_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e8959c5e758a693db12e9e81a947f9c4_200x112.png\" data-caption=\"典型的 ReAct prompt\" data-size=\"normal\" data-rawwidth=\"2530\" data-rawheight=\"2488\" data-watermark=\"watermark\" data-original-src=\"v2-e8959c5e758a693db12e9e81a947f9c4\" data-watermark-src=\"v2-a5d133b8902cbe430ddf8f117871b635\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e8959c5e758a693db12e9e81a947f9c4_r.png\"\u002F\u003E前两周 AutoGPT，BabyAGI 等项目异常火爆，周末也正好花了点时间来看了下这些 AI agent 类项目的代码，写篇文章来总结一下对于当前这类项目进展的技术角度认识和思考，与大家一同交流。 从语言理解到任务执行之前大多相关项目和产品都主要利用了 GPT 模型的…","created":1681820749,"updated":1681821513,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"1055464808517865473","medalName":"专业","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b42f593c6ccee918d956a183eed2ffd7_l.png?source=172ae18b","description":"回答收到「专业认可」即可获得","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","ipInfo":"IP 属地浙江","imageWidth":1344,"imageHeight":896,"content":"\u003Cp data-pid=\"v7BW6Vwt\"\u003E前两周 AutoGPT，BabyAGI 等项目异常火爆，周末也正好花了点时间来看了下这些 AI agent 类项目的代码，写篇文章来总结一下对于当前这类项目进展的技术角度认识和思考，与大家一同交流。\u003C\u002Fp\u003E\u003Ch2\u003E从语言理解到任务执行\u003C\u002Fh2\u003E\u003Cp data-pid=\"WF7iTVA_\"\u003E之前大多相关项目和产品都主要利用了 GPT 模型的语言理解方面的能力，例如生成文案的 Jasper，Notion AI，帮忙做网页、文档总结的 Glarity，Bearly.ai，做问答的 New Bing，ChatPDF 等。后续想要拓展 GPT 的应用范围，一个很自然的方向就是让 GPT 能够学会自己使用各种外部工具，来进行更广泛的任务类型的执行，做到“知行合一” 。除了上面提到的 AutoGPT 和 BabyAGI，还有很多有意思的项目如 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2302.04761\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EToolformer\u003C\u002Fa\u003E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fmicrosoft\u002FJARVIS\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EHuggingGPT\u003C\u002Fa\u003E，\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fmicrosoft\u002Fvisual-chatgpt\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EVisual ChatGPT\u003C\u002Fa\u003E 等都在尝试这个方向。\u003C\u002Fp\u003E\u003Cp data-pid=\"z8dvO_UQ\"\u003E这个任务执行说起来原理也不复杂，基本的套路还是让 GPT 去做生成，只不过我们会在 Prompt 中告诉 GPT，如果你需要调用一些外部工具，那么就按照特定的格式来生成一些指令\u002F代码，程序接收到之后，再根据 GPT 生成的内容去调用外部工具并获得相应结果，这个结果再作为输入可以由 GPT 去做进一步的理解和生成，循环往复。以 LangChain 里最常见的 ReAct prompt 为例，输入给模型的内容如下：\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-text\"\u003E...\n你可以使用如下工具来完成任务：\n\n1. 计算器，用来执行各种数学计算获取精确结果，输入表达式，例如 1 + 1，得到结果\n...\n\n问题：123 乘以 456 的结果是多少？\n...\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp data-pid=\"DBmRy4Hz\"\u003E模型生成的内容如下：\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-text\"\u003E思考：我需要使用计算器来计算 123 乘以 456 的结果\n动作：调用计算器\n动作输入：123 * 456\n观测结果：\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp data-pid=\"gxGETQWi\"\u003E然后我们可以处理这段返回，调用计算器程序，拿到 123 * 456 的结果，然后将结果填写到观测结果后面，再让模型继续生成下一段内容。\u003C\u002Fp\u003E\u003Cp data-pid=\"YNnKTqxG\"\u003E这就是基本的任务执行的方法。更多内容也可以参考我之前对于 LangChain 的一些分享：\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.bilibili.com\u002Fvideo\u002FBV1DY4y1Q7Te\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E微软 365 Copilot 是如何实现的？揭秘 LLM 如何生成指令\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5d133b8902cbe430ddf8f117871b635_b.jpg\" data-size=\"normal\" data-rawwidth=\"2530\" data-rawheight=\"2488\" class=\"origin_image zh-lightbox-thumb\" width=\"2530\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5d133b8902cbe430ddf8f117871b635_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2530&#39; height=&#39;2488&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2530\" data-rawheight=\"2488\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2530\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5d133b8902cbe430ddf8f117871b635_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5d133b8902cbe430ddf8f117871b635_b.jpg\" data-original-token=\"v2-e8959c5e758a693db12e9e81a947f9c4\"\u002F\u003E\u003Cfigcaption\u003E典型的 ReAct prompt\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E模型记忆\u003C\u002Fh2\u003E\u003Cp data-pid=\"MHFsKRaz\"\u003E另外一类非常常见的模式是通过外部存储来增强模型记忆。其中一个典型场景是长 session 的聊天过程，由于 GPT API 本身的输入信息有 4000 个 token 的限制，所以当聊天进行比较久之后，用户经常会发现 ChatGPT 已经“忘了”之前讲过的内容。另外一个典型场景是给 LLM 提供更多的新信息，像一些产品里能够对一整篇 PDF 甚至一整个知识库里的内容做理解和问答，那么自然不可能直接把所有这些额外信息都直接在 prompt 里扔给 GPT 去处理。\u003C\u002Fp\u003E\u003Cp data-pid=\"Y-04tgmn\"\u003E这时候就需要通过外部存储来帮助 GPT 拓展记忆。最简单的方法就是直接把这些对话记录，外部信息等以文本形式保存到文件或者数据库系统里，后续在与模型进行交互时，可以按需去获取这些外部存储中的信息。我们可以把 prompt 里的内容当成模型的“短期记忆”，那么这些外部存储自然就成为了“长期记忆”。除了前面提到的好处外，这种记忆系统模式还能一定程度上起到降低模型 hallucinations 的作用，避免纯粹依靠“生成”来实现任务目标。\u003C\u002Fp\u003E\u003Cp data-pid=\"pqnWFL9q\"\u003E获取长期记忆的方法，目前最常见的方式是通过“语义搜索”。大概意思就是利用一个 embedding 模型，将所有的记忆文本都转化为一个向量。而后续跟模型的交互信息也可以通过同样的 embedding 模型转化为向量，然后通过计算相似度来找到最相似的记忆文本。最后再将这些记忆文本拼接到 prompt 里，作为模型的输入。这类方法最热门的开源项目可以参考 OpenAI 官方的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fopenai\u002Fchatgpt-retrieval-plugin\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EChatGPT Retrieval Plugin\u003C\u002Fa\u003E 和 Jerry Liu 的 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fjerryjliu\u002Fllama_index\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ELlamaIndex\u003C\u002Fa\u003E。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3742a095fdd75d3c3a66faecbb690575_b.jpg\" data-size=\"normal\" data-rawwidth=\"4062\" data-rawheight=\"1828\" class=\"origin_image zh-lightbox-thumb\" width=\"4062\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3742a095fdd75d3c3a66faecbb690575_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;4062&#39; height=&#39;1828&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"4062\" data-rawheight=\"1828\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"4062\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3742a095fdd75d3c3a66faecbb690575_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3742a095fdd75d3c3a66faecbb690575_b.jpg\" data-original-token=\"v2-2de22c9b5ca4ae995c091cc49a59c9bd\"\u002F\u003E\u003Cfigcaption\u003ERetrieval Pattern\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"-hNG5WRk\"\u003E这种拓展模型记忆的模式相比人类大脑的运作方式来说感觉还有些“粗糙”，所谓的长期与短期记忆（包括 LangChain 与 LlamaIndex 中一些更复杂的实现），仍然是比较“hard coded”的感觉。如果未来在模型 context size 上有突破性的研究进展，那么当前的这类模式或许就不再需要了。\u003C\u002Fp\u003E\u003Cp data-pid=\"reXEJqKB\"\u003E从整体的交互流程来看，这类模型记忆实现模式也可以看作是一种“任务执行”的方式，只不过这里的任务是“写入\u002F获取记忆”，而不是“执行某个外部工具”。我们可以把两者统一来看，也就是当前大语言模型最常用的应用开发模式。后面我们也会看到，各种所谓的智能 agent 也都是在这个思路下进行拓展实现的。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-670e38abdbd8e6686adcc2c35aea66c2_b.jpg\" data-size=\"normal\" data-rawwidth=\"2110\" data-rawheight=\"1612\" class=\"origin_image zh-lightbox-thumb\" width=\"2110\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-670e38abdbd8e6686adcc2c35aea66c2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2110&#39; height=&#39;1612&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2110\" data-rawheight=\"1612\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2110\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-670e38abdbd8e6686adcc2c35aea66c2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-670e38abdbd8e6686adcc2c35aea66c2_b.jpg\" data-original-token=\"v2-3129260d55eeb003642fa296a099649c\"\u002F\u003E\u003Cfigcaption\u003ELLM 调用外部工具的应用模式\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"4IZPJwNy\"\u003E有意思的是，OpenAI 的 Jack Rae 和 Ilya Sutskever 在之前的分享中也分别提到了 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.youtube.com\u002Fwatch%3Fv%3DdO4TPJkeaaU\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E压缩即智慧\u003C\u002Fa\u003E 的理念。对于模型的“压缩率”来说，如果能更有效地使用这些“外部工具”，就能大幅提升很多特定任务 next token 预测的准确率。个人感觉这个方向的发展还有非常大的空间，例如从“有效数据”角度看，人类执行各类任务使用工具，甚至思维过程等数据会有非常高的价值。而从模型训练角度来看，如何能在过程中把模型利用工具的能力也体现在 loss function 里，可能也是个很有趣的方向。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-06fe12da5124690ef0bcba8b8531d618_b.jpg\" data-size=\"normal\" data-rawwidth=\"4062\" data-rawheight=\"1900\" class=\"origin_image zh-lightbox-thumb\" width=\"4062\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-06fe12da5124690ef0bcba8b8531d618_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;4062&#39; height=&#39;1900&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"4062\" data-rawheight=\"1900\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"4062\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-06fe12da5124690ef0bcba8b8531d618_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-06fe12da5124690ef0bcba8b8531d618_b.jpg\" data-original-token=\"v2-832efe1eca0848dc9cc3d516aaedf91d\"\u002F\u003E\u003Cfigcaption\u003E提升“压缩率”的手段\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003EAutoGPT\u003C\u002Fh2\u003E\u003Cp data-pid=\"Y9gBzrPW\"\u003E有了前面的铺垫信息，我们来理解 AutoGPT 这类 AI agent 工作的内部结构与核心逻辑就会比较容易了。这类项目绝大多数的主要创新还是在 prompt 层面，通过更好的提示词来激发模型的能力，把更多原先需要通过代码来实现的流程“硬逻辑”转化为模型自动生成的“动态逻辑”。以 AutoGPT 为例，它的核心 prompt 如下：\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-text\"\u003EYou are Guandata-GPT, &#39;an AI assistant designed to help data analysts do their daily work.&#39;\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n\nGOALS:\n\n1. &#39;Process data sets&#39;\n2. &#39;Generate data reports and visualizations&#39;\n3. &#39;Analyze reports to gain business insights&#39;\n\nConstraints:\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n3. No user assistance\n4. Exclusively use the commands listed in double quotes e.g. &#34;command name&#34;\n\nCommands:\n1. Google Search: &#34;google&#34;, args: &#34;input&#34;: &#34;&lt;search&gt;&#34;\n2. Browse Website: &#34;browse_website&#34;, args: &#34;url&#34;: &#34;&lt;url&gt;&#34;, &#34;question&#34;: &#34;&lt;what_you_want_to_find_on_website&gt;&#34;\n3. Start GPT Agent: &#34;start_agent&#34;, args: &#34;name&#34;: &#34;&lt;name&gt;&#34;, &#34;task&#34;: &#34;&lt;short_task_desc&gt;&#34;, &#34;prompt&#34;: &#34;&lt;prompt&gt;&#34;\n4. Message GPT Agent: &#34;message_agent&#34;, args: &#34;key&#34;: &#34;&lt;key&gt;&#34;, &#34;message&#34;: &#34;&lt;message&gt;&#34;\n5. List GPT Agents: &#34;list_agents&#34;, args: \n6. Delete GPT Agent: &#34;delete_agent&#34;, args: &#34;key&#34;: &#34;&lt;key&gt;&#34;\n7. Clone Repository: &#34;clone_repository&#34;, args: &#34;repository_url&#34;: &#34;&lt;url&gt;&#34;, &#34;clone_path&#34;: &#34;&lt;directory&gt;&#34;\n8. Write to file: &#34;write_to_file&#34;, args: &#34;file&#34;: &#34;&lt;file&gt;&#34;, &#34;text&#34;: &#34;&lt;text&gt;&#34;\n9. Read file: &#34;read_file&#34;, args: &#34;file&#34;: &#34;&lt;file&gt;&#34;\n10. Append to file: &#34;append_to_file&#34;, args: &#34;file&#34;: &#34;&lt;file&gt;&#34;, &#34;text&#34;: &#34;&lt;text&gt;&#34;\n11. Delete file: &#34;delete_file&#34;, args: &#34;file&#34;: &#34;&lt;file&gt;&#34;\n12. Search Files: &#34;search_files&#34;, args: &#34;directory&#34;: &#34;&lt;directory&gt;&#34;\n13. Evaluate Code: &#34;evaluate_code&#34;, args: &#34;code&#34;: &#34;&lt;full_code_string&gt;&#34;\n14. Get Improved Code: &#34;improve_code&#34;, args: &#34;suggestions&#34;: &#34;&lt;list_of_suggestions&gt;&#34;, &#34;code&#34;: &#34;&lt;full_code_string&gt;&#34;\n15. Write Tests: &#34;write_tests&#34;, args: &#34;code&#34;: &#34;&lt;full_code_string&gt;&#34;, &#34;focus&#34;: &#34;&lt;list_of_focus_areas&gt;&#34;\n16. Execute Python File: &#34;execute_python_file&#34;, args: &#34;file&#34;: &#34;&lt;file&gt;&#34;\n17. Generate Image: &#34;generate_image&#34;, args: &#34;prompt&#34;: &#34;&lt;prompt&gt;&#34;\n18. Send Tweet: &#34;send_tweet&#34;, args: &#34;text&#34;: &#34;&lt;text&gt;&#34;\n19. Do Nothing: &#34;do_nothing&#34;, args: \n20. Task Complete (Shutdown): &#34;task_complete&#34;, args: &#34;reason&#34;: &#34;&lt;reason&gt;&#34;\n\nResources:\n1. Internet access for searches and information gathering.\n2. Long Term memory management.\n3. GPT-3.5 powered Agents for delegation of simple tasks.\n4. File output.\n\nPerformance Evaluation:\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n2. Constructively self-criticize your big-picture behavior constantly.\n3. Reflect on past decisions and strategies to refine your approach.\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n\nYou should only respond in JSON format as described below \nResponse Format: \n{\n    &#34;thoughts&#34;: {\n        &#34;text&#34;: &#34;thought&#34;,\n        &#34;reasoning&#34;: &#34;reasoning&#34;,\n        &#34;plan&#34;: &#34;- short bulleted\\n- list that conveys\\n- long-term plan&#34;,\n        &#34;criticism&#34;: &#34;constructive self-criticism&#34;,\n        &#34;speak&#34;: &#34;thoughts summary to say to user&#34;\n    },\n    &#34;command&#34;: {\n        &#34;name&#34;: &#34;command name&#34;,\n        &#34;args&#34;: {\n            &#34;arg name&#34;: &#34;value&#34;\n        }\n    }\n} \nEnsure the response can be parsed by Python json.loads\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp data-pid=\"qadTZNUu\"\u003E从这大段的 prompt 可以看出来，AutoGPT 的确算得上是提示词应用模式当前比较先进的“集大成者”了，有很多可以学习的地方。相比经典的 reason + act 模式，我们可以分别来看看它都做了哪些进一步的发展改进。\u003C\u002Fp\u003E\u003Ch3\u003EConstraints &amp; Resources\u003C\u002Fh3\u003E\u003Cp data-pid=\"2Jb8BGEH\"\u003E在这里告诉了模型你自己的各种局限性，也是很有喜感。例如模型的输入 context size 有限制，所以你需要把重要的信息保存到文件里。尤其在代码生成场景中这个动作非常重要，否则无法实现长代码的生成和执行。另外 AutoGPT 里也给模型提供了长期记忆的管理功能，当前这类复杂 prompt 生成的解决任务的流程往往比较冗长，没有这类长期记忆的管理很容易就会导致模型的输出变得不连贯协调。\u003C\u002Fp\u003E\u003Cp data-pid=\"sX737LGu\"\u003E另外像默认的模型是“没有联网”的，所有的知识只更新到训练数据的截止日期。所以也明确告诉模型可以通过网络搜索来获取更多时效性的外部信息。\u003C\u002Fp\u003E\u003Ch3\u003ECommands\u003C\u002Fh3\u003E\u003Cp data-pid=\"U-9J01LS\"\u003E在 commands 也就是各类工具的选择上，这里给出的选项非常丰富。这也是为何很多文章宣传里提到 AutoGPT 能够完成多种不同任务的原因之一，灵活性与通用性很高。\u003C\u002Fp\u003E\u003Cp data-pid=\"83AG-xZ0\"\u003E具体的 commands 中，可以分为几大类，包括搜索、浏览网页相关，启动其它的 GPT agent，文件读写操作，代码生成与执行等。使用其它的 agent 的想法跟 HuggingGPT 有些类似，因为目前 GPT 模型对于越具体，细致的任务，生成的表现就越精确和稳定。所以这种“分而治之”的思路，是很有必要的。\u003C\u002Fp\u003E\u003Ch3\u003EPerformance Evaluation\u003C\u002Fh3\u003E\u003Cp data-pid=\"BJCc_t9B\"\u003E这里给出了模型整体思考流程的指导原则，分为了几个具体维度，包括对自己的能力与行为的匹配进行 review，大局观与自我反思，结合长期记忆对决策动作进行优化，以及尽可能高效率地用较少的动作来完成任务。这个思考逻辑也非常符合人类的思考，决策与反馈迭代的过程。\u003C\u002Fp\u003E\u003Ch3\u003EResponse\u003C\u002Fh3\u003E\u003Cp data-pid=\"nBiIG2l2\"\u003E从 response 格式上来看，也是综合了几种模式，包括需要把自己的想法写出来，做一些 reasoning 获取相关背景知识，生成有具体步骤的 plan，以及对自己的思考过程进行 criticism 等。这些格式的限定也是对前面思维指导原则的具体操作规范说明。\u003C\u002Fp\u003E\u003Cp data-pid=\"ojsrh11r\"\u003E具体 command 的生成与前面提到的 ReAct 方式基本一致。这里的 command 也是可以嵌套的，比如可以在一个 command 中启动另一个 GPT agent，然后再对这个 agent 发送 message，这样就可以实现更复杂的任务了。而在 LangChain 里，子 agent 与主流程之间应该只有一次调用和返回，相对来说比较受局限。\u003C\u002Fp\u003E\u003Cp data-pid=\"DKZ1-EpS\"\u003E值得注意的是这么一大段 response 是模型一次交互生成的，而不像一些其它框架中会把计划，审视，动作生成等通过多轮模型交互来生成。个人感觉是因为 AutoGPT 生成的解决流程往往会非常冗长，如果每一个动作的生成都需要与 LLM 做多轮交互，耗费的时间和 token 量都会非常大。但如果某个具体决策动作的开销非常大，例如需要调用一个比较贵的 API 做图片生成，那么可能把这个动作做多次审视优化，最后做一次决策，可能整体成本会更低一些。\u003C\u002Fp\u003E\u003Ch3\u003E人工介入\u003C\u002Fh3\u003E\u003Cp data-pid=\"660nhDmd\"\u003E如果大家自己跑过 AutoGPT，会发现模型很容易会把问题复杂化或者在执行计划层面“跑偏”。所以在具体执行过程中，AutoGPT 也允许用户来介入，对于每一个具体执行步骤提供额外的输入来指导模型行为。经过人工反馈输入后，模型会重新生成上述的 response，以此往复。大家可以访问这个 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgodmode.space\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E带界面的 AutoGPT 产品\u003C\u002Fa\u003E，实际体验一下这个流程。虽然从实际完成任务角度来看还在比较早期的阶段，但这个 prompt 的设计和交互方式还是挺有启发性的。\u003C\u002Fp\u003E\u003Ch2\u003EBabyAGI\u003C\u002Fh2\u003E\u003Cp data-pid=\"5b1Extdt\"\u003E相比 AutoGPT 来说，BabyAGI 是一个相对更聚焦在“思维流程”方面尝试的项目，并没有添加对各种外部工具利用的支持。其核心逻辑非常简单：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli data-pid=\"hp3oKfIZ\"\u003E从任务列表中获取排在第一位的任务。\u003C\u002Fli\u003E\u003Cli data-pid=\"aVrH89wS\"\u003E获取任务相关的“记忆”信息，由任务执行 agent 来执行这个任务，获取结果。目前这个执行就是一个简单的 LLM 调用，不涉及外部工具。\u003C\u002Fli\u003E\u003Cli data-pid=\"MHgDBaiC\"\u003E将返回结果再存放到记忆存储中。\u003C\u002Fli\u003E\u003Cli data-pid=\"DcGpqfdF\"\u003E基于当前的信息，如整体目标，最近一次执行结果，任务描述，还未执行的任务列表等，生成所需要的新任务。\u003C\u002Fli\u003E\u003Cli data-pid=\"RaI_PqD_\"\u003E将新任务添加到任务列表中，再判断所有任务的优先级，重新排序。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp data-pid=\"VDVytWML\"\u003E作者表示这个过程就是在模拟他一天真实的工作流程。早上起来看下有哪些任务要做，白天做任务拿反馈，晚上再看下基于反馈有没有新的任务要加进来，然后重新排下优先级。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fc665ce2bae6d064e16ae444a5096ff0_b.jpg\" data-size=\"normal\" data-rawwidth=\"1970\" data-rawheight=\"1618\" class=\"origin_image zh-lightbox-thumb\" width=\"1970\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fc665ce2bae6d064e16ae444a5096ff0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1970&#39; height=&#39;1618&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1970\" data-rawheight=\"1618\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1970\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fc665ce2bae6d064e16ae444a5096ff0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fc665ce2bae6d064e16ae444a5096ff0_b.jpg\" data-original-token=\"v2-629620a3d4cd0f0b292c0e29098b6f93\"\u002F\u003E\u003Cfigcaption\u003EBabyAGI 运作流程\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"yi2e-lXE\"\u003E整个项目的代码量很少，相关的 prompts 也比较简单易懂，有兴趣的同学可以自行阅读。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a6a493784c7c41d553390551e64f9f4d_b.jpg\" data-size=\"normal\" data-rawwidth=\"2210\" data-rawheight=\"1538\" class=\"origin_image zh-lightbox-thumb\" width=\"2210\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a6a493784c7c41d553390551e64f9f4d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2210&#39; height=&#39;1538&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2210\" data-rawheight=\"1538\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2210\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a6a493784c7c41d553390551e64f9f4d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a6a493784c7c41d553390551e64f9f4d_b.jpg\" data-original-token=\"v2-93ae48ddb742777dd8f9f7dfb5e22741\"\u002F\u003E\u003Cfigcaption\u003EBabyAGI prompts 示例\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"6vvbYHbA\"\u003E后续也出现了一些在这个项目上的进化版本，例如这个 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Foliveirabruno01\u002Fbabyagi-asi\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EBabyASI\u003C\u002Fa\u003E，借鉴了 AutoGPT 添加了对 search，代码执行等工具的支持。理论上来说，如果这个 ASI（Artificial Super Intelligence）真的足够聪明，甚至可以产生代码给自己做 prompt 优化，流程改造，甚至持续的模型训练等，让 GPT 自己开发未来的 GPT，想想是不是很带感 。\u003C\u002Fp\u003E\u003Ch2\u003EHuggingGPT\u003C\u002Fh2\u003E\u003Cp data-pid=\"LUVs331-\"\u003E如果说 BabyAGI 更多的是探索了 plan &amp; execution 这个应用 LLM 的模式，那么 HuggingGPT 这个相对早一些的工作更多地展示了在“外部工具”这个层面的想象空间。其核心运作逻辑也是计划加上执行，只不过在执行工具层面，可以利用丰富的“领域专业模型”来协助 LLM 更好地完成复杂任务，如下图所示：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-512ef42cf0d983c518d3d47d2638dbbe_b.jpg\" data-size=\"normal\" data-rawwidth=\"1246\" data-rawheight=\"1240\" class=\"origin_image zh-lightbox-thumb\" width=\"1246\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-512ef42cf0d983c518d3d47d2638dbbe_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1246&#39; height=&#39;1240&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1246\" data-rawheight=\"1240\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1246\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-512ef42cf0d983c518d3d47d2638dbbe_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-512ef42cf0d983c518d3d47d2638dbbe_b.jpg\" data-original-token=\"v2-1bd0fee0a05d861d146c08595d3332dc\"\u002F\u003E\u003Cfigcaption\u003EHuggingGPT 流程\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"6WdYVRY-\"\u003E通过作者给出的各种例子，可以看出 LLM 能够很好地理解任务并调用相应模型来解决。虽然很多例子可能会被后来多模态的 GPT 系列通过端到端的方式直接完成，但这个想法还是挺有意思的。外部工具不仅仅局限于搜索，API 调用这些，也可以调用其他复杂的模型。未来或许不光能调用模型，还能触发数据收集，模型训练\u002F微调等动作，完成更加复杂的任务流程。\u003C\u002Fp\u003E\u003Cp data-pid=\"9Zk60Fzt\"\u003E从另一个角度看，对于一些目标明确，专业化且高频的场景，往往具有丰富的数据，可以通过构建一个更小的专有模型来很好地以较低成本来完成相关诉求。而像一些更加模糊，需求多变的“胖尾”诉求，就可以更好地利用大模型强大的理解，推理，生成能力来满足，未来或许会替换到很多当基于启发式规则驱动的业务流程。这或许是未来大模型与小模型的一种常见组合应用形态。\u003C\u002Fp\u003E\u003Ch2\u003ECamel \u002F Generative Agents\u003C\u002Fh2\u003E\u003Cp data-pid=\"8JBCFjbx\"\u003E在前面 AutoGPT 里，我们看到了一些给模型 agent 加上长期记忆，以及调用其它 agent 进行交互的玩法。另外在前面的 prompt 模式中也发现，让模型进行自我审视，或者先计划再执行的方式往往能达到非常好的效果提升。如果沿着这个方向进一步推演，是否可以将多个 agent 组成一个团队，分别扮演不同的角色，是否能更好地解决一些复杂问题，甚至让这个小的“社群”演化出一些更复杂的行为模式甚至新知识的发现？最近就有两篇很火的工作跟 agent“社群”的方向相关。\u003C\u002Fp\u003E\u003Ch3\u003ECamel\u003C\u002Fh3\u003E\u003Cp data-pid=\"xqaZwiwl\"\u003E在 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.camel-ai.org\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ECamel\u003C\u002Fa\u003E 这篇工作中，作者的思路是通过 LLM 来模拟用户和 AI 助手，让两个 agent 进行角色扮演（例如一个是业务专家，一个是程序员），然后让他们自主沟通协作来完成一项具体的任务。这个想法还是比较直接的，不过作者也提到 prompt 的设计还是蛮重要的，否则很容易出现角色转换，重复指令，消息无限循环，有瑕疵的回复，何时终止对话等等问题。有兴趣的同学可以具体看项目代码中给出的 prompt 设定，添加了非常多的明确指令来让 agent 按照预想的设定来沟通协作。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0f871ff3f5b1af49a74d56caa39a785b_b.jpg\" data-size=\"normal\" data-rawwidth=\"2184\" data-rawheight=\"2494\" class=\"origin_image zh-lightbox-thumb\" width=\"2184\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0f871ff3f5b1af49a74d56caa39a785b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2184&#39; height=&#39;2494&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2184\" data-rawheight=\"2494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2184\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0f871ff3f5b1af49a74d56caa39a785b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0f871ff3f5b1af49a74d56caa39a785b_b.jpg\" data-original-token=\"v2-d8817269dd5e48957ca03c8794e5ec3e\"\u002F\u003E\u003Cfigcaption\u003EAI 用户与 AI 代码助手 prompt\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"PdQV7b8h\"\u003E除了 agent prompt 和运作模式的设计优化外，作者还设计了 prompt 来自动生成各种角色，场景诉求等内容。这些内容在自动组成各种角色扮演的场景，就能收集到各个场景下 agent 的交互情况，便于后续做进一步的挖掘分析。感兴趣的同学可以在 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=http%3A\u002F\u002Fdata.camel-ai.org\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E这个网站\u003C\u002Fa\u003E 来探索他们已经生成的各种 agent 组合之间的对话记录。这个项目代码也做了开源，会是一个非常好的研究 AI agent 社群研究方向的起点。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3dbb028cb33164d20aaff5ba6b0c1a65_b.jpg\" data-size=\"normal\" data-rawwidth=\"2210\" data-rawheight=\"1660\" class=\"origin_image zh-lightbox-thumb\" width=\"2210\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3dbb028cb33164d20aaff5ba6b0c1a65_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2210&#39; height=&#39;1660&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2210\" data-rawheight=\"1660\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2210\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3dbb028cb33164d20aaff5ba6b0c1a65_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-3dbb028cb33164d20aaff5ba6b0c1a65_b.jpg\" data-original-token=\"v2-f78f362ea18d9620921b46047b2e2148\"\u002F\u003E\u003Cfigcaption\u003E数据生成 prompt\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003EGenerative Agents\u003C\u002Fh3\u003E\u003Cp data-pid=\"l6l-0Arj\"\u003E而在 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fabs\u002F2304.03442\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EGenerative Agents\u003C\u002Fa\u003E 这篇工作中，作者将 25 个拥有身份设定的模型 agent 组成了一个虚拟小镇社群，每个 agent 都具有记忆系统，并通过做计划，行动应答，自我反思等机制来让他们自由活动，真正来模拟一个社群的运作。从模拟过程来看这个社群也“涌现”了不少真实社会中的现象，非常有意思。\u003C\u002Fp\u003E\u003Cp data-pid=\"Ysk6Ru4Z\"\u003E从技术角度来说，这篇文章中有几个 agent 行为的设定值得学习：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli data-pid=\"s2s_VyhC\"\u003E每个 agent 的记忆获取做得更加细致，会结合时效性，重要度和相关度来做相关记忆的召回。相比简单的向量相似度搜索来说效果会好很多。\u003C\u002Fli\u003E\u003Cli data-pid=\"xBFqK_ZT\"\u003E记忆的存储方面也添加了 reflection 步骤，定期对记忆进行反思总结，保持 agent 的“目标感”。\u003C\u002Fli\u003E\u003Cli data-pid=\"yiTnXVrn\"\u003E在 plan 生成方面也做了多层级的递归，由粗到细生成接下来的行动计划，跟我们的日常思考模式也更接近。\u003C\u002Fli\u003E\u003Cli data-pid=\"hFxNu2fN\"\u003E通过“人物采访”的方式来评估这些行为设定的效果，消融实验中都能发现明显的提升。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4d785241de1d097d8c5ba10b2666fba2_b.jpg\" data-size=\"normal\" data-rawwidth=\"2872\" data-rawheight=\"1062\" class=\"origin_image zh-lightbox-thumb\" width=\"2872\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4d785241de1d097d8c5ba10b2666fba2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2872&#39; height=&#39;1062&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2872\" data-rawheight=\"1062\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2872\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4d785241de1d097d8c5ba10b2666fba2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4d785241de1d097d8c5ba10b2666fba2_b.jpg\" data-original-token=\"v2-abe6e96570170ffe7481926024083f68\"\u002F\u003E\u003Cfigcaption\u003EAgent 架构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"5hCLcOCI\"\u003E这一整套 identity，plan， act\u002Freact，reflect，memory stream 的逻辑看起来也挺合理的，与 AutoGPT 的做法可以进行一些互补。当然局限性应该也有不少，比如模拟过程中 agent 之间都是一对一的谈话，而没有会议\u002F广播这种设定。目前模拟运行的时长也有限，比较难确保长时间的运行下 agent 的记忆、行为模式的演化，社群整体目标的探索与推进等方面的效果。\u003C\u002Fp\u003E\u003Cp data-pid=\"oqYUtQtO\"\u003E从应用角度来看，目前好像也主要集中在社会活动模拟，游戏应用等。是否能拓展到任务处理，知识探索等更广阔的领域，还有待进一步探索。\u003C\u002Fp\u003E\u003Ch2\u003EPrompt Patterns\u003C\u002Fh2\u003E\u003Cp data-pid=\"KEKd-n8g\"\u003E最后我们来总结一下前面这些项目中体现的 prompt 设计模式。\u003C\u002Fp\u003E\u003Col\u003E\u003Cli data-pid=\"uIasu9dx\"\u003ECoT prompt，在给出指令的过程中，同时也给出执行任务过程的拆解或者样例。这个应该很多人都用过，“let&#39;s think step by step”  \u003C\u002Fli\u003E\u003Cli data-pid=\"CWB6JYLC\"\u003E“自我审视”，提醒模型在产出结果之前，先自我审视一下，看看是否有更好的方案。也可以拿到结果后再调用一下模型强制审视一下。比如 AutoGPT 里的“Constructively self-criticize your big-picture behavior constantly”。\u003C\u002Fli\u003E\u003Cli data-pid=\"z7luH5Dl\"\u003E分而治之，大家在写 prompt 的时候也发现，越是具体的 context 和目标，模型往往完成得越好。所以把任务拆细再来应用模型，往往比让它一次性把整个任务做完效果要好。利用外部工具，嵌套 agent 等也都是这个角度，也是 CoT 的自然延伸。\u003C\u002Fli\u003E\u003Cli data-pid=\"9_vRbTM0\"\u003E先计划，后执行。BabyAGI，HuggingGPT 和 Generative Agents 都应用了这个模式。也可以扩展这个模式，例如在计划阶段让模型主动来提出问题，澄清目标，或者给出一些可能的方案，再由人工 review 来进行确认或者给出反馈，减少目标偏离的可能。\u003C\u002Fli\u003E\u003Cli data-pid=\"tWjx0nuQ\"\u003E记忆系统，包括短期记忆的 scratchpad，长期记忆的 memory stream 的存储、加工和提取等。这个模式同样在几乎所有的 agent 项目里都有应用，也是目前能体现一些模型的实时学习能力的方案。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp data-pid=\"KdjmAbaP\"\u003E可以看出这些模式都与人类的认知和思考模式有很大的相似性，历史上也有专门做 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fcogarch.ict.usc.edu\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Ecognitive architecture 相关的研究\u003C\u002Fa\u003E，从记忆，世界认知，问题解决（行动），感知，注意力，奖励机制，学习等维度来系统性思考智能体的设计。个人感觉目前的 LLM agent 尝中，在奖励机制（是否有比较好的目标指引）和学习进化（是否能持续提升能力）这两方面还有很大的提升空间。或许未来 RL 在模型 agent 这方的应用会有很大的想象空间，而不仅仅是现在主要用来做“价值观对齐”。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8fd3707e43ddc4afa367ce855ab84205_b.jpg\" data-size=\"normal\" data-rawwidth=\"1259\" data-rawheight=\"1280\" class=\"origin_image zh-lightbox-thumb\" width=\"1259\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8fd3707e43ddc4afa367ce855ab84205_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1259&#39; height=&#39;1280&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1259\" data-rawheight=\"1280\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1259\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8fd3707e43ddc4afa367ce855ab84205_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8fd3707e43ddc4afa367ce855ab84205_b.jpg\" data-original-token=\"v2-d180c7da0828c96231f8aa308c9443d2\"\u002F\u003E\u003Cfigcaption\u003E认知架构研究\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E常见问题\u003C\u002Fh2\u003E\u003Cp data-pid=\"5x82KwMa\"\u003E如果大家有实际上手玩过这些项目，应该能切实感受到一些当前模型 agent 的问题和局限性。例如：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli data-pid=\"YW7LXwZV\"\u003E记忆召回问题。如果只是做简单的 embedding 相似性召回，很容易发现召回的结果不是很好。这里应该也有不少可以改进的空间，例如前面提到的 Generative Agents 里对于记忆的更细致的处理，LlamaIndex 中对于 index 结构的设计也有很多可以选择与调优的地方。\u003C\u002Fli\u003E\u003Cli data-pid=\"VTUg4SP8\"\u003E错误累积问题。网上给出的很多例子应该都是做了 cherry-picking 的，实际上模型总体表现并没有那么惊艳，反而经常在前面一些步骤就出现了偏差，然后逐渐越跑越远……这里一个很重要的问题可能还是任务拆解执行，外部工具利用等方面的高质量训练数据相对匮乏。这应该也是 OpenAI 为啥要自己来做 plugin 体系的原因之一。\u003C\u002Fli\u003E\u003Cli data-pid=\"2i0haGCv\"\u003E探索效率问题。对于很多简单的场景，目前通过模型 agent 来自行探索并完成整个解决过程还是比较繁琐耗时，agent 也很容易把问题复杂化。考虑到 LLM 调用的成本，要在实际场景落地使用也还需要在这方面做不少优化。一种方式可能是像 AutoGPT 那样可以中途引入人工的判断干预和反馈输入。\u003C\u002Fli\u003E\u003Cli data-pid=\"JqdmiiB1\"\u003E任务终止与结果验证。在一些开放性问题或者无法通过明确的评估方式来判断结果的场景下，模型 agent 的工作如何终止也是一个挑战。这也回到了前面提到的，执行 task 相关的数据收集与模型训练以及强化学习的应用或许可以帮助解决这个问题。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp data-pid=\"n0kQi3_g\"\u003E你在使用这些模型 agent 过程中有碰到过什么样棘手的问题，有什么好的解决方法？或者有没有发现什么场景已经可以由现有的 agent 很好地满足？欢迎在评论区分享交流。\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20660508","type":"topic","id":"20660508","name":"LLM"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F27403263","type":"topic","id":"27403263","name":"Prompt Engineer"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":305,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"},"commentCount":10,"contributions":[{"id":44951719,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"}},{"id":45020237,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"作为一名算法工程师正在不断成长！","isFollowing":false,"urlToken":"c_161945759","id":"c_161945759","articlesCount":63,"acceptSubmission":true,"title":"我的ai之路","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_161945759","commentPermission":"all","created":1518061440,"updated":1599150227,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-1b5f41d17c32a5cfb050c9f6b5932647.jpg?source=172ae18b","uid":"723281551369977856","userType":"people","isFollowing":false,"urlToken":"qiu-zhen-yu-87","id":"98d958ca3c00b19cde95163e2b58e746","description":"致力于用ai做一些有实际意义的东西","name":"邱震宇","isAdvertiser":false,"headline":"程序员 机器学习 NLP探索者","gender":1,"url":"\u002Fpeople\u002F98d958ca3c00b19cde95163e2b58e746","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1b5f41d17c32a5cfb050c9f6b5932647_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":1215,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":812,"isNormal":true,"status":0,"activityToppingInfo":{"state":"untopped"},"shareText":"AutoGPT与LLM Agent解析 - 来自知乎专栏「RandomGenerator」，作者: 字节 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F622947810 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":83,"hasColumn":true,"republishers":[{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-1b5f41d17c32a5cfb050c9f6b5932647.jpg?source=172ae18b","uid":"723281551369977856","userType":"people","isFollowing":false,"urlToken":"qiu-zhen-yu-87","id":"98d958ca3c00b19cde95163e2b58e746","description":"致力于用ai做一些有实际意义的东西","name":"邱震宇","isAdvertiser":false,"headline":"程序员 机器学习 NLP探索者","gender":1,"url":"\u002Fpeople\u002F98d958ca3c00b19cde95163e2b58e746","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1b5f41d17c32a5cfb050c9f6b5932647_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}}],"isNewLinkCard":true,"emojiReaction":{"cryFaceCount":0,"cryFaceHasSet":false,"hugCount":0,"hugHasSet":false,"likeCount":83,"likeHasSet":false,"onlookerCount":0,"onlookerHasSet":false},"abParam":{"qaHiddenVoteup":"1","rsInterest1":"1"},"attachedInfo":"kgIkCgkyMjY1NjQzNzUSCTYyMjk0NzgxMBgHIgpJTUFHRV9URVhU","shareGuide":{"hasPositiveBubble":false,"hasTimeBubble":false,"hitShareGuideCluster":false},"settings":{"tableOfContents":{"enabled":true}},"canReference":false,"reactionInstruction":{}}},"columns":{"zijie0":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"zijie0","id":"zijie0","articlesCount":49,"acceptSubmission":true,"title":"RandomGenerator","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fzijie0","commentPermission":"all","created":1480664647,"updated":1590922686,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-b7a5731b9b518c13c4a82a90453ebaf6_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22.jpg?source=172ae18b","uid":"27758868561920","userType":"people","isFollowing":false,"urlToken":"zijie0","id":"dd44fd707897acda43e0a65ba07b3199","description":"如果您对我的作品感兴趣，欢迎关注个人公众号：RandomGenerator","name":"字节","isAdvertiser":false,"headline":"天地大观，志存高远","gender":1,"url":"\u002Fpeople\u002Fdd44fd707897acda43e0a65ba07b3199","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95ba0bb27d5abbdac132d83c17310b22_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":515,"type":"column"},"c_161945759":{"description":"","canManage":false,"intro":"作为一名算法工程师正在不断成长！","isFollowing":false,"urlToken":"c_161945759","id":"c_161945759","articlesCount":63,"acceptSubmission":true,"title":"我的ai之路","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_161945759","commentPermission":"all","created":1518061440,"updated":1599150227,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-1b5f41d17c32a5cfb050c9f6b5932647.jpg?source=172ae18b","uid":"723281551369977856","userType":"people","isFollowing":false,"urlToken":"qiu-zhen-yu-87","id":"98d958ca3c00b19cde95163e2b58e746","description":"致力于用ai做一些有实际意义的东西","name":"邱震宇","isAdvertiser":false,"headline":"程序员 机器学习 NLP探索者","gender":1,"url":"\u002Fpeople\u002F98d958ca3c00b19cde95163e2b58e746","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1b5f41d17c32a5cfb050c9f6b5932647_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":1215,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"zvideos":{},"zvideoContributions":{},"briefs":{},"eduCourses":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"ab":{"config":{"params":[{"id":"ques_follow_con","type":"Int","value":"0","chainId":"_gene_","layerId":"ques_follow_con","key":3320}],"experiments":[],"chains":[],"encodedParams":"Cgo7ArcDiwUnB\u002FgMEgUAAAAAAA=="},"triggers":{}},"abV2":{"config":{"paramMap":{"pm_new_task":{"value":"0"},"ws_platform_new":{"value":"0"},"in_editor_title":{"value":"0"}},"abMap":{}},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":true,"Android":false,"iOS":true,"isAppleDevice":true,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (iPhone; CPU iPhone OS 16_4 like Mac OS X) AppleWebKit\u002F605.1.15 (KHTML, like Gecko) Mobile\u002F15E148"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F622947810","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F622947810","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"oppoSearch":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false,"huaweiSearch":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"","xUDId":"AFBXnGGr8BaPTq1NbGXn_ppp0RPq8BY0Jxo=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"武汉","countryName":"中国","regionName":"湖北","countryCode":"CN"},"logged":false,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0}},"recommend":{"recommendTimes":{}}},"explore":{},"levelUpperLimit":10,"mcn":{},"mcnManage":{},"tasks":{},"announcement":{},"creatorsRecommendInfo":{}},"creators":{"common":{"applyStatus":{},"rightsStatus":{}},"bayesDomains":{"status":{},"options":{"topDomains":null,"allDomains":null,"editable":0},"contents":null},"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"faq":{"tabs":[],"article":{}},"knowledgeIncome":{},"safeguardRights":{},"analytics":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"account":{"growthLevel":{}},"KMResource":{},"training":{},"ToolsQuestion":{"goodatTopics":[]},"ToolsHotspot":{"domains":[]},"ToolsRecommend":{},"ToolsCustomPromotion":{"itemLists":{},"baseInfo":{}},"ToolsSearchQuestion":{},"editorSetting":{},"MCNManage":{},"knowledgeTasks":{},"incomeAnalysis":{"income":{"aggregation":{}}},"creationManage":{"editModal":{"status":false}},"activity":{},"announcement":{},"home":{"currentCreatorUrlToken":null,"rights":[],"newRights":[],"scoreInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"bannerList":[],"recentlyCreated":[]},"videoSupport":{"textBenefit":{}},"videoDistribution":{}},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"concernedUpvoters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"zijie0","c_161945759"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false},"linkCardLimit":0},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]},"adPromotion":{"answer":{},"article":{}}},"fetchHost":"www.zhihu.com","subAppName":"column","spanName":"Post","canaryConfig":{"test_canary":"0","use_new_player":"1","player_vendor":"1","use_hevc":"1","upload_use_signature":"1","use_backdrop_blur":"1","article_title_imagex":"0","play_station":"1"}}</script><script crossorigin="" src="https://static.zhihu.com/heifetz/vendor.5f3e51e68d56265eb628.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react@17.0.2/umd/react.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom-server.browser.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/runtime.app.560046624f28621b8b9f.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-29107295.app.a7b6d98ed785438234bf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-79b5cf47.app.f16b5bf4c3cff85007a0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-330004dc.app.1a4905d34b3df3f09dff.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-0e5ce61e.app.121a4e979ab55ff600b2.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-83b0f42f.app.6f9779781d0af52a0ddf.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-2ec050f6.app.c4cf2528b321f02e9fa0.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/680.app.f3c9d9e614b550bbff65.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.app.b9bcd5e5f805cd0c6068.js"></script><script defer="" src="https://static.zhihu.com/event/wza/4613/aria.js?appid=c5ddb58ead4528987249d96fb27246ab" id="ariascripts" wapforceoldfixed="false" loaddata="false" callbackexit="RQ_HALW_QDPH" callback="RQ_VWDUW_QDPH"></script><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script crossorigin="" src="https://unpkg.zhimg.com/za-js-sdk@4.13.0/dist/zap.js"></script><div><div style="display: none;"><i>想来知乎工作？请发送邮件到 jobs@zhihu.com</i></div></div><script src="https://zz.bdstatic.com/linksubmit/push.js"></script><script crossorigin="" src="https://unpkg.zhimg.com/@cfe/emoticon@1.2.4/lib/emoticon.js"></script></body></html>