    <html>
      <body>
        <div><h1>迈向 ChatGPT 时代 - 商业篇</h1>
                                        <p>这是一个系列文章，上一篇主要讲述了 ChatGPT
                                            背后的相关技术，感兴趣的同学可以参考：</p>
                                        <div><a href="https://zhuanlan.zhihu.com/p/608075096">字节：迈向 ChatGPT 时代 - 技术篇</a></div>
                                        <h2>商业</h2>
                                        <p>接下来我们来看看大语言模型在商业部分的影响，比如我们会不会失业，或者有没有什么其它发财的机会 :)</p>
                                        <h3>我们会失业吗？</h3>
                                        <p>前面在 AGI
                                            的探讨中，我们提出了目前即使是通用人工智能，其发展目标也是成为人类工作的助手。所以对于这个问题，很多大佬给出的回答都是模型并不会取代人的工作，但会深刻地变革我们的工作方式。就像远古时代，人类用树枝、石头来作画，后来有了纸和笔，再后来又发展出了数位板，Photoshop
                                            等，而未来，人类可能会通过自然语言指导模型生成来作画，让更多有创造力的人可以不用花很多时间学习绘画技术也能成为创作者。这是我们创造引擎的不断升级。当然，掌握这些新工具可能是非常重要的，所以最后一部分我也会展开聊聊我个人目前在尝试的一些新一代生产力提升工具产品。
                                        </p>
                                        <h3>从搜索引擎到个人助理</h3>
                                        <p>ChatGPT 刚推出时，讨论最多的可能就是它是否会有取代 Google
                                            搜索的可能。从当前的能力来看，显然还是无法做到的，但是不可否认 chatbot
                                            在形式上会有更多不一样的想象空间。例如在搜索引擎上搜一个问题，我们往往需要花大量的时间来查看和筛选其中的信息。而在对话机器人中，我们则可以通过不断地对话交互去快速定位到我们想要问题的答案，进一步降低了掌握这类工具的门槛。结合模型的生成能力，也能够做到搜索引擎无法完成的事情，例如帮忙产生特定需求下的文案、代码，根据用户的反馈信息提供个性化的建议方案（工作，健康，消费，娱乐
                                            etc.）等等。</p>
                                        <h3>商业化图景</h3>
                                        <p>这方面有很多机构与个人都做了梳理，例如 <a href="https://link.zhihu.com/?target=https%3A//www.sequoiacap.com/article/generative-ai-a-creative-new-world/">红杉从各类
                                                AIGC 的应用角度的图景</a> 和 <a href="https://link.zhihu.com/?target=https%3A//a16z.com/2023/01/19/who-owns-the-generative-ai-platform/">a16z 从
                                                tech stack 角度的图景</a>。个人感觉来自 <a href="https://link.zhihu.com/?target=https%3A//www.madrona.com/foundation-models/">Madrona
                                                的 foundation model stack</a> 的理念很有意思，其中也把很多关键的讨论点标了出来。我们下面也基于这张图做一些探讨。
                                        </p>
                                        <p><br></p>
                                        <figure><img src="https://pic1.zhimg.com/v2-440809ce63f7c1155c2b6c6b21479a94_b.jpg"></figure>
                                        <p><br></p>
                                        <h3>应用层</h3>
                                        <p>对于应用层来说，里面有很多我们耳熟能详的公司，例如 22 年做到一亿美金 ARR 的
                                            Jasper，文生图领域非常火的 Midjourney，以及代码代发辅助 GitHub Copilot 等。a16z
                                            的文章中指出，按照以往经验，应用层应该是能够捕获商业价值最大的部分，但目前他们尚未找到哪家公司拥有了难以复制的显著网络效应、数据积累或者与某些业务工作流的深入结合。即使像
                                            Jasper 这种已经有很高收入的公司，也仍然需要观察他们后面几年的 NDR 情况如何。例如早年的 Prisma
                                            也出现过短暂的火爆，但后续用户的留存率非常低。</p>
                                        <p>对于应用层的公司来说，尤其是目前比较火热的做文本生成相关的公司，有两个需要思考的决策：</p>
                                        <h3>使用闭源模型（MaaS/API），还是利用开源构建自有模型？</h3>
                                        <p>目前 text-to-text 生成领域，最好用的模型应该还是 OpenAI 提供的各种 API 和
                                            ChatGPT 这个产品。所以像 Jasper，Copy.ai 等几个知名公司都是基于 OpenAI 的模型来做的产品。但是 ChatGPT
                                            的推出，可能让很多依赖 OpenAI 接口的产品产生了一些危机感。如果 OpenAI
                                            自己使用了更好的模型做出了类似功能的产品，并且没有把相关能力通过他们的付费 API 提供出来，那么基于 OpenAI
                                            的这些公司的地位就很容易受到冲击，毫无竞争壁垒可言。</p>
                                        <p>有意思的是在文生图领域，OpenAI 虽然也有类似的 Dall-E
                                            2，但绝大多数公司都是使用开源模型（Stable Diffusion）来构建。一方面可能是因为这类模型的规模本身没有 GPT
                                            那么大（其中的文本模型部分相比 GPT 小很多），训练、微调和推理的成本相对可控，图像领域的 foundation model
                                            体系也还没成熟。另一方也说明了如果有足够优秀的开源模型提供出来，大家还是更倾向于“把命运掌握在自己手中”，并且整个应用的生态可能发展的也会更快一些。
                                        </p>
                                        <p>未来会如何发展呢？是会有更多的公司都训练自有模型，形成企业技术 stack 的一个部分，还是会往 AI
                                            时代的云平台发展，仅有少数的公司提供巨大的 foundation model service？这里可以深入思考的点有很多，例如：</p>
                                        <ul>
                                            <li>MaaS 模式下，应用开发的速度明显加快，会大大提升应用层生态的快速发展。供给侧的繁荣也很重要。
                                            </li>
                                            <li>
                                                应用层公司可能的两个壁垒，一是在模型基础上与真实场景连接时，仍然需要复杂的编排，交互设计等。越理解垂直行业，体验就会越好。二是我们经常说的，需要通过数据来构建壁垒，用户用的越多，有价值的专有数据就越多。
                                            </li>
                                            <li>模型技术会如何发展？应用类公司积累的专有数据能否很好的融入到公开模型中（prompt
                                                可能是中间状态）？Fine tune 对于模型通用泛化能力的性能损耗相比 in context learning 没法保留较长的
                                                context，哪个会胜出？超大规模模型相比中小规模模型在“涌现”能力上的差距会不会放大？</li>
                                            <li>
                                                用户场景对于模型“专有化”的诉求会到哪一层？是更希望把整个互联网的数据都看一遍的通用模型，还是小一点的模型，把某个领域的知识多看一点，还是更精细化，每个人都可以有一个自己的“微调”模型？从当前的推荐系统来看，更多的是每个平台/产品自己构建一个的中间状态。
                                            </li>
                                            <li>算力成本长期来说肯定会大幅降低，这个应该大家都没有疑问。</li>
                                        </ul>
                                        <p>当前个人更倾向于 MaaS
                                            的方向，尤其是基于公开数据训练的超大多模态基础模型，即使训练成本在不断降低，但各种数据的爬取，人工/系统化打标的维护，模型在数据量、参数上的潜在规模优势，少量有经验顶尖人才资源的争夺等，都能让资源聚集下的少数公司取得比自有模型好很多的效果。结合“涌现”能力来说，有可能会把差距越拉越大。
                                        </p>
                                        <p>
                                            当然各种企业内部的私有数据（很多是结构化数据）方面，仍然是有很多自有模型构建与应用的需求的，以目前的技术发展来看这部分仍然是有开源模型与 model
                                            hub、MLOps 等公司的市场空间的。而且当前结构化数据基本上也还是以传统模型为主，甚至用上深度学习的都非常少（相关研究也少，缺乏海量公开表格数据）。
                                        </p>
                                        <p>总体来说，这块是技术与市场需求都在高速演化的一个状态，OpenAI 是否已经拿到了足够的先发优势也不好说。</p>
                                        <h3>是初创类公司更有优势，还是成熟公司产品中融入相关能力更有优势？</h3>
                                        <p>我们在图景中也会发现很多已有公司会在相关的功能中开始嵌入相应的能力，比如 Notion 中已经加入了 GPT 的
                                            AI 协助能力，Office 也计划马上要在全线产品中嵌入 ChatGPT
                                            功能支持。对于应用层来说，是否能够很好地嵌入到企业/个人的工作流中去，提供更好的体验、更高的效率是非常重要的一点，也是产品核心的竞争壁垒。此外前面也反复提到长期积累的领域相关用户行为数据也至关重要。
                                        </p>
                                        <p>
                                            对于创业型公司来说，主要的优势在于没有历史包袱，针对性地打造新产品，使用新技术手段的迭代速度可以做到非常快（这点是不是和自建模型会有冲突），让客户更快享受到新技术带来的价值。而对于成熟公司来说，主要的优势在于已经有了成熟的供应渠道，且原有
                                            workflow
                                            的融合度也会更好一些。创业公司能否在这些成熟渠道反应过来之前，尽快嵌入到用户使用流程中去，且建立起一些不可替代的价值点，才有可能站稳脚跟。对于像文本创意领域，个人相对来说还是会更看好已有产品公司一些。创业公司的机会肯定有，但感觉更可能在那些“新物种”型的产品上获得突破，例如后面会提到的类似
                                            Gong 这样的公司从新能力角度去切入已有市场需求。</p>
                                        <h3>新的杀手级应用？</h3>
                                        <p>
                                            有了大语言模型这种强大的能力，后续衍生出来的新物种会是什么样的形态呢？目前很多人给出的梳理大都还是从技术能力角度出发，例如 Twitter 上的这个图：
                                        </p>
                                        <p><br></p>
                                        <figure><img src="https://pic4.zhimg.com/v2-4c2e5cf6d895107a87ce20811d0a5eab_b.jpg"></figure>
                                        <p><br></p>
                                        <p>
                                            从这个角度去思考，以大语言模型为例，我们是否可以挖掘一下日常生活、工作中各种以自然语言形式存在的内容，有没有机会使用这些模型来提效。例如我每天会听到和读到哪些类型的文字，以及我每天需要说出或者打字输出哪些类型的文字，这些内容是否能通过模型来帮助提效或优化。一个例子如
                                            <a href="https://link.zhihu.com/?target=https%3A//www.synthesia.io/">Synthesia</a>，<a href="https://link.zhihu.com/?target=https%3A//www.d-id.com/">D-ID</a> 这类产品可以直接从文本来生成一个真人/avatar
                                            的播报视频，大大提升此类传播内容创作的效率。
                                        </p>
                                        <p>
                                            除了单点的文字型应用外，回想一下前面提到的“模型之间可以与文字来交流”这件事，可以做进一步的组合。比如一部分模型负责生成代码，通过代码执行得到一些新的文字结果，这个结果又可以进入搜索引擎，最后搜回来的结果再通过一个语言模型来做总结。甚至这类新的基于语言文字的
                                            workflow 成熟之后，以往的某些单点中间任务都不需要做了，这也是仅仅拿新技术去适配当前产品功能所需要额外注意的点。</p>
                                        <p>
                                            另外我们也可以从问题和场景的角度来思考。例如对于知识查询，在个人电脑时代我们拿到的是大英百科全书的光盘，但互联网时代就被维基百科所颠覆，而到了移动时代可能类似
                                            Siri 之类的语音助手又挖走了一部分流量。其它问题也类似，我们可以沿着互联网时代如何解决某个问题，再到移动时代如何解决某个问题，去思考未来 AI
                                            时代我们会去如何解决这个问题。</p>
                                        <p>就在写这篇文章的时候，谷歌和微软已经在 AI 时代的搜索应用上开战了。新版的 Bing
                                            看起来已经非常好地融合了时效性信息与大语言模型两者的能力，效果惊艳。而对谷歌来说，集成模型能力进来会提升每一次搜索的计算成本开销，另一方面如何在问答中“植入广告”也还没有明确的方案，两者叠加不可避免会降低谷歌的利润里。以当前形势来看，看来谷歌真的是在成立以来第一次受到了巨大的挑战与威胁。
                                        </p>
                                        <p>从 AI
                                            对人类社会的长远影响来看，还有一种流行的想法是未来各种商品的生产成本会无限地降低，未来可能有非常多的人都不需要工作了，可以做更多自己喜欢的事情。从而可能会有大量的人长期沉浸在
                                            AR/VR 环境的游戏世界中，毕竟人生也就是一场体验的游戏嘛。当前也有很多把 AIGC 相关能力开始使用到游戏行业中的尝试，包括自动生成 NPC
                                            对话，生成新的装备道具，甚至连剧情，地图场景，玩法系统都可以自动产生，真正成为“无穷的游戏”。</p>
                                        <h3>工具层</h3>
                                        <p>在大语言模型方面，目前业界主流的方式都是调用第三方的 API
                                            来开发相关应用。这也使得模型的使用与维护门槛降低了不少，大量的软件工程师也可以参与到其中来，而不再像以前那样强依赖于机器学习工程师。但目前的 API
                                            还有很多限制与不足，例如我们通常需要对不同的任务设计不同的提示词（prompt/instruct），模型的输入一般有 4000-8000 个 token
                                            的上限限制，在完成一些具体场景任务时需要与多种外部系统协同配合等，因此出现了一系列针对 LLM 的开发工具。这些工具与传统的
                                            ETL，或者任务编排工具在场景上会更加聚焦一些，形成了一个全新的品类，最知名的应该就是 <a href="https://link.zhihu.com/?target=https%3A//github.com/hwchase17/langchain">LangChain</a> 了，后面我们也会详细介绍它。</p>
                                        <p>在图中也标出了一些专注于做大模型评估的产品，例如 <a href="https://link.zhihu.com/?target=https%3A//humanloop.com/">Humanloop</a>，我上去看了一眼功能也与前面提到的大语言模型编排工具很类似（LangChain
                                            里也有 evaluation 功能）。</p>
                                        <p>由于整个行业对于 LLM 的应用也处在很早期，这块公司产品的商业机会不确定性非常大，简单列举几个我的想法：</p>
                                        <ul>
                                            <li>首先这些产品逻辑成立的前提可能是需要大多数应用都以当前的这种基于 model as a service
                                                的方式来构建，如果未来自建模型，fine tune 等成为了主流，那么这其中的不少功能就用不上了。</li>
                                            <li>具体功能点上，也会随着底层 API 的变化有可能需要演进。例如普遍的判断是 prompt
                                                工程会随着模型技术的迭代而变得越来越不重要，很多原先需要编排实现的功能后续也很可能会集成到模型服务商的 API
                                                里。到底哪些功能在长期发展趋势上仍然会是一个差异化的价值点需要深思熟虑。</li>
                                            <li>最后就是怎么赚钱的问题了，比如是否可以在模型 a/b 测试，动态选择效果与价格最优的 API
                                                上收点服务费？现在考虑这个问题可能还有点早。</li>
                                        </ul>
                                        <p>所以总体来看这一个新的层还处在很早期，不确定性很大。当然如果这两年迎来了基于 LLM API
                                            的应用爆发的话（成熟产品，创业公司都需要集成），或许很快就能形成一个不小的开发工具市场。</p>
                                        <p>PS 这一个工具层也可以被称为 FOMO FOundation Model Orchestration aka
                                            Fear Of Missing Out :)</p>
                                        <h3>模型层</h3>
                                        <p>与我们前面提到应用层的选择相呼应，在模型层也有两大类 stack，分别是闭源的私有模型服务，以及开源模型 +
                                            model hub。图中以 iPhone vs. Android
                                            来做类比也挺形象，前者可以更快地开发出应用上架售卖，而后者的可定制化程度会更高。下面的讨论中我们会以语言模型方向为主。</p>
                                        <p>在私有模型层面，有数据表明目前市场上大概有 80%的应用使用的都是 OpenAI 的服务，有 15%使用 <a href="https://link.zhihu.com/?target=https%3A//cohere.ai/">Cohere</a>，还有约 5%使用 <a href="https://link.zhihu.com/?target=https%3A//www.anthropic.com/">Anthropic</a>。由于大语言模型/基础模型所需的数据量，算力，顶尖人才等都有很高的门槛，普通的创业公司应该很难在这块有所作为。而几家头部公司要在这块体现出竞争优势的话，可能也是进一步去完善开发者的体验（侵食前面提到的工具层的能力），能够让应用生态中的参与者们更快更便宜的把相关应用构建出来并赚到钱。这也是他们与开源方案竞争的一个重要方向。
                                        </p>
                                        <p>开源模型层面，最知名的应该就是 HuggingFace 了。在 GPT API 风靡之前，各种应用
                                            Bert/Transformer 模型的公司应该都会使用 HuggingFace 上提供的各种模型和代码，基本已经成为了语言模型领域的
                                            GitHub。但在 OpenAI 提出 prompt + zero/few shot 这条路线之后，或许已经对定制化模型这条路产生了一些挑战。如果调用
                                            API 的效果已经如此之好了，做应用的公司是否还有必要招聘很多 NLP
                                            工程师来做模型开发，调优，运维方面的工作呢？这块我的了解也不多，非常欢迎深入研究开源模型栈的同学更正我的想法。</p>
                                        <p>现阶段如果有在公司内部复现 GPT 类模型的诉求，图中的 Bloom，OPT，GLM-130B
                                            都是可以尝试的一些优秀开源模型。在开源数据集层面，Stable Diffusion 的模型是基于 Laion 的数据训练的，而 GPT
                                            系列印象中有一部分是基于 Common Crawl
                                            的数据做了一系列质量上的筛选形成的训练集。这些数据提供方在未来应该也会有越来越重要的商业价值，甚至产生新的业务形态与公司。</p>
                                        <p><br></p>
                                        <figure><img src="https://pic2.zhimg.com/v2-2d2757b60874738ecd9a7858d6b0696d_b.jpg"></figure>
                                        <p><br></p>
                                        <h3>Foundation Model Ops</h3>
                                        <p>这一层会与传统的 MLOps
                                            比较一致，有一系列提供模型训练，推理，部署优化（稀疏化，模型压缩，编译优化等）等方面的工具产品。个人感觉这一层也同样受到了中间核心的模型层选择的巨大影响。如果大家都更倾向于使用私有模型
                                            API 服务，且这类大模型往往具有很高的开发，部署，运维复杂度，难以通过通用产品来满足（定制化为主），那么的确很多以前的 MLOps
                                            工具的应用场景与价值获取都会受到挤压。</p>
                                        <p>这里也顺带提个八卦，网上有文章说 OpenAI 使用了 Ray 框架来做模型训练，我初看到也比较震惊。一直觉得
                                            Ray
                                            属于那种主打易用性，但增加了很多抽象层牺牲了极致性能的框架，竟然可以用来训练这些大模型？后来稍微做了些功课，貌似出处来自一篇国外的付费文章，但从看过文章的人来描述，其中也并没有明确说
                                            OpenAI 用了 Ray 来做分布式的模型训练。大多数的专业人士的判断和猜测也跟我类似，Ray
                                            可能并不是用在了模型训练部分，更可能是一些其它数据和流程处理方面的应用。</p>
                                        <p>另外还有一些专注于数据层面（打标，仿真与生成）的公司，如 Scale.ai，Snorkel，<a href="https://link.zhihu.com/?target=https%3A//mostly.ai/">Mostly
                                                AI</a>, <a href="https://link.zhihu.com/?target=https%3A//hazy.com/">Hazy</a> 等未来应该会有不少机会，RLHF
                                            甚至有可能从一项技术变为一种新的职业。最近还了解到像 <a href="https://zhuanlan.zhihu.com/p/603784945">Profluent</a>，<a href="https://zhuanlan.zhihu.com/p/589735937">Generate
                                                Biomedicines</a> 这样的生物医药科技公司，也都在使用 AIGC
                                            相关的技术做蛋白质设计生成，他们所依赖的训练数据与传统的文本模型有很大差别，也是这类范式应用到其它领域的一个关键问题。从生产要素角度总体来看，数据、提供
                                            AI 所不具备能力的人才以及能源或许是未来这个领域最重要的几个组成部分。</p>
                                        <h3>Infra 层</h3>
                                        <p>在 a16z 的报告中，目前各类 AIGC 应用公司约有
                                            20-40%的收入都会用于支付在云平台上的推理、微调等产生的计算费用，而模型供应商如 cohere 等则有
                                            50%的收入用于云基础设施的建设。所以从目前阶段来说，三大云厂商以及相关硬件厂商如英伟达、台积电等在很长一段时间内都能拿到不小的收入分成。长远来看，如果
                                            AI
                                            技术本身是差异点，那么纵向应用（end-to-end，包括自建基础设施）可能会拿走大部分的收入。如果是百花齐放的长尾应用分布，或许会出现新时代的“AI
                                            计算”基础设施，这类横向平台会占领市场收入的大头。</p>
                                        <p>从当前大家对于 ChatGPT，Midjourney 类应用的火爆需求程度来看（用 ChatGPT
                                            的回答速度肉眼可见地变慢了），对于底层算力和效率提升的需求是非常巨大的。相关的专用软硬件加速方案或许会迎来一个市场的春天。</p>
                                        <h3>商业化壁垒</h3>
                                        <p>a16z 对此的评论是：</p>
                                        <blockquote>
                                            老生常谈的护城河依然存在，比如：规模护城河（“我能比你融到更多的钱！”），供应链护城河（“我拥有你所没有的
                                            GPU！”），生态护城河（“所有人都已经在使用我的软件”），算法护城河（“我们比你更聪明！”），分发护城河（“我已经组建了销售团队并且客户数比你多！”）以及数据管道护城河（“我在互联网上爬取了比你更多的信息！”）。但长期而言，这些护城河并不可持续。强大的网络效应是否会在生成式
                                            AI 技术栈中的任何一层占据上风？现在下定论，一切还为时过早。</blockquote>
                                        <p>个人当前有几点比较零星的体会，主要针对应用层面：</p>
                                        <ul>
                                            <li>找到明确需要解决的问题还是关键，最终的解决方案可能是非常综合的，而不是单纯从 AI 技术角度出发思考。
                                            </li>
                                            <li>融入到企业或个人的特定工作流程中去，形成使用上的习惯与粘性，是构建产品壁垒的很关键一点。很多 AI
                                                产品看起来比较新奇，能在短时间内获得大量的关注和试用，但如果没有在用户 workflow 中稳固下来，很容易在热情退去后惨淡收场。</li>
                                            <li>需要去思考如何系统性地获取到领域相关的专有知识和数据，反过来不断促进产品能力的提升，形成正向循环。比如
                                                ChatGPT 就能持续从用户使用过程中获取反馈信息，进而更好地改进他们的核心模型。</li>
                                        </ul>
                                        <h3>经济模型</h3>
                                        <p>前面提到大模型的算力需求问题，这里有一篇很好的文章来系统性地阐述 <a href="https://link.zhihu.com/?target=https%3A//sunyan.substack.com/p/the-economics-of-large-language-models">LLM
                                                的算力经济模型</a>。另外 ARK 也在报告中预估，到了 2030 年，GPT-3 模型训练的成本可能会降到 30 美元。</p>
                                        <p><br></p>
                                        <figure><img src="https://pic1.zhimg.com/v2-1fc0c270bd2fcbe4594d4d2e319e0cec_b.jpg"></figure>
                                        <p><br></p>
                                        <p>这个算力增长的趋势我非常认同，但在训练价格降低的情况下，是否会成为上述在私有 MaaS
                                            与开源模型之间选择的决定因素，仍然不好下结论。类似于当前购买单台服务器的成本也很低，但为何上云是一个非常显著的趋势？在算力存储都不断变得更便宜的同时，整个互联网硬件体系的规模也并没有逐年减少。或许在
                                            2030 年我们需要拿整个英特网的数据来训练更有效的大模型，其成本比今天更高也不好说。</p>
                                        <h3>相关公司与产品</h3>
                                        <p>Antler 这家机构整理了非常多 AIGC
                                            领域相关公司的信息，包括产品领域，创办地点，时间，一句话介绍，融资信息等，具体可以打开这个 <a href="https://link.zhihu.com/?target=https%3A//airtable.com/shrBeWpMlxf3e14E8/tblS4TkbJbm0cqT0o">在线表格</a> 查看。也可以在搜索公众号“深思圈”，上面有非常多的相关公司产品介绍。
                                        </p>
                                        <p>应用层面看，最知名的应该还是泛创意领域的那几家如 Grammarly，Jasper，Copy.ai
                                            等帮用户撰写优化文字的，以及 stability.ai，Midjourney，Runway
                                            等文字生成图片与视频编辑的。之前很多人理解中，创意应该是最难被 AI
                                            颠覆的工作，但现在来看这类开放性，有一定错误容忍度的场景，反而非常适合模型来进行辅助提效。其实仔细想想，推荐搜索这类老牌应用也是有一定的这方面的特质的。但很多需要完全准确可控输出的场景，反而很少看到大模型在这方面的应用进展。
                                        </p>
                                        <p>在估值比较高的公司里，有两家我之前并不太熟悉，分别是 <a href="https://link.zhihu.com/?target=https%3A//www.ada.cx/">Ada</a>
                                            和 <a href="https://link.zhihu.com/?target=https%3A//cresta.com/">Cresta</a>，查了一下发现都是智能客服、聊天机器人领域的公司。两家的功能形态上粗看也挺类似的，都能做的规模比较大，看起来这块在国外来说的确是个很大的市场。
                                        </p>
                                        <p>另外也有一些 to B 公司看起来没有被收录到这个表格中，比如 <a href="https://link.zhihu.com/?target=https%3A//www.gong.io/">Gong</a> 和 <a href="https://link.zhihu.com/?target=https%3A//www.deepscribe.ai/">DeepScribe</a>。以前者为例，他们能够自动记录销售电话，邮件，短信等非结构化数据，通过大模型的能力来进行处理与分析这些文本信息，进而提供如业绩进度，客户反馈内容，销售线索质量等相关
                                            insights，指导后续动作，也可以用来培训销售人员。以此为核心，他们就能切入之前看起来很成熟的 CRM 市场，有望成为 AI
                                            时代的引领者。当然过程中需要考虑的困难因素也有不少，例如：</p>
                                        <ul>
                                            <li>当前的大模型大多是通过公开数据训练的，如何把企业内部的信息知识融入模型会是一个挑战（fine tune
                                                很贵，prompt 有长度限制）。</li>
                                            <li>企业场景中对于结果输出的正确性和可控性要求也会比通常的创意场景高很多。</li>
                                            <li>前面提到的通过积累行业、领域专门数据来构建竞争壁垒方面，这部分的知识怎么与模型 stack 来结合？
                                            </li>
                                            <li>如果使用公开的模型 API，数据安全方面如何保障与合规？</li>
                                            <li>如何能做到轻量级切入，后续又能与企业中的已有流程紧密结合？</li>
                                        </ul>
                                        <p>更有野心一点的公司像 <a href="https://link.zhihu.com/?target=https%3A//www.adept.ai/">Adept</a>，想要做一个基于自然语言接口的
                                            RPA，从演示上来看非常酷炫。不过嘛如果未来各个应用或网站本身就是天然以自然语言和问答的形式来交互的话，RPA 的作用可能就没有那么显著了。</p>
                                        <p>最后从表格里看，大多数初创公司还是集中在应用层，少量会切入工具层，专注于模型层和底层 Infra
                                            相关的新公司不多，可能也是侧面印证了这块的进入门槛有些高。当然前面也提到过，目前大家普遍认为在这一层领先的技术与平台能拿到的收入利润也是确定性非常高的，很多大厂都不甘于在这块落后。
                                        </p>
                                        <h3>产品设计</h3>
                                        <p>在体验 Dall-E 2，Stable Diffusion 和 Midjourney
                                            时发现，这几个产品除了在生成画作上的风格有所区别外，发现在产品形态也是非常的不一样。很多普通用户来使用此类产品，可能第一反应是不知道自己想要画什么。像
                                            Dall-E 2，Stable Diffusion 之类虽然也提供了样例，prompt database 之类，但个人感觉 Midjourney
                                            这种在公开频道里让大家彼此都能实时看到别人用的
                                            prompt，产生的效果，是一种非常好的快速上手，提升分享氛围，进而激发创造力的方式。另外像画作的生成过程，时间与质量的权衡，可以调整的参数，进一步处理与优化等方面，显然
                                            Midjourney 也是经过很多思考与设计的，相对来说另外两家就更像是个原型。</p>
                                        <p><br></p>
                                        <figure><img src="https://pic1.zhimg.com/v2-d1518baa53d9dac77f6864946a0aafb8_b.jpg"></figure>
                                        <p><br></p>
                                        <p>同样，Jasper.ai 在技术如何满足用户诉求方面也有着非常深入的洞察。前面有提到，OpenAI
                                            这类做基础模型的公司，看起来“护城河”更深一些。但反过来讲，语言模型的 API 通用度比较高，对于 Jasper
                                            这样的公司来说，切换成本可能并不高。即使作为 GPT
                                            的创造者，其实对于其模型能力、应用场景上并不了解，需要有更多有深入客户洞察的应用型公司来开拓商业场景。举一个简单的例子，当前的语言模型在输出文本的语义复杂度，事实遵从程度以及领域相关性上，是存在一些取舍关系的。在诸如教育场景中，用户可能会更倾向于生成简洁但精确的文本信息；而在营销场景中，用户可能更喜欢生成辞藻华丽的大段文章，在此基础上做删减，而不是反过来。这些用户洞察一样可以成为应用型公司的护城河。
                                        </p>
                                        <p>
                                            总结来说即使是在类似模型技术的条件下，在产品设计和人机交互层面，到进一步的场景化层面，或者再到社区/市场的层面，其实都有很多改进空间和市场机会。对于想投身这方面的创业者，不要仅仅盯着技术浪潮就
                                            all in 进去，还是要把“要解决什么问题，为什么是现在，为什么是我”等问题思考清楚。 </p>
                                        <hr>
                                        <p>这篇文章会分为三个部分，如果觉得内容上对你很有帮助，想先睹为快剩下的内容，可以移步公众号付费文章：</p>
                                        <div><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/d_KrCHcoOJiKg2cEh-lMQQ">解锁超能力 - ChatGPT 时代的技术，商业与个人生产力</a></div>
                                        
                                    </div>
      </body>
    </html>
    