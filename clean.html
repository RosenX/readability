    <html>
      <head>
        <title>OpenAI领投，这家机器人公司要给ChatGPT造个身体？ - 知乎</title>
      </head>
      <body>
        <h1>OpenAI领投，这家机器人公司要给ChatGPT造个身体？ - 知乎</h1>
        <div><blockquote>OpenAI 投了一家做具身智能的机器人公司，ChatGPT 要有身体了？</blockquote><p>前段时间，OpenAI 和微软联手扔下两枚重磅炸弹：被人千呼万唤的 GPT-4 和以迅雷不及掩耳之势发布的 Microsoft 365 Copilot。借助前者强大的图文理解、生成能力，后者把很多工作都自动化了，包括写文档，把 Word 转成 PPT，根据 Excel 数据生成图表……</p><p>一时之间，AI 模型似乎什么都可以干了，但有些需要身体的活儿暂时还干不了。于是，压力来到了机器人这边。</p><figure><div><img src="\&quot;https://pic2.zhimg.com/80/v2-d5ba00641746268dcd1fa8ef44ae0451_1440w.jpg\&quot;"></div></figure><p>AI 大模型加机器人会产生什么化学反应？谷歌前不久的一项研究已经给出了初步答案：他们训练了一个参数量达 5620 亿的具身多模态语言模型 —— PaLM-E，然后用这个模型来驱动机器人自主地完成各项任务。在执行这些任务的过程中，机器人必须像人一样能看、能「思考」，把眼前的状况分析清楚，然后制定行动计划并执行。</p><p>比如，你可以直接问机器人：「如果一个机器人想在这里（如下图）发挥作用，它应该采取哪些步骤？」PaLM-E 可以给出答案：首先清理桌子、清理垃圾，然后挪动椅子、擦椅子，最后把椅子放回原处。对于普通 AI 模型来说，能回答出这些就已经可以了。但区别在于，谷歌这个大模型是有身体的，因此可以把上面提到的工作都做完。这就给了大家更大的想象空间。</p><figure><div><img src="\&quot;https://pic1.zhimg.com/80/v2-5d5d08684ca7ead726534a5a256d34cc_1440w.jpg\&quot;"></div></figure><figure><div><div><img src="\&quot;https://pic1.zhimg.com/v2-74bddd5b98c8c24652917d5def4d1a44_b.jpg\&quot;"></div></div></figure><p>当然，在这个名为「具身智能」的领域，谷歌并不是唯一的玩家。国内外很多研究机构、初创公司都将其作为发力方向之一。其中，一家名为「1X」的机器人公司成功引起了 OpenAI 的注意。</p><p>1X 成立于 2014 年，原名 Halodi Robotics，其目标是创造具有实用价值，可以在现实世界中应用的机器人，以增加全球劳动力。</p><figure><div><div><img src="\&quot;https://pic2.zhimg.com/v2-2f6e3df24278d305b3d9ef379e794611_b.jpg\&quot;"></div></div></figure><p><i>Halodi Robotics 发布的自家机器人 demo</i></p><p>在最近公布的 A2 轮融资中，这家公司总共融到了 2350 万美元。重要的是，这轮融资是由 OpenAI 创业基金领投的，老虎环球和一个由 Sandwater、Alliance Ventures 和 Skagerak Capital 等挪威投资者组成的财团也参与了投资。1X 计划用这笔资金来加大力度研发双足机器人模型 NEO，以及在挪威和北美量产其首款商用机器人 EVE。</p><figure><div><img src="\&quot;data:image/svg+xml;utf8,\&quot;"></div></figure><p><i>官网展示的机器人模型 NEO</i></p><figure><div><div><img src="\&quot;https://pic2.zhimg.com/v2-df05b046d506c83238d0059a21d6cd61_b.jpg\&quot;"></div></div></figure><p><i>机器人 EVE</i></p><p>在 1X 的官网上，我们可以看到该公司对于两大机器人产品的路径规划：EVE 具备轻柔地移动、操纵物体和与世界互动的能力，离现实世界应用已经非常近了；NEO 的目标则是探索人工智能如何在类人身体中形成，也就是我们所说的具身 AI。这或许既是 OpenAI 选择投资 1X，也是前谷歌机器人高级研究科学家 Eric Jang 选择加入这家公司的原因。</p><figure><div><img src="\&quot;data:image/svg+xml;utf8,\&quot;"></div></figure><p>Eric Jang 2022 年 3 月末从谷歌离职（待了 6 年），4 月 25 日宣布加入 1X（当时还叫 Halodi Robotics），担任 AI 副总裁一职。</p><figure><div><img src="\&quot;data:image/svg+xml;utf8,\&quot;"></div></figure><p>在选择下家的过程中，Eric Jang 是非常谨慎的，最重要的决定因素是该公司是否拥有领先竞争对手数年的技术优势。在他看来，专攻类人机器人的 Halodi 已经满足这一条件。</p><p>「我个人（通过加入 Halodi）押注的护城河是『比其他任何公司都领先 5 年的人形机器人』。Halodi 已经有了，而特斯拉正在开发他们的同类产品。我在 Halodi 的主要工作最初是训练模型以解决移动操作中的特定客户问题，同时也为 AGI 制定路线图：如何从人形形式压缩大量具身的第一人称数据，从而产生通用智能、心智理论和自我意识。」Eric Jang 在博客中写道。</p><figure><div><img src="\&quot;data:image/svg+xml;utf8,\&quot;"></div></figure><p>OpenAI 对 1X 的投资让这家公司备受瞩目，OpenAI 创业基金 Brad Lightcap 表示，他们相信 1X 可能对未来工作提供的方法及产生的影响。老虎环球的合伙人 Griffin Schroeder 也表达了对 1X 使命的热情：「我们相信 1X 的机器人正在彻底改变机器人领域，我们很高兴能与 OpenAI 一起投资，以支持他们的持续增长」。</p><p>不过，将 AI 与机器人融合可能并没有想象中那么容易。Eric Jang 在刚加入新公司的时候也提到，「近年来，具身 AI 和机器人研究已经失去了一些光彩，因为大型语言模型现在可以解释笑话，而机器人仍然在以不可接受的成功率进行拾取和放置。」但他还是选择了「押注」。因为他认为，「仅在比特世界对模型进行训练是不够的」。</p><figure><div><img src="\&quot;data:image/svg+xml;utf8,\&quot;"></div></figure><p><i>Eric Jang 在博客中展示的机器人领域泛化研究的现状。他提到，「目前很多机器人研究人员仍在进行的是小模型训练，并且还没有用过 Vision Transformer！」</i></p><p>在加入 Halodi 的这一年里，Eric Jang 一直密切注视着 AI 基础模型方向的进展，试图缩小机器人与 AI 生成模型之间的差距。在一篇名为《我们如何让机器人更像生成模型》的博客中，Eric Jang 从三个不同的维度比较了生成模型和机器人技术，思考如何将二者更好地联系到一起。其成果或将体现在今年夏天即将面世的 NEO 机器人中。</p><p>相关阅读：</p><p>《<a href="\&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650844751%26idx%3D1%26sn%3D6c985e44b6abce045575936112606c11%26chksm%3D84e56a31b392e3272ac75aa325cb27d532526884a86100af7b397ba085ae46da8cd5ff4ea299%26scene%3D21%23wechat_redirect\&quot;">离开谷歌这样的大厂，他们是这样寻找下家的</a>》</p><p>《<a href="\&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650853902%26idx%3D3%26sn%3D2e4b9cbce12256569fa3e436f1bb641d%26chksm%3D84e51670b3929f66819e39f0a5a8e5bba1e79968decde23308016399a734d93203762036489d%26scene%3D21%23wechat_redirect\&quot;">与生成模型相比，为何机器人研究还在用几年前的老方法？</a>》</p><p>《<a href="\&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650870477%26idx%3D2%26sn%3D663d31609cf30c6a039cd89efdc1513b%26chksm%3D84e4d6b3b3935fa57fea061233d9b44677eb2f0ed334ac9aa455d7fcc7b6dcf150ca947a6633%26scene%3D21%23wechat_redirect\&quot;">5620 亿参数，最大多模态模型控制机器人，谷歌把具身智能玩出新高度</a>》</p><p>《<a href="\&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650866616%26idx%3D3%26sn%3D337ed596386a6bd95f8de18ebab3f085%26chksm%3D84e4c7c6b3934ed06a7328ebe8ef7e9976a033015cd4d14a1473e36d809e0823edf24cf71a17%26scene%3D21%23wechat_redirect\&quot;">为什么说具身智能是通往 AGI 值得探索的方向？上海交大教授卢策吾深度解读</a>》</p><p>《<a href="\&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650849573%26idx%3D2%26sn%3Dfdb161ae4b83d207952951cdd4163bed%26chksm%3D84e5055bb3928c4d16d60a59a0add71778dcebe9f4f20ab529978dc3f6f77167ed7a5a07a8c8%26scene%3D21%23wechat_redirect\&quot;">李飞飞划重点的「具身智能」，走到哪一步了？</a>》</p></div>
      </body>
    </html>
    
